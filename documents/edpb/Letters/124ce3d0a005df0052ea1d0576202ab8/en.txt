 

 

Mr Didier Reynders 
European Commissioner  for Justice 
 
Sent by e-mail only 

 

 

 

 

 

 

 

  

 
Brussels, 22 February 2022 
Ref: OUT2022-0009 

 

Dear Commissioner  Reynders, 

 
The EDPB very much welcomes the Commission’s  initiative aiming at adapting liability rules to 
the digital age and artificial intelligence (AI) and wishes, in this context, to underline some elements 
that should  be considered and could usefully  complement the recent public consultation undertaken 
on this matter.  

 
Building upon  the 2018 evaluation of the Product Liability Directive and its main conclusions,  
the  EDPB considers  that the revision  of  this  legal  framework should  ensure  consistency  with  and 
complement the EU acquis in the field of personal data protection, in particular when it comes to the 
security of personal data processing and the use of AI systems to comply with this obligation.   

 
While,  under  the GDPR, only  controllers  and  processors  would  be  liable, e.g., in  case of  a 
personal  data breach, it  is  essential  to  consider  the  role  and  potential  liability  of  providers  of  AI 
systems developed and made available in order to secure personal data processing. In such case, the 
EDPB considers relevant to strengthen the liability regime of providers of such AI systems, and ensure 
that processors and controllers can trustfully rely on those systems. 

In their joint opinion 5/2021 on the proposal for a Regulation of the European Parliament and 
of the Council  laying down  harmonized rules on artificial intelligence (the AI Act)1, the EDPB and the 
EDPS laid down a list of acknowledgements and recommendations. In accordance with this opinion, 
the EDPB wishes  to reiterate some of its recommendations and to underline some points  of interest 
that should  be considered when adapting the Product Liability Directive to the new challenges of AI 
systems.  

                                                             
1 EDPB-EDPS Joint Opinion 5/2021 on the proposal for a Regulation of the European Parliament and of the 
Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act), 18 June 2021, available 
at:  https://edpb.europa.eu/our-work-tools/our-documents/edpbedps-joint-opinion/edpb-edps-joint-opinion-
52021-proposal_en  

 

 

 

 
Firstly, the EDPB wishes to renew a recommendation regarding the clarity of role attribution 
that was already raised in the joint  opinion  5/2021, and that gains further weight with the possible 
introduction of new attributions under the Product Liability Directive. In order to promote an efficient 
liability framework for AI systems that are used as security measures for personal data processing, the 
EDPB wishes to emphasize the importance of the interplay with existing regulation, such as the GDPR, 
especially when  it comes  to the attribution of responsibilities.  So as to ensure  clarity regarding this 
category of systems,  the EDPB considers  that the role and responsibilities  of  the provider of  the AI 
system  must  be  precisely  defined  to  bridge  the  gap  with  the  existing  framework  binding  data 
controllers and data processors. 

 
Secondly, the EDPB wishes  to draw the Commission’s  attention to the importance of several 
aspects of AI that were underlined  in the joint opinion  5/2021. Because of the nature of AI, assigning 
the  responsibility  to  a  party  in  a  claim  that involves  an  AI  system  might  be  particularly  difficult, 
especially when the burden of proof lies with the individual  since the latter could be unaware of the 
fact that AI is used  and, in the majority of  cases, would lack the necessary information  to prove the 
liability of the AI system. Hence, the explainability of the system  must be foreseen  at the step of its 
conception so that the results of all intended use, foreseeable use and foreseeable misuse that could 
lead to a potential claim, will be explainable by design. For that purpose, the EDPB wishes to stress 
the positive  effects of including systematic human supervision  and transparency for the end user on 
the use and operation of the AI system and on the deployed methods and algorithms. Limitations and 
risks  on  the use  of  AI systems  due  to different  types of  attacks, e.g., cyber-attacks and adversarial 
attacks, should  also be taken into consideration  in the responsibility  and liability schemes. Providers 
of AI systems should be responsible for providing users with mitigation tools for known and new types 
of  attacks and for  embedding security  by  design throughout the entire lifecycle  of the AI, whereas 
users  of AI systems  should  be  responsible  for  ensuring the safe operation of  the system. The EDPB 
considers  that these measures should  be mandatory, in  particular when the AI  system  is used  as a 
security measure for personal data processing  but does not process  personal data itself. Moreover, 
the AI system should  be accompanied with a thorough and accessible documentation, as this piece of 
information would  be necessary for the data controller to understand the cause of a system failure, 
especially if it led to a data breach, and to be able to stop the failure in a timely manner. Finally, the 
EDPB invites the Commission  to ensure that the revised directive will allow any affected person to find 
effective legal remedies after a system failure or a successful attack. 

Thirdly, specific liabilities might be triggered by the ineffective application of data protection 
principles by AI providers and users. Lack of data accuracy, or scarce attention paid to the fairness of 
algorithmic decisions  might translate into impairments to individuals’ rights and freedoms as well as 
damages or economic losses. It is essential that in the forthcoming legal regime on AI liability a primary 
role is vested by the preliminary assessment of the quality and representativeness of the data used by 
machine  learning  algorithms to  draw their  decisions.  Measurability  of  the degree  of  fairness  and 
causality of  algorithmic decisions  in general should  be a pillar  of  the new liability  rules  in  order to 
create  a  trustable  technological  environment  and  limit  the  negative  effects  arising  from  the 
occurrence of erroneous decisions. 

 

 

Lastly, the EDPB wishes  to underline  that the proposal  should  be effective as  a standalone 
legislation and not rely on the obligations laid by the AI Act. As was raised in the joint opinion  5/2021, 
the obligations laid on AI systems users and providers only apply to restricted categories of high-risk 
AI systems, whereas it is foreseeable that some AI systems that were not included in these categories 
could lead to possible  claims and thus require a liability framework. While the GDPR and the future AI 
Act should  be consistent with one another, the EDPB wishes  to draw the Commission’s  attention on 
the possible legal void in which some AI systems could be left when they are neither considered high-
risk under the AI Act, nor covered by the GDPR.  

 

Yours sincerely, 

 

Andrea Jelinek 

 

