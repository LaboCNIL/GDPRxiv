

"Open Al altera l'identità personale e ascolta le nostre telefonate"
Intervista a Guido Scorza, componente del Garante per la protezione dei dati personali
(di Arcangelo Rociola, La Stampa, 1 aprile 2023)
"A OpenAi abbiamo chiesto di sospendere con effetto immediato il trattamento dei dati personali degli utenti italiani. Abbiamo agito autonomamente. Ora la società ha 20 giorni per adeguarsi". Guido Scorza dal 2020 è tra i componenti del Collegio dell'Autorità Garante per la protezione dei dati personali. La società che ha creato ChatGpt, secondo l'accusa, non rispetterebbe la legge europea e italiana sul trattamento dei dati. "Manca un'informativa, e questo è l'illecito che contestiamo alla società. Ma è evidente che c'è anche un altro tema: con ChatGpt e i chatbot si hanno colloqui, e in questi colloqui si tende spesso a condividere molto delle nostre vite".
Avvocato, cosa contestate a OpenAi?
"In particolare tre violazioni diverse: l'aver raccolto i dati personali di miliardi di persone per addestrare i propri algoritmi senza informarli di questa circostanza, verosimilmente senza disporre di un'idonea base giuridica; la raccolta di dati personali degli utenti nel corso delle conversazioni senza informarli della sorte di questi dati; infine di generare contenuti, in risposta alle domande, che talvolta attribuiscono alle persone fatti e circostanze inesatte e non veritiere distorcendo la loro identità personale".
Ci fa un esempio?
"Se chiedo al chatbot quando Guido Scorza è entrato nel Collegio del Garante per la privacy, la risposta è che questo è accaduto nel 2016, mentre io ci sono entrato nel 2020. Poco male in questo caso. Ma se invece dicesse che ho investito un bambino su un lungomare e sono poi scappato via e tale circostanza non fosse veritiera distruggerebbe la mia vita per sempre. E non credo si possa aspettare che accada".
Che effetti avrà il vostro provvedimento?
"Intanto OpenAi deve smettere di trattare i dati personali per addestrare gli algoritmi. Noi abbiamo adottato un provvedimento di urgenza, che si basa sulla presenza di un "fumus" di violazione, quindi non sulla certezza che ci sia un illecito, ma sull'apparente fondatezza di questo illecito".
Si può pensare che ChatGpt diventì inaccessibile in ltalia?
"Ordinare l'inaccessibilità a ChatGpt non rientra tra le nostre competenze. Se da domani ChatGpt riuscisse a lavorare senza trattare dati personali o a correggere il tiro rispetto alle violazioni che contestiamo, potrebbe rimanere accessibile".
Quindi ora cosa succede?
"Intanto è stata avviata un'istruttoria. Che comunque andrà avanti. Va accertato se c'è stata una violazione o no. La cosa migliore sarebbe farla insieme alla società, in questo caso OpenAi. Ma anche se non dovessero accettare di collaborare e fornirci le loro ragioni l'istruttoria andrebbe avanti".
ChatGpt è anche uno strumento usato da molti per fare domande, a volte intime, o che riguardano la sfera strettamente personale. È stato anche questo a indurvi a muovervi con urgenza?
"È una sintesi delle due cose. C'è il forte sospetto che ci sia un illecito e lo chiariremo con l'istruttoria. In questo caso l'illecito potrebbe avere conseguenze più gravi perché nell'ambito di una conversazione si è portati a condividere ancora di più cose che riguardano la sfera intima·".
Avete agito in modo autonomo o c'è un qualche tipo di coordinamento tra le autorità per la privacy europee?
"Autonomamente: OpenAi non ha sede in Europa. Ma nei prossimi giorni immagino ci sarà spazio per un confronto a livello europeo per capire se e come agire insieme".

