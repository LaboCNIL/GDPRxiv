

Scorza (Garante Privacy): "Contro OpenAI e ChatGpt provvedimento d'urgenza". Ecco cosa può accadere ora
Intervista a Guido Scorza, componente del Garante per la protezione dei dati personali
(di Arcangelo Rociola, Italian Tech, La Repubblica, 31 marzo 2023)
“Ad OpenAi abbiamo chiesto di sospendere con effetto immediato il trattamento dei dati personali degli utenti italiani. Abbiamo agito autonomamente. Ora la società ha 20 giorni per adeguarsi”. Guido Scorza dal 2020 è tra i componenti del collegio dell’autorità garante per la protezione della privacy. La società che ha creato ChatGpt, secondo il Garante, non rispetterebbe la legge italiana sul trattamento dei dati. “Manca un’informativa, e questo è l’illecito che contestiamo alla società. Ma è evidente che c’è anche un altro tema: con Chatgpt e i chatbot si hanno colloqui, e in questi colloqui si tende spesso a condividere molto delle nostre vite”.
Avvocato, cosa contestate a OpenAI?
“In particolare tre violazioni diverse: (a) aver raccolto i dati personali di miliardi di persone per addestrare i propri algoritmi senza informarli di questa circostanza e, verosimilmente senza disporre di un’idonea base giuridica, (b) raccogliere i dati personali degli utenti nel corso delle conversazioni senza informarli della sorte di questi dati e (c) generare contenuti, in risposta alle domande, che talvolta attribuiscono alle persone fatti e circostanze inesatte e non veritiere proponendo così una rappresentazione distorta della loro identità personale”
Ci fa un esempio?
“Se chiedo al chatbot quando Guido Scorza è entrato nel Collegio del Garante per la privacy, la risposta è che questo è accaduto nel 2016, mentre io ci sono entrato nel 2020. Poco male in questo caso. Ma se invece dicesse che ho investito un bambino su un lungomare e sono poi scappato via e tale circostanza non fosse veritiera distruggerebbe la mia vita per sempre. E non credo si possa aspettare che accada”.
Cosa comporta il vostro stop?
“Intanto OpenAi dovrebbe smettere di trattare i dati personali utilizzati per addestrare gli algoritmi. Noi abbiamo adottato un provvedimento di urgenza, che si basa sulla presenza di un ‘fumus’ di violazione, quindi non sulla certezza che ci sia un illecito, ma sull’apparente fondatezza di questo illecito. Occorrerà poi valutare in che modo risponderà la società nel corso dell’istruttoria appena avviata”.
Si può pensare a una ChatGpt inaccessibile in Italia?
“Ordinare l’inaccessibilità a ChatGpt non rientra tra le nostre competenze. Se da domani ChatGpt riuscisse, ad esempio, a lavorare senza trattare dati personali o a correggere il tiro rispetto alle violazioni che le contestiamo, potrebbe rimanere accessibile”.
Quindi cosa succede ora?
“Intanto è stata avviata un’istruttoria. Che comunque andrà avanti. Va accertato se c’è stata una violazione o no. La cosa migliore sarebbe farla insieme alla società, in questo caso OpenAI. Ma anche se non dovessero accettare di collaborare e fornirci le loro ragioni l’istruttoria andrebbe avanti”.
Quali sono gli scenari possibili?
“L’istruttoria potrebbe confutare i nostri sospetti di illiceità del trattamento di dati personali effettuato da OpenAI o viceversa confermarli. Nel primo caso c’è l’archiviazione. Nel secondo si potrebbero adottare dei provvedimenti, o correttivi o sanzionatori”.
Cosa succede se la vostra indagine dovesse confermare che OpenAI si comporta in modo illecito?
“Potremmo adottare un provvedimento correttivo,  e OpenAI potrebbe essere obbligata a cancellare i dati accumulati sugli utenti italiani, o a non raccoglierne più in futuro. O potremmo irrogarle una sanzione di natura economica fino al 2% o al 4% del fatturato della società a cui si contesta l’illecito a seconda la gravità dell’illecito”.
ChatGpt oltre a trattare e raccogliere dati, è uno strumento usato da molti per fare domande, a volte intime, o che riguardano la sfera strettamente personale. È stato anche questo a indurvi a muovervi con urgenza?
“È una sintesi delle due cose. C’è il forte sospetto che ci sia un illecito e lo chiariremo con l’istruttoria. In questo caso senza dubbio l’illecito potrebbe avere conseguenze più gravi perché nell’ambito di una conversazione si è portati a condividere ancora di più cose che riguardano la sfera intima. Ma di base c’è la violazione di una regola”.
Avete agito in modo autonomo o c’è un qualche tipo di coordinamento tra le autorità per la privacy europee?
“In questo caso abbiamo agito autonomamente perché OpenAi non ha sede in Europa ed è fuori dalle procedure di cooperazione, ma nei prossimi giorni immagino ci sarà senz’altro spazio per un confronto a livello europeo per capire se e come cooperare e agire insieme”.

