

Scorza: "Sulle regole AI l’Europa pone la prima pietra, ma sarà sfida enorme: ecco perché"
Intervento di Guido Scorza, componente del Garante per la protezione dei dati personali
(AgendaDigitale, 23 aprile 2021)
Quello presentato nei giorni scorsi dalla Commissione europea è il primo esercizio al mondo di regolamentazione "a tutto tondo" della protagonista indiscussa di una rivoluzione tecnologica il cui impatto sulla società è destinato a avere una magnitudine superiore rispetto a quella di Internet: l’intelligenza artificiale, qualsiasi cosa si intenda per davvero con questa espressione perché, per la verità, la stessa definizione contenuta nel draft del Regolamento è inevitabilmente ampia, generica, sfuggente.
La definizione di AI da parte della Commissione Ue
All’art. 3, i sistemi di intelligenza artificiale oggetto di regolamentazione, sono infatti definiti come "il software sviluppato con una o più delle tecniche e degli approcci elencati nell’allegato I e che può, per una data serie di obiettivi definiti dall’uomo, generare risultati quali contenuti, previsioni, raccomandazioni, o decisioni che influenzano gli ambienti con cui interagiscono".
Né le “tecniche e gli approcci” individuati nell’allegato I valgono a restringere, per davvero, in maniera significativa l’ambito di applicazione delle regole appena proposte dalla Commissione.
E, d’altra parte, chiunque abbia tentato di definire, in un contesto qualsiasi, l’intelligenza artificiale sa quanto sia difficile riuscire nell’impresa.
Non è un elemento di poco conto perché l’elasticità del perimetro di riferimento delle nuove regole le rende, inesorabilmente, ancora più centrali, importanti, rilevanti nel governo degli scenari tecnologici presenti e futuri.
È, infatti, davvero difficile pensare a applicazioni, servizi, dispositivi tecnologici disegnati, progettato, sviluppati, commercializzati e usati negli anni che verranno che, per un verso o per l’altro, non rientreranno nell’ambito di applicazione di tutte o alcune delle regole appena tratteggiate dalla Commissione nella sua proposta.
L’ambizione dell’Europa fa il paio col Gdpr
E questo, naturalmente, rende ancor più ambizioso l’esercizio appena avviato dalla Commissione e la sfida – perché anche di questo si tratta – lanciata al resto del mondo a seguire l’esempio europeo nella regolamentazione della materia come, almeno in parte, è accaduto e sta accadendo con la disciplina in materia di privacy cristallizzata nel celeberrimo GDPR, il Regolamento generale sulla protezione dei dati personali e sulla loro libera circolazione, nato a Bruxelles ma diventato rapidamente cittadino del mondo.
L’Europa ora ci riprova.
E, forse, è anche per questo che l’approccio seguito dalla Commissione europea nella proposta di regolamentazione ricorda molto da vicino quello alla base della disciplina in materia di privacy con la quale le disposizioni contenute nella proposta di regolamento condividono, evidentemente, un patrimonio cromosomico comune.
E’ un patrimonio genetico che ruota attorno all’esigenza che l’intelligenza artificiale sia antropocentrica e che i diritti fondamentali – richiamati non a caso già nel primo considerando della proposta di Regolamento – rappresentino uno steccato chiamato a orientare la corsa del progresso tecnologico.
Analogie con disciplina privacy
Ma affondano le loro radici nella stessa disciplina sulla privacy anche molti degli strumenti di regolamentazione: alcuni divieti all’uso di talune applicazioni derogabili in un numero limitato di ipotesi e, comunque, all’esito di un bilanciamento tra diritti e interessi contrapposti, un meccanismo di regolamentazione secondaria e controlli affidato a un sistema, tutto da costruire, di autorità amministrative indipendenti che dovranno coordinarsi a livello europeo, un ampio spazio lasciato alle certificazioni, una serie di stringenti obblighi di trasparenza in capo a chi progetta, sviluppa e commercializza le intelligenze artificiali e a favore dei loro utenti, alcune forme di “vaccinazione obbligatoria” degli algoritmi e, soprattutto, dei dati usati per addestrarli contro il rischio di discriminazioni e errori capaci di produrre pregiudizi alle persone, le valutazioni di impatto.
Sembra, davvero, di leggere un nuovo regolamento generale sulla protezione dei dati personali sottoposto a un esercizio di astrazione, dal particolare al generale, dal governo dei soli – si fa per dire – dati personali al governo degli algoritmi, dei dati – personali e non utilizzati per garantirne il funzionamento – e delle decisioni assunte dalla combinazione, appunto, di dati e algoritmi.
E’ davvero il metodo privacy applicato all’intelligenza artificiale e si tratta, probabilmente, di un aspetto confortante perché per quanto, naturalmente, il GDPR abbia limiti evidenti e sia lontano dal potersi considerare perfetto è, però, universalmente – o quasi riconosciuto – un esercizio regolamentare illuminato.
Ma siamo al giorno zero di un iter normativo ancora lungo a livello europeo e poi a livello nazionale dove le nuove regole, allo stato, sembrano destinate a diventare applicabili ventiquattro mesi dopo l’entrata in vigore del Regolamento.
Ci vorranno tre anni perché diventi legge
Difficilmente meno di tre anni da oggi.
Sarà il 2024, magari il 2025 se, come non può essere escluso, qualche ostacolo lungo la strada lo si incontrerà.
E il fattore tempo non è secondario nel governo di fenomeni come quello in questione che si evolvono, trasformano, mutano pelle, ormai, nell’ambito di mesi, settimane talvolta semplicemente perché una particolare applicazione tecnologica – spesso neppure la più straordinaria dal punto di vista strettamente tecnico – si impone sul mercato per semplicità d’uso, utilità, appeal o, persino, design.
Le prime macchine a guida autonoma – o, almeno, semi autonoma – sono già sulle nostre strade e le affolleranno nei prossimi anni, le nostre case sono già piene zeppe di dispositivi intelligenti, i social network utilizzano da tempo algoritmi e soluzioni che rientrano nella definizione di intelligenza artificiale che perimetra l’ambito di applicazione della proposta di regolamento, i nostri smartphone hanno a bordo assistenti vocali intelligenti e governi e soggetti privati utilizzano o provano a utilizzare soluzioni di intelligenza artificiale dal riconoscimento facciale allo scoring reputazionale che, giustamente, la Commissione propone di mettere, salvo eccezioni, fuori legge.
Che succederà nei prossimi tre o quattro anni?
Le nuove regole saranno in grado di governare fenomeni che nei laboratori, nei mercati, nella società saranno frattanto andati così tanto avanti, si saranno affermati, avranno fallito, avranno cambiato completamente pelle?
Questo dobbiamo necessariamente chiedercelo.
Così come dobbiamo chiederci cosa accadrà domani.
Quale sarà l’impatto dell’annuncio della Commissione europea e della pubblicazione di una proposta di regolamentazione che, tuttavia, non sarà legge nel breve?
I rischi dell’attesa
C’è il rischio che si crei incertezza giuridica e che il mondo si divida tra quanti, in qualche modo, potrebbero “adeguarsi” anzitempo alle nuove indicazioni regolamentari e quanti, invece, peraltro legittimamente, le ignorino.
E, naturalmente, i primi potrebbero perdere capacità competitiva sui mercati a vantaggio dei secondi.
E tutto questo ha anche un impatto geopolitico non secondario perché è inutile girarci attorno: regole diverse – anche se solo annunciate – tra Stati Uniti, Europa e Cina, rispetto a un mercato che è per definizione globale, determinano inesorabilmente vantaggi e svantaggi straordinariamente significativi per gli uni, l’altra o l’altra ancora.
E quanto sia dannosa l’incertezza giuridica determinata dall’annuncio di un intervento regolamentare che poi tarda a arrivare ce lo racconta, ancora una volta, l’esperienza della disciplina in materia di protezione dei dati personali con quel draft di Regolamento sulla privacy nella comunicazioni elettroniche noto agli addetti ai lavori come Regolamento E-Privacy che avrebbe dovuto entrare in vigore lo stesso giorno del Regolamento generale sulla protezione dei dati personali e che, invece, oggi, tre anni dopo, è ancora solo una proposta ostaggio della politica europea, degli interessi enormi degli stakeholder i cui servizi sono destinati a cadere nell’ambito di applicazione delle nuove regole e dei processi normativi per definizione – e spesso necessariamente – lunghi e articolati, troppo rispetto al ritmo del progresso tecnologico e alle cose che accadono sui mercati.
Ma nel caso del draft del Regolamento e-privacy, almeno, si tratta “solo” di nuove regole destinate a aggiornare delle regole che già ci sono e, per di più, nell’ambito di un framework di regolamentazione generale della materia – quello disegnato dal GDPR – che perimetra già con sufficiente chiarezza almeno i principi a cui ispirare i trattamenti di dati personali anche nell’universo delle comunicazioni elettroniche.
Nel caso delle nuove regole per l’intelligenza artificiale è diverso perché, ancora una volta, i soli riferimenti esistenti sono le poche norme che lambiscono il tema contenuti proprio nello stesso Regolamento generale sulla protezione dei dati personali.
Di più non c’è.
E, quindi, un imprenditore europeo o anche extra-europeo ma che voglia fornire i suoi servizi anche in Europa cosa dovrebbe fare, per esempio, rispetto alle applicazioni di intelligenza artificiale che la proposta di regolamento classifica come vietate salve eccezioni?
Il problema esiste e, probabilmente, andrebbe affrontato perché viviamo in un’epoca nelle quali una manciata di mesi di asimmetria normativa genera impatti economici e democratici straordinari.
Ma questioni di metodo e impatto a parte, veniamo al merito della proposta di regolamentazione e, in particolare, a qualche dubbio e perplessità sulle soluzioni identificate per risolvere questioni e problemi che, pure, sono indiscutibilmente reali, importanti e urgenti.
Un limite: l’elenco di app ad alto rischio
Qualche perplessità, innanzitutto, solleva l’idea, pure centrale nella struttura della proposta della Commissione di redigere, oggi per domani – e si è già detto quanto quel domani potrebbe essere lontano – un elenco, per quanto suscettibile di modifiche e aggiornamento, di applicazioni di intelligenza artificiale più ad alto rischio di altre e per questo sottoposte a una disciplina più rigorosa e un elenco di applicazioni vietate salvo laddove autorizzate espressamente dalla legge.
Si tratta, probabilmente, di un esercizio troppo ambizioso specie davanti a un contesto tecnologico e di mercato dai confini in così rapido e costante movimento.
Nessuno, infatti, può escludere che ciò che oggi – allo stato della tecnica – appare più pericoloso domani lo sia meno di qualcosa che oggi appare meno pericolosa e viceversa.
E, allora, forse si potrebbe pensare di generalizzare semplicemente il pure previsto meccanismo delle valutazioni di impatto ereditato dalla disciplina generale sulla privacy, stabilendo che qualora il produttore o fornitore di un servizio non sia in grado di adottare e documentare – appunto nella valutazione – accorgimenti che consentano di eliminare o abbattere fino a una soglia di sostenibilità sociale e democratica taluni rischi del genere di quelli che, attualmente, valgono a inserire le soluzioni nella lista nera, abbia bisogno, prima di procedere, di un confronto con la competente autorità di regolamentazione e vigilanza che potrebbe legittimare o meno, a seconda dei casi, eventualmente anche imponendo l’adozione di taluni correttivi, la prosecuzione dell’attività.
Il limite dell’obbligo alla trasparenza
E, egualmente, qualche dubbio, per la verità, suscita l’approccio al problema della c.d. trasparenza degli algoritmi – sebbene la questione sia come nota più complicata di così e più che alla trasparenza in senso tecnico attenga alla effettiva comprensibilità delle loro dinamiche di funzionamento – nei confronti degli utenti delle soluzioni di intelligenza artificiale.
Le relative disposizioni presenti nella proposta di Regolamento, infatti, ricalcano pedissequamente l’approccio tradizionale della disciplina consumeristica e, più di recente, di quella in materia di protezione dei dati personali: imporre alle parti forti del rapporto obblighi di informazione nei confronti delle parti deboli.
Questo approccio, tuttavia, ha fatto il suo tempo.
Nella società dell’accetta e continua, nessuno legge più le chilometriche condizioni generali di contratto e informative per la privacy che i fornitori di servizi digitali ci propongono online con la conseguenza che tale sistema non vale a rendere le parti deboli del rapporto più consapevoli mentre vale a consentire alle parti forti di poter sempre eccepire a utenti e consumatori di aver adempiuto ai propri obblighi di informazione.
Non c’è ragione di ritenere che lo stesso approccio abbia maggior fortuna nell’universo dell’intelligenza artificiale dove le informazioni da trasferire agli utenti in relazione alle logiche di funzionamento degli algoritmi sono più numerose e complesse.
Difficile immaginarsi soluzioni alternative certamente efficaci ma, probabilmente, si potrebbe e dovrebbe pensare a qualche misura che valga a garantire effettivamente – e non solo nella dimensione formale – che cittadini, utenti e consumatori prima di iniziare a utilizzare una soluzione di intelligenza artificiale siano informati circa la logica di funzionamento degli algoritmi alla base di tali soluzioni, i dati trattati per l’adozione delle decisioni, i rischi e i limiti connessi al loro uso.
Il problema della governance
C’è poi il grande tema della governance della materia. Gli artt. 56 e ss della Proposta prevedono l’istituzione di un “European Artificial Intelligence Board” nel quale siedono i rappresentanti delle autorità di controllo nazionali e del Garante europeo per la protezione dei dati. Il Board ha essenzialmente compiti di coordinamento delle autorità nazionali, di ausilio all’attività della Commissione e di assistenza sia alla Commissione che alle predette autorità nazionali con riferimento alle questioni emergenti nel mercato interno in seguito all’entrata in vigore del regolamento del quale ne garantisce l’uniforme applicazione.
Qui qualche domanda sorge spontanea.
Anche considerato che, come si è detto, il fattore tempo non è secondario, serve davvero un nuovo board europeo dedicato all’intelligenza artificiale e una nuova rete di autorità competenti anche a livello nazionale?
O, forse, si potrebbe pensare di estendere al governo dell’intelligenza artificiale le competenze delle autorità di protezione dei dati personali ovviamente dotandole delle necessarie risorse umane e materiali.
In fondo il metodo scelto per governare l’intelligenza artificiale è proprio quello già scelto per governare la privacy ­- come anche si evince dal ruolo e dalle competenze che, a livello europeo, vengono riconosciute al Garante europeo per la protezione dei dati (European Data Protection Supervisor) inserito d’ufficio nel nuovo board per l’intelligenza artificiale – e la più parte delle questioni da governare riguardano profili sovrapponibili o, almeno, contigui a quelli che già rientrano nella competenza delle autorità europee di protezione dei dati personali.
In conclusione
Ma, appunto, siamo solo all’inizio di un iter normativo ancora lungo e tortuoso e mentre è troppo presto per esprimere giudizi è, il momento giusto, per prendere atto del fatto che il vecchio continente tanto “vecchio” evidentemente non è, è sul pezzo rispetto alla sfida delle sfide nel governo del futuro: ci siamo posti il problema e stiamo lavorando alla ricerca di una soluzione rispettosa dei nostri valori più profondi.
C’è tempo per far meglio ma l’inizio è già confortante e, in ogni caso, iniziare a scrivere su un foglio bianco è enormemente più difficile che proporre di rivedere o correggere un paio di righe già scritte.

