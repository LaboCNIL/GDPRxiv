

Fake news, Cerrina Feroni (Garante privacy): “Cosa fare contro la dittatura del pensiero dominante”
La Rete presenta sfide e pericoli che devono essere contrastati laddove interessi generali siano a rischio. E i rischi maggiori per la democrazia stanno nel contenitore e non nei contenuti. Il compito di determinare cosa sia vero o falso non può quindi essere appannaggio delle piattaforme ma serve un coinvolgimento corale
Intervento di Ginevra Cerrina Feroni, vice Presidente del Garante per la protezione dei dati personali
(AgendaDigitale, 18 gennaio 2023)
È difficile, forse impossibile, circoscrivere e sviluppare in maniera sufficientemente esauriente argomenti che, in pochi anni, hanno subito una esplosione tale a quello delle fake news: opinione pubblica, studiosi, istituzioni riservano infatti molto interesse alla categoria e il tema è divenuto una delle questioni più dibattute nel mondo dell’informazione e della politica.
Fake news, libertà di espressione e democrazia
In un recente libro dal titolo provocatorio “Finché ci sono fake news c’è speranza”, l’Autore Carlo Magnani ricostruisce l’origine “politica” del fenomeno e la colloca al 2016 quando la Brexit, le presidenziali Usa e il referendum costituzionale in Italia hanno prodotto esiti del tutto inaspettati da parte dei commentatori d’allora. Da qui l’allarme sulle fake news che avrebbero adulterato il genuino processo di formazione delle idee fuorviando gli elettori[1].
A questa inedita attenzione rispetto alla veridicità dei contenuti diffusi si è aggiunta quella verso i mezzi di diffusione: sotto accusa sono finiti i nuovi media, i social, stigmatizzati, per il grado di libertà che lasciano ai propri utenti, come veicoli privilegiati della circolazione delle “bufale”.
Le istituzioni statali e sovranazionali hanno raccolto la comune apprensione promuovendo politiche di contrasto alla disinformazione mediante accordi con i grandi operatori della Rete (Commissione europea) e attraverso leggi o interventi delle autorità interne di regolazione (Germania, Francia). In epoca di pandemia, poi, si sono moltiplicate le azioni di contrasto alle fake news in ambito sanitario: si pensi ai vari tavoli – per l’Italia incardinati presso la Presidenza del Consiglio e l’Autorità Garante delle Comunicazioni – con compiti di analisi e monitoraggio dell’informazione diffusa relativamente al Covid, anche tramite il coinvolgimento dei principali motori di ricerca e delle piattaforme social.
Tema, quest’ultimo, assai rilevante considerato il ruolo decisivo assunto dalle piattaforme non solo nella definizione dei confini di ciò che è ammissibile (o non ammissibile) sostenere nel dibattito pubblico in merito ai vaccini – e che ha condotto a veri e propri silenziamenti di opinioni scientifiche “non allineate” – ma addirittura, sembrerebbe, nella rimozione delle informazioni più scomode sugli effetti dei farmaci a mRna[2].
Ma soffocare il dibattito scientifico è in sé un ossimoro, poiché il metodo scientifico non si concilia con il dogmatismo, ma al contrario con il pluralismo delle opinioni, che diventano, di volta in volta, ipotesi da studiare e da convalidare.
Non vi è dubbio che non devono sottovalutarsi i rischi della disinformazione, specie su un tema delicato come il Covid-19, perché ciò determina confusione, influenza le persone a cercare trattamenti illusori, mina l’efficacia delle strategie messe in atto dalla autorità sanitarie[3].
Ma proprio per questo l’effetto è dirompente (in senso negativo), sotto il profilo della fiducia dei governati nei confronti dei governanti, quando le informazioni bollate come fake news e, dunque, puntualmente censurate, risultino poi, all’evidenza dei fatti, tutt’altro che fake. Incontrovertibile oggi un dato: lo sgretolarsi, purtroppo, del racconto ufficiale che ha fatto da pietra angolare all’intero impianto della campagna vaccinale, ovvero che i vaccinati divengono per ciò solo “immuni”, che hanno la garanzia di ritrovarsi in ambiente sicuro, e che non possono trasmettere il Covid-19[4].
Il tema è, dunque, da maneggiarsi con estrema cautela, proprio perché tocca il cuore della democrazia, ovvero la libertà di espressione del pensiero, nel senso che se la disinformazione manca, deve accendersi una spia di allarme perché significa che la verità è solo nelle mani di chi decide, ossia del regime. E non è detto, appunto, che i giudizi di ciò che è vero e di ciò che è falso, secondo il potere in quel momento in carica, siano sempre affidabili, sicché – come è stato ben sottolineato – «un sistema che voglia davvero proteggere la libertà di espressione deve impegnarsi anche a proteggere le falsità»[5].
Accade così – come ricorda ancora Magnani – che la complessa fenomenologia della comunicazione digitale finisca per alimentare una sorta di pessimismo sulle condizioni, e sulla sorte, tanto della libertà d’espressione che della democrazia. Paiono oggi, quantomeno più lontani, i tempi delle visioni idealiste di internet come strumento di libertà e di partecipazione politica e civica.
Il punto è che questo allarmismo, pur se animato da nobili fini, rischia di suggerire rimedi che non sono meno problematici dei mali che dovrebbero curare. Per correggere il disordine informativo odierno si assiste, così, alla coerente proposizione di una «nuova politica della verità»[6], dove la categoria della verità si riverbera nel paternalismo democratico considerato, sovente, l’antidoto al populismo digitale.
Quale definizione per le fake news?
Un primo elemento di complicazione, come abbiamo sopra accennato, è determinato dalla nozione stessa di fake news, i cui confini giuridici ambigui la rendono talvolta strumentalizzabile e foriera del rischio, non peregrino, che il ricorso a tale espressione diventi un modo per limitare la libertà del pensiero e il dibattito pubblico (il che risulta evidente fin dalla complessità intrinseca alla definizione, che fa riferimento a notizie che si assumono volutamente tendenziose e/o false)[7].
Seppur vago, si tratta comunque di un fenomeno che presenta dei profili di reale interesse, tanto più in un momento di forti tensioni internazionali come quello che stiamo vivendo: di non molto tempo fa è la notizia che il fondatore della compagnia Wagner ha ammesso, anzi rivendicato, il suo ruolo nelle campagne di disinformazione per il voto americano del 2016.
Più specificamente, il fenomeno può essere inserito nelle dinamiche di quello che è stato definito information disorder, ossia la divulgazione di notizie, non necessariamente false, attraverso modalità idonee a inquinare ugualmente l’ecosistema informativo[8].
Il concetto di fake news ricomprende in sé categorie diverse:
misinformation, che si verifica quando contenuti falsi vengono diffusi accidentalmente da utenti inconsapevoli, convinti di divulgare contenuti che corrispondono a un reale interesse sociale.
malinformation, quando informazioni veritiere vengono pubblicate con lo specifico scopo di creare conseguenze avverse.
disinformation, laddove il contenuto della notizia diffusa è intenzionalmente falso e trasmesso ad hoc per causare conseguenze dannose.
Invero, come già anticipato, la difficile individuabilità dei suoi presupposti e condizioni richiede che l’approccio al problema delle fake news, come potenziale categoria giuridica, sia accompagnato da un’estrema prudenza interpretativa. Questa stessa prudenza ci porta a concludere come solo nel primo e nel terzo caso possiamo parlare effettivamente e in senso stretto di fake news[9].
Va poi rilevato che il fenomeno delle fake news si basa su un paradosso di fondo, quello per cui la libertà d’espressione trova il suo confine non tanto nella tutela dei diritti dei terzi, ma soprattutto nel cattivo uso che si farebbe della libertà stessa ed è perciò che sembra ragionevole inserirlo all’interno della categoria dell’abuso del diritto. La nozione di fake news, infatti, non include le informazioni e le notizie che sono già vietate per effetto di altre norme “tipiche”, come ad esempio quelle sulla diffamazione, sull’incitazione a delinquere o sulla propaganda razzista.
Il focus è, pertanto, su notizie non veritiere che, anche se messe in circolazione da persone consapevoli di tale falsità, non sono di per sé illecite per altre ragioni.
Questa precisazione è importante perché spalanca le porte ad una sostanziale indeterminatezza della fattispecie e conduce a chiedersi quali siano i requisiti giuridici che una manifestazione in tal senso dovrebbe incontrare non solo per poter essere qualificata come fake news, ma anche per poter essere censurata.
La vaghezza e l’ambiguità del concetto, e i confini giuridici ancora in massima parte oscuri, sono stati sottolineati anche dallo High Level Group della Commis­sione europea sulle fake news e la disinformazione online che, nel suo Rapporto pubblicato a marzo del 2018, rileva come il termine fake news sia stato oramai distorto nel dibattito pubblico e che non sia adeguato a catturare la complessità di un fe­nomeno che coinvolge anche una serie di pratiche come l’uso di account automatizzati, la creazione di reti di fake followers, la pubblicità mirata, il trolling organizzato ed altre pratiche dagli elementi soggettivi e oggettivi e dagli scopi molto diversi tra loro.
C’è, infine, chi ha sostenuto che la lotta contro la disinformazione possa essere assimilabile a uno strumento di democrazia protetta e, se ciò fosse vero, il problema richiederebbe di essere considerato con ulteriore cautela, date le due generali – e talvolta problematiche – caratteristiche del concetto di democrazia protetta: l’anticipazione della tutela e la repressione del dissenso ideologico.
Decentramento informativo e fake news
Legata a doppio filo con il problema delle fake news è la dibattuta questione sulla regolamentazione del web. Perché?
Perché sebbene la diffusione di notizie false non sia nata con il web, è grazie allo sviluppo del digitale e dei social che tale fenomeno ha visto un rapido aumento e aggravamento. Le piattaforme, infatti, hanno spezzato il filtro offerto dai professionisti dell’informazione e dai loro strumenti di garanzia, consentendo a qualsiasi soggetto, anche quelli che secondo lo schema tradizionale del rapporto informativo sarebbero stati meri fruitori, di contribuire personalmente alla produzione e divulgazione di informazioni. Questo fenomeno, conosciuto come decentramento informativo, è stato ed è tuttora promosso dalle piattaforme che, come è noto, nascono proprio come mezzi di intermediazione neutri.
Basti ricordare che lo slogan di WordPress.com è «democratize publishing», mentre Facebook ha come scopo quello di «give people the power to share and make the world more open and connected». Ancora, Google si propone di «organize the world’s information and make it universally accessible and useful».
Ma i vantaggi che indiscutibilmente vengono offerti ai cittadini, le nuove opportunità di accedere alle informazioni senza intermediari di contenuto, di esprimere opinioni e partecipare ai processi democratici, dalla celebre sentenza Google Spain in poi (2016), hanno iniziato poco a poco a fare i conti con i problemi che questa mancanza di intermediazione ha portato con sé, portando così a ciò che è comunemente conosciuto come la responsabilizzazione delle piattaforme e lo spostamento dal governo pubblico al governo privato, dal rule of law, appunto, il “governo del diritto” al rule of platforms.
Il Rule of platforms
Questo fenomeno, è bene ricordarlo, non si è sviluppato esclusivamente per scelta delle piattaforme. Al contrario, in alcuni casi questo potere appare agli stessi social fin troppo ingombrante. È significativo, a tal proposito, ciò che disse Mark Zuckerberg inaugurando il progetto per il nuovo sistema di governance dei contenuti online nel 2018 da cui poi scaturì il Facebook Oversight Board: “Facebook should not make so many important decisions about free expression and safety on our own”.
Eppure, proprio di recente abbiamo assistito a un caso emblematico di applicazione di quello che abbiamo definito rule of platforms: il nuovo CEO di Twitter, Elon Musk ha sottoposto un sondaggio agli utenti del social con il quale chiedeva loro se fossero o meno d’accordo sulla riammissione di Donald Trump su Twitter. L’esito favorevole di appena due punti percentuali ha decretato la reintegrazione dell’ex Presidente statunitense il quale comunque, poco dopo, ha escluso un suo ritorno sulla piattaforma.
Ciò che qui rileva è che il governo privato della libertà di espressione ci spinge, oggi più che mai, a domandarci in che modo le democrazie costituzionali possano combattere la marginalizzazione del rule of law nello spazio digitale o, in altre parole, come sia possibile strutturare i meccanismi di governance della Rete in modo tale da non alterare la natura dei social media, preservandone il più possibile la mutazione da meri intermediari in veri e propri produttori di contenuto e decisori dell’infosfera[10].
Un potere, questo, il cui consolidamento non ha trovato indifferente l’Unione europea, che attraverso il Digital Services Act, intende proprio mitigare le sfide costituzionali sollevate dal governo privato della Rete.
In questa prospettiva l’Unione sembra avere abbandonato l’approccio neoliberale, a cui, ad esempio, sono profondamente ancorati gli Stati Uniti, per valorizzare la matrice dignitaria della libertà di espressione. Se questo è certamente coerente con l’impianto costituzionale della maggior parte dei Paesi europei, non si può evitare di notare il duplice pericolo che questo metodo porta con sé: una eccessiva responsabilizzazione delle piattaforme e una ipervalutazione di interessi che rischiano di scollarsi dalla reale e concreta esigenza di protezione democratica e, quindi, di porsi come uno strumento di repressione ideologica tout court.
Si pensi al caso dell’estromissione delle frequenze di Russia Today, che ha trovato il suo coronamento nella decisione del Tribunale dell’Unione europea del 27 luglio 2022, secondo cui le esigenze di tutela del “public health”, cioè di mantenere una sorta di ambiente democraticamente “sano” contro le fake news che rifluiscono sugli Stati membri, hanno giustificato la censura dell’emittente russa.
Le reazioni e le omissioni costituzionali nei confronti del governo privato della libertà di espressione mostrano come, in virtù della condivisione dei principi e capisaldi di un sistema democratico, sia sempre più necessario fornire un nuovo quadro giuridico di responsabilità delle piattaforme attraverso nuovi obblighi procedurali per quelle azioni che coinvolgono la portata della libertà d’espressione e questo, non da ultimo, al fine di sollevare le stesse piattaforme dalla difficile posizione in cui si trovano adesso.
In mancanza di regole chiare, un naturale chilling effect legato alla paura di ripercussioni sia di natura legale sia, soprattutto, economica, ha portato poco alla volta le piattaforme a restringere libertà di espressione. Non si può, infatti, far finta di non vedere in che significativa misura incida l’interesse economico alla tutela dell’immagine aziendale nella scelta di censurare alcuni commenti borderline per impedire la dis-iscrizione di molti utenti delusi o feriti proprio da quegli stessi post.
I Provider, nati con lo scopo di fornire un accesso alle principali reti di comunicazione elettronica e di consentire la diffusione passiva di contenuti, hanno dunque mutato con il tempo la propria funzione, abbandonando, via via, la propria veste di “intermediari neutri” in favore di un ruolo maggiormente attivo che si sostanzia nell’intervento concreto sui contenuti pubblicati dagli utenti allo scopo di aumentarne la visibilità, incrementarne le potenzialità di interazione e consentire maggiori possibilità di diffusione.
Il “giudice algoritmo”
Vi è però un ulteriore profilo problematico. È noto che le cosiddette Big Tech selezionano, seppur con procedimenti automatizzati, le informazioni da rimuovere o da proporre per prime ai singoli utenti attraverso l’utilizzo di algoritmi capaci di adeguarle alle preferenze espresse dagli utenti durante la “navigazione” sul web[11]. Ma l’utilizzo di profilazione algoritmica dei dati alimenta una bubble informativa “customizzazata” che rischia, oltre che violare la privacy degli utenti, di deformare la reale estensione del quadro delle loro opinioni e visioni, poiché il criterio di selezione delle notizie non è più l’attendibilità e l’affidabilità, ma la mera preferenza[12].
Ciò ovviamente produce anche il fenomeno per cui l’algoritmo permette che contenuti paradossali o controversi (perché violenti, offensivi o semplicemente falsi), che eccitano la curiosità degli utenti, siano ricompensati da molte visualizzazioni[13].
In una prospettiva più generale, invece, la profilazione algoritmica pone problemi di trasparenza e di neutralità nella Rete che, a loro volta, potrebbero compromettere la libertà di espressione. Questo rischio – che è insieme di eccessiva e di insufficiente responsabilizzazione – è portato all’ennesimo grado proprio dall’utilizzo in via esclusiva o, comunque, preponderante dell’algoritmo.
Il metodo automatizzato, se da un lato porta innegabili vantaggi, come il fatto di affrontare problemi su larga scala e di sollevare i moderatori dal costo psicologico di guardare continuamente immagini cruente e, infine, di rappresentare talvolta l’unico strumento che può rivelare alcuni tipi di contenuti, come ad esempio i deep fake generati dall’intelligenza artificiale, dall’altro non convince del tutto.
Ciò per almeno due ordini di ragioni:
I) può determinare alcuni grossolani errori e distorsioni frutto dei bias dei suoi programmatori privi della sensibilità (sociale, politica, umana) necessaria per distinguere le differenti situazioni;
II) sul lungo termine, rischia di deresponsabilizzare i moderatori umani.
Proprio con riferimento alla procedura algoritmica si capisce come un confronto proficuo su questi temi richieda non solo uno scambio tra stakeholders e teorici, ma anche una profonda interdisciplinarietà di approccio, un confronto tra esperti di ambiti diversi che parta dall’analisi del funzionamento delle piattaforme e arrivi a indagare le prospettive a lungo termine relativamente alla tenuta dei capisaldi democratici e dei diritti fondamentali.
In questo sistema, il principio espresso per la prima volta dal giudice della Corte Suprema degli Stati Uniti, William O. Douglas, nella decisione del caso United States v. Rumely nel 1953, del “mercato” dell’informazione come free marketplace of ideas (ritenuto un principio cardine della manifestazione del pensiero e della circolazione di informazioni su internet) entra oggi in crisi a causa di due fattori: da una parte, l’alto numero di notizie a cui l’utente è sottoposto che spesso gli impedisce di controllare la loro attendibilità o, più semplicemente, di approfondirle; dall’altra parte, il problema della profilazione algoritmica delle notizie sopra affrontato che minaccia il suo diritto a una libera informazione, nonché rende più difficoltosa l’effettuazione di verifiche sulle notizie profilate fornite dall’algoritmo.
A causa del miglioramento computazionale degli algoritmi, infatti, può dirsi concretizzato quanto paventato da Nicholas Negroponte che, già nel 1995, utilizzò l’espressione ‘Daily Me’ per descrivere un giornale virtuale “su misura” per ogni persona: un contesto informativo nel quale l’utente ha accesso esclusivamente alle notizie inclini alle proprie idee[14].
Ma gli effetti pregiudizievoli non si limitano al diritto alla privacy e alla libertà di informazione, estendendosi anche alle relazioni umane: group polarization è la propensione umana ad instaurare legami sulla base di affinità con individui simili che, come avviene all’interno dei social network, contribuisce ad alimentare camere di risonanza, dove le opinioni rischiano di radicalizzarsi e cristallizzarsi, con un netto impoverimento del clima in punto di pluralismo.
La tecnologia come antidoto alle possibili distorsioni tecnologiche
Se, come rappresentato, dall’utilizzo degli algoritmi derivano una serie di questioni problematiche, è pur vero che la stessa tecnologia può dare un grande apporto all’individuazione di fake news e, negli ultimi tempi, i sistemi automatizzati di riconoscimento ai fini di moderazione, aggiornati e perfezionati, permettono, in particolare se combinati tra loro, una maggiore precisione nell’individuazione della cattiva informazione. Apporto fondamentale, ad esempio, è quello portato dal Natural language processing, branca a metà tra linguistica e informatica finalizzata alla creazione di reti neurali digitali che permettano all’algoritmo di comprendere il significato del testo che esso analizza[15]. Tale facoltà dovrebbe permettere all’algoritmo di contestualizzare maggiormente il contenuto dell’informazione. L’efficienza computazionale “incosciente” fornisce senza dubbio dati oggettivi e presenta in un carattere estremamente impersonale informazioni che possono aiutare a raggiungere la verità.
Tuttavia, sulle modalità con cui questo può avvenire non devono essere fatte semplificazioni: gli algoritmi restano, infatti, sistemi indiretti per l’analisi del contenuto delle notizie che si basano su fondamenti statistico-probabilistici elaborati da una coscienza “anonima” e perciò non sempre rispecchiano le nostre vere intenzioni. L’algoritmo è di estrema utilità laddove l’“interferenza” umana sia da esso riconosciuta e accettata, laddove cioè esso sia ricondotto alla sua vera dimensione di mezzo e non di fine.
Conclusioni
Il fenomeno dell’information disorder non può, dunque, essere affrontato esclusivamente con un approccio tecnologico (quindi solo con l’utilizzo di algoritmi per il fact checking o per la content moderation). Non è possibile nemmeno sostenere che la disciplina del controllo umano possa essere totalmente appaltato all’autoregolamentazione delle singole piattaforme, laddove queste ultime siano influenzate, nella loro azione, da considerazioni legate a dinamiche prettamente economiche che le spingono a preferire la censura per fidelizzare gli utenti e non perdere fatturato. Appare quindi importante, accanto alla partecipazione attiva delle piattaforme, favorire il processo di riappropriazione del loro ruolo di intermediari neutrali che era alla base dell’implicito statuto della Rete.
La Rete presenta sfide e pericoli che non possono essere taciuti e che devono essere contrastati laddove interessi generali siano a rischio. Ma i rischi maggiori per la democrazia, a ben vedere, stanno nel contenitore e non nei contenuti, sono cioè nel mezzo.
I grandi operatori delle piattaforme sono i veri proprietari della sfera pubblica, che governano con strumenti algoritmici automatici che sfuggono al controllo diretto e il governo delle fake news rischia di diventare uno strumento troppo malleabile e di essere strumentalizzato da una parte o dall’altra a seconda della convenienza.
In tal senso, sono illuminanti le parole della Corte Suprema Statunitense che nel caso United States vs. Alvarez del 2012 ha rifuggito, come è suo costume, la via repressiva, valorizzando l’approccio dialogico, anche in riferimento alla disinformazione. Nel dichiarare contraria al Primo Emendamento una legge che puniva chi affermasse falsamente di aver conseguito una decorazione – affermava: “il rimedio contro le dichiarazioni false sono le dichiarazioni vere. All’irrazionale si risponde con il razionale, al disinformato con l’illuminato, alla palese menzogna con la semplice verità. La teoria che sta alla base della nostra Costituzione è che il miglior test di verità è la capacità del pensiero di farsi accettare nella competizione del libero mercato [del pensiero] e qualsiasi soppressione del­la libertà di parola da parte del Governo rende l’esposizione delle falsità non più facile, ma più difficile!”.
Nel contesto digitale e informativo non è dunque sufficiente, per garantire il rispetto della pluralità e della verità dell’informazione, che siano vietate determinate pratiche. Non possiamo limitarci ad un approccio prescrittivo o tecnologico e nemmeno ad appaltare a presunti “terzi esperti” il compito di determinare cosa sia vero o falso. È invece indispensabile adottare un approccio attivo, plurale, che non si traduca in quella che Tocqueville definì “dittatura della maggioranza” e che oggi potremmo ribattezzare come “dittatura del pensiero dominante”.
 
Note
1- C. Magnani, Finché ci sono fake news c’è speranza: libertà di espressione, democrazia, nuovi media, Rubbettino Università, Roma, 2021, p. 4. 
2- Ne parla A. Rico, Vaccini, Facebook censurava le notizie vere, in LaVerità, 10 gennaio 2023.
3 - S. Sassi, Disinformazione contro Costituzionalismo, Napoli, ES, 2021, 105.
4 - Per l’impatto che ha avuto, non si può non ricordare, su tutte, la dichiarazione del Presidente del Consiglio Mario Draghi nella conferenza stampa del 22 luglio 2021. 
5 - S. Sassi, op, cit., 212 per la quale l’unica eccezione al principio è che l’autorità pubblica dimostri che le falsità siano diffuse con l’intenzione di provocare un serio danno ai valori democratici nel loro complesso.
6 -C. Magnani, op. cit., p. 96. 
7- H. Allcott, M. Gentzkow, Social Media and Fake News in the 2016 Election, in Journal of Economic Perspectives, Volume 31, n. 2, 2017, p. 213.
8 - R. Bracciale, F. Grisolia, Information Disorder: acceleratori tecnologici e dinamiche sociali, in Federalismi.it, 2020, 63. 
9 - Sulla problematicità di inserire la mal-information all’interno della categoria delle fake news, C. Wardle, First Draft’s Essential Guide to Undestanding Information Disorder, ottobre 2019, online su www.firstdraftnews.org. In questo caso è solo l’intento, l’obiettivo della condotta a rilevare in quanto la lesione della libertà di informazione si incardina soprattutto sul turbamento della corretta capacità di essere informati a causa di quello che è conosciuto come la weaponisation of context. Cfr. anche M. De Cock Buning et al., A multi-dimensional approach to disinformation. Report of the independent High-level Group on fake news and online disinformation, Publications Office – Unione europea, 2018, online su www.data.europa.eu. 
10 - P. Sammarco, Giustizia e social media, Bologna, il Mulino, 2019, par. 6. 
11 - Garante Privacy, Agcom, Agcm, Indagine conoscitiva sui Big Data, Roma, 10 febbraio 2020, 10 (delibera n. 217/17/CONS). 
12 - G. Pitruzzella, La libertà di informazione nell’era di Internet, in MediaLaws, 2019, 24. 
13 - E. Llansò et al., Artificial Intelligence, Content Moderation and Freedom of Expression, TWG Papers, 2020, online su www.ivir.nl. 
14 - F. Bridle, The bespoke newspaper – will the Daily Me soon be delivered?, in The Guardian, 13 luglio 2014. 
15 - Lo accenna, P. Dunn, Moderazione automatizzata e discriminazione algoritmica: il caso dell’hate speech, in L. Abba, A. Lazzaroni, M. Pietrangelo (a cura di), La internet governance e le sfide della trasformazione digitale, Napoli, ESI, 2022, 175-190, spec. 178-179.

