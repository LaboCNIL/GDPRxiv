
Audizione informale del Presidente del Garante per la protezione dei dati personali nell'ambito dell'esame delle proposte di legge C. 1056 e abb., recanti istituzione di una Commissione parlamentare di inchiesta sulla diffusione intenzionale, seriale e massiva di informazioni false (cosiddette fake news)
Commissioni riunite IX (Trasporti) e VII (Cultura) della Camera dei deputati
(3 marzo 2020)
Ringrazio le Commissioni per aver inteso analizzare il complesso  fenomeno  delle fake news anche dal punto di vista della protezione dati: disciplina sempre più centrale  nel governo della società digitale.
Il perimetro di azione dell'istituenda Commissione appare ben definito in tutte le proposte, riguardando i temi sia della disinformazione che della malainformazione nelle sue principali implicazioni di ordine individuale e collettivo.
Sotto il primo profilo, infatti, il fenomeno può essere considerato soprattutto nella sua valenza istigativa di condotte discriminatorie, diffamatorie o comunque lesive della dignità individuale.
La malainformazione, per altro verso, rappresenta un complesso fenomeno da analizzare anche quale possibile minaccia per la democrazia, con riflessi potenzialmente negativi sulla sovranità.
Infatti il social-bombing effettuato con messaggi propagandistici o anche solo l'invio di notizie unilaterali, targettizzate in ragione del profilo di elettore stilato dall'algoritmo -come nel caso di Cambridge Analitica- possono avere effetti estremamente distorsivi sulla corretta formazione del consenso, così da orientare le scelte politiche del corpo elettorale nella direzione voluta.  
Si condivide, dunque, la scelta di estendere in questi termini l'oggetto dell'indagine, per evitare di ridurre una grande questione democratica quale quella della "postverità" a mera questione penale o tecnologica.
Ora, è chiaro che né la disinformazione né la malainformazione nascono con i social.
Sicuramente ciò che con la rete si amplifica in misura esponenziale è la viralità con cui persino notizie palesemente false fanno il giro del web.
E si finisce per crederle vere per quel meccanismo autoconfermativo che finisce con il far dipendere l'attendibilità della notizia non dalla sua verificabilità ma dalla quantità di condivisioni che abbia ottenuto: dalla sua diffusività e non dalla sua intrinseca veridicità.
E' la logica dell'audience: le notizie comunque formate, finiscono per  conferire autorevolezza alla loro fonte in funzione della quantità di lettori-spettatori che ottengano e il meccanismo della remunerazione pubblicitaria, correlata al numero di visitatori del sito, certo non aiuta.
La verifica dei fatti è stata così sostituita dalla narrazione; il riscontro delle fonti dal consenso di massa quale unico parametro di valutazione delle notizie.
Ma soprattutto, ciò che fa più notizia è generalmente ciò che è più lontano dalla realtà, così da apparire come  verità finalmente disvelata e sottratta ai tentativi di mistificazione del potere.
Il tutto, poi, è aggravato dalla frammentazione dei centri d'informazione, che finisce con il determinare una sorta di autismo informativo: la tendenza cioè a informarsi soltanto da fonti inclini a confermarci nelle nostre pregresse convinzioni, ostacolando la possibilità di riscontro su false notizie o credenze.
Ciò non può che indebolire ulteriormente il senso critico indispensabile alla selezione delle informazioni veritiere dalla massa di notizie offerte dal web.  
Che fare? Delle varie soluzioni proposte nessuna è, di per sé sola, risolutiva, ma può risultare almeno in parte utile se combinata con le altre.
Sotto il profilo, di rilievo essenzialmente pubblicistico, del contrasto della disinformazione, la scorciatoia tecnologica – ovvero un software in grado di depotenziare le notizie false ponendole in coda, assegnando priorità alle informazioni verificate – non pare poter rappresentare, almeno di per sé sola, una  soluzione convincente.
Perché si alimenta della stessa logica viziata cui tenta di porre rimedio: la delega all'algoritmo di un'attività, quale il riscontro su fonti e notizie, che non può che essere umana e valutativa.
L'automazione del fact-checking, se priva di un adeguato supporto umano, contribuirebbe, infatti, a  deprimere ulteriormente il già debole senso critico e l'abitudine al riscontro dialettico.
Ciò che invece può risultare utile è l'adozione di misure, anche di carattere tecnico, volte a segnalare possibili distorsioni dei contenuti informativi dovute alla loro origine robotizzata.
Distinguere libertà di espressione da amplificazione algoritmica, può infatti contribuire a fornire all'utente maggiori strumenti per orientarsi in maniera consapevole in quella che rischia, altrimenti, di essere mera entropia (e non ricchezza) informativa.
In questo senso, andrebbe percorsa la strada- già in parte intrapresa in via sperimentale da alcuni gestori – di soluzioni  tecniche volte a segnalare all'utente, in base a criteri oggettivi -ad esempio la massività degli invii- contenuti potenzialmente inaffidabili, stimolando anche, così, il senso critico del pubblico.
Utilizzare la tecnica in funzione di promozione, anziché di limitazione, dei diritti può essere, in questo senso, una delle soluzioni migliori per contribuire a rendere la rete quello straordinario strumento democratico che doveva e deve essere.
Ma il contrasto della distorsione informativa può avvalersi anche di strumenti preziosi offerti dalla disciplina di protezione dati, ogniqualvolta  l'intento manipolativo dei contenuti veicolati si fondi sulla loro targettizzazione, resa possibile dalla segmentazione psicometrica del pubblico dovuta alla profilazione.
E' ciò che è successo con Cambridge Analitica ma che è ragionevole pensare avvenga in virtù della più ampia estensione del metodo profilativo dal piano commerciale a quello politico.
L'invio di contenuti specificamente ritagliati sul modo di essere, pensare, agire, desumibili dal comportamento on line dell'utente rilevato dall'algoritmo, può infatti avere una valenza manipolativa del suo pensiero non paragonabile a nessun monopolio dell'informazione perché, appunto, capace di adattarsi così perfettamente al pensiero del "bersaglio" da limitarne fortemente l'autodeterminazione.
Il contrasto di tali fenomeni distorsivi – dall'impatto devastante su garanzie democratiche primarie quali il pluralismo informativo, la libertà di e all'informazione – passa, in primo luogo, dal contrasto dell'illecito sfruttamento dei dati degli utenti che ne è alla base e per cui, ad esempio, abbiamo sanzionato Facebook.
La rilevanza di tale metodo di contrasto è tale che la disciplina europea sanziona oggi, espressamente, l'uso illecito di dati personali per condizionare i risultati elettorali, spesso, come abbiamo visto, persino da parte di potenze straniere.
Meglio potenziare questi strumenti, dunque, che cedere alla ricorrente tentazione del penale:  fuorviante perché riduzionista e controversa in termini democratici, perché finisce con l'attribuire alla magistratura penale il compito di tribunale della verità, in un contesto in cui invece l'esattezza andrebbe perseguita con il confronto pluralista e dialettico.
E con il limite invalicabile del rispetto dell'altrui dignità, assistito in caso di violazione dalle norme (esse sì penali) su istigazione alla discriminazione, diffamazione, trattamento illecito di dati, che tracciano il confine oltre cui la libertà di espressione non può spingersi senza violare indebitamente la dignità altrui.
Ma all'interno di questo confine esiste ed è ulteriormente configurabile una vasta gamma di strumenti nati anche sul terreno del diritto alla protezione dei dati personali, che meglio di altri possono contribuire a contrastare notizie inesatte, lesive della dignità.
In questo senso è molto importante non solo la rettifica di notizie diffamatorie, ma anche l'aggiornamento (persino dallo snippet di Google!) di notizie obsolete perché ormai superate dai fatti successivi, come avviene spesso per la cronaca giudiziaria.
Strumento doppiamente proficuo, perché utile non solo a tutelare la dignità dell'interessato ma la stessa qualità dell'informazione, migliorata inevitabilmente dallo stimolo all'aggiornamento e alla completezza della notizia.
Si tratta di un aspetto distinto e ulteriore rispetto a quello, già di per sé, importante, del "delisting", dal momento che l'aggiornamento è funzionale non all'"oblio" di un passato cristallizzato in una notizia ma all'integrale rappresentazione dell'identità, anche nell'evoluzione diacronica che può subire e nella sua proiezione sociale, completando nei suoi sviluppi un passato che altrimenti non ci corrisponderebbe più.
E se di questi strumenti già è possibile avvalersi oggi per contrastare campagne diffamatorie e istigazione all'odio,  ben possono introdursi ulteriori misure sul duplice piano della tutela remediale e della responsabilizzazione degli utenti, oltre che delle piattaforme, pur nei limiti imposti dal divieto di loro sorveglianza sui contenuti diffusi.
Sotto il primo profilo, andrebbe rafforzato il sistema di rimozione dei contenuti illeciti on line, limitandone la diffusione ulteriore e responsabilizzando il gestore, pur con la riserva di decisione, in ultima istanza, all'autorità pubblica.
Come dimostra il caso del cyberbullismo, il meccanismo fondato sulla richiesta al gestore di rimozione e la successiva istanza al Garante in caso di inerzia o contestazione, è un utile strumento di tutela dei diritti della personalità on line, in quanto coniuga l'esigenza della pronta rimozione dei contenuti, con la riserva all'autorità pubblica della decisione in ultima istanza, nel contraddittorio delle parti.
Si tratta di un complessivo bilanciamento che risponde alle esigenze sottolineate dalla Corte di giustizia e dalla Corte europea dei diritti dell'uomo; quest'ultima in particolare con alcune sentenze che hanno sancito addirittura, in capo agli Stati, un obbligo positivo di assicurare misure idonee a tutelare la dignità personale.
In tal senso, soprattutto per il contrasto dell'hate speech sarebbe utile una norma che disciplini, anche dal punto di vista temporale, la procedura che i gestori sono tenuti a seguire a seguito della ricezione di istanze di rimozione, con tempi celeri come previsto per il cyberbullismo e con il diritto anche della controparte di adire il Garante in caso di contestazione.
Naturalmente, nel caso in cui non siano in questione dati personali ma i contenuti diffusi siano illeciti perché volti a realizzare campagne di disinformazione, si potrebbe anche immaginare un sistema simile a quello tedesco, in cui la segnalazione di fake news venga decisa da soggetti indipendenti (un'Authority, l'ordine dei giornalisti o altro) e determini,  se fondata, l'obbligo per il gestore di rimuovere la notizia e comunicare la rettifica agli utenti che abbiano "interagito" (mediante condivisione, like o commento) con la notizia falsa.
Il tutto con la possibilità di adire il giudice in caso di contestazione della decisione, così da riservare all'autorità pubblica la decisione in ultima istanza su diritti fondamentali.
Un secondo livello di intervento - sul modello della vigente legge francese – potrebbe concernere la regolazione dell'uso oggi anomico e ritorsivo dell'anonimato in rete, rendendolo realmente reversibile, ovvero suscettibile di consentire l'identificazione dell'autore di contenuti illeciti su richiesta dell'autorità giudiziaria.
Si potrebbe pensare, così, a un obbligo di fornire al gestore della piattaforma social, all'atto dell'apertura di un profilo, un documento identificativo, che tuttavia sia per legge previsto come inaccessibile da parte del gestore, pena l'integrazione di un reato che si potrebbe, esso sì, anche introdurre ad hoc.
Il gestore avrebbe invece l'obbligo di consentirne l'accesso alla sola autorità giudiziaria presso cui sia incardinato un procedimento penale a carico dell'autore dei contenuti illeciti o un procedimento civile per risarcimento del danno subito per effetto dei medesimi contenuti.
Anche questa misura. peraltro non priva di criticità- è bene chiarirlo- non sarebbe mai del tutto risolutiva in assenza di un'uniformazione a livello internazionale della disciplina dell'anonimato in rete che, bilanciando libertà di espressione e dignità, consenta di rendere effettiva la tutela delle vittime di illeciti on-line, oggi ostacolata dal ricorso a metodi i più vari di mascheramento dell'identità.
Il complesso di strumenti sopra delineati, volti a contrastare le violazioni tanto della persona, quanto dei presidi democratici essenziali, realizzate con l'uso distorto della rete, non può che lasciar residuare  tuttavia un'incomprimibile sfera di libera espressione, in cui dobbiamo saper accettare anche il rischio dell'inesattezza come controparte del pluralismo e della tolleranza.
Un "costo" della democrazia, se così vogliamo definirlo, ma certamente un dato con cui dobbiamo fare i conti non tanto perché esiste il web quanto perché non esistono organi certificatori della verità, che non può che essere il risultato di un'opera dialettica di confronto e riscontro.
Un'opera certamente più complessa e faticosa, da condurre all'insegna dell'etica del dubbio e del senso del limite, ma non sostituibile con alcun Tribunale della verità.
