

Memoria del Garante per la protezione dei dati personali - Indagine conoscitiva sulla diffusione delle dipendenze patologiche tra i giovani
Commissione parlamentare per l'infanzia e l'adolescenza
(19 agosto 2021)
1. Il contesto
Ringrazio la Commissione per questo confronto, quantomai utile e per la sensibilità mostrata rispetto alle implicazioni di protezione dati di un tema, quale quello delle dipendenze in età giovanile,  così rilevante e ampio da intersecare una molteplicità di competenze. 
Proprio perché estremamente vasto, il tema sarà affrontato con riguardo agli aspetti più contigui alle attribuzioni dell’Autorità e, dunque, alla problematica (in certa misura oggetto di provvedimenti del Garante) della dipendenza da internet e da un uso, appunto, patologico (internet addiction disorder).
Si tratta peraltro, alla luce delle più recenti rilevazioni statistiche, di un fenomeno in non trascurabile ascesa tra gli adolescenti, in particolare nell’età compresa tra i tredici e diciannove anni. Esso, soprattutto durante il lock-down, ha peraltro conosciuto una manifestazione ulteriore, benché non interamente sovrapponibile, con il fenomeno degli hikikomori, espressione di un’iperconessione virtuale che determina sconnessione dai legami reali.
Come ogni dipendenza, anche quella da internet ha implicazioni tanto più pregiudizievoli quanto più riguardi soggetti la cui personalità sia, come nel caso dei minori, ancora in formazione e, in quanto tale, suscettibile di essere maggiormente incisa con effetti peraltro, se non permanenti, quantomeno più duraturi.
Nel caso dei giovani, poi, soprattutto in età adolescenziale è tanto più difficile distinguere l’uso patologico del web quello, invece, fisiologico. E questo perché  la rete rappresenta oggi, per i nostri ragazzi, non una delle tante dimensioni in cui realizzare le attività più varie, ma l’orizzonte lungo il quale si snoda la loro vita, intessuta di una trama di amicizie virtuali che spesso rimarranno tali, giocata sulla replica telematica delle azioni reali, cristallizzata in mosaici di foto affidate alla discrezione dell’altro e troppe volte finite, invece, sui social con effetti spesso anche fatali.
E proprio quest’intersezione costante, fin quasi alla sovrapposizione, delle dimensioni reale e virtuale, rende labile il confine tra ricorso corretto alla rete e dipendenza, anche distruttiva e autodistruttiva, da essa. Se, infatti, tutto diviene oggetto di proiezione on-line, l’intera vita rischia di essere assorbita dalla rete e ridursi a rappresentazione telematica di se stessa, con la conseguente espansione illimitata del ricorso al web, che rende oltremodo difficile individuare la soglia del patologico. 
Anche per questo, è tanto più rilevante garantire che l’esperienza del mondo on-line venga vissuta, da parte dei più piccoli, non in solitudine ma con la guida, vigile e lungimirante, degli adulti e, da parte degli adolescenti, con la necessaria consapevolezza delle implicazioni che può avere ogni loro click, sulla vita propria e su quella degli altri.
La disciplina di protezione dati rappresenta, in tale prospettiva, un ausilio determinante per garantire che, da un lato, i minori infraquattordicenni non accedano alla rete in totale solitudine (essendo, al di sotto di quell’età, richiesto il consenso dei genitori per il trattamento dei dati dei figli) e, dall’altro, gli ultraquattordicenni vivano quest’esperienza (totalizzante quanto poche altre) disponendo di un bagaglio minimo di informazioni sul ricorso corretto delle nuove tecnologie e sui rischi connessi a un uso errato delle stesse. Basti pensare, in questo senso, a quanto deleterio (e in prospettiva fatale) possa essere il contatto con contenuti o soggetti per gestire i quali il ragazzo non disponga delle competenze e dell’autonomia psicologica necessarie o il coinvolgimento in “sfide” autolesionistiche o, finanche, suicide. E’ significativo che esse, con sempre maggiore e drammatica frequenza si diffondano in rete, sfruttando l’attrattiva di quella che l’ultimo Freud definiva “pulsione di morte”.
Da un lato, dunque, la rete espone il minore al concreto rischio di subire condotte delittuose purtroppo diffuse sul web (anche a causa dell’apparente anonimato che esso offre) quali pedopornografia, revenge porn, cyberbullismo, sextorsion, istigazione al suicidio, grooming. Esse sono solo alcune delle forme che la violenza, la discriminazione, gli abusi i più varii assumono in rete, dirette contro il soggetto più vulnerabile (per la carenza di consapevolezza e per la personalità ancora in formazione) che possa accedere allo spazio digitale: il minore, come ha sottolineato anche il Comitato dei Ministri del Consiglio d’Europa nella dichiarazione del 28 aprile 2021.
Anche per effetto della telematizzazione della vita, indotta dalla pandemia, nel 2020 si è registrato un incremento di circa il 132%, rispetto al 2019 dei casi trattati dal Centro nazionale per il contrasto della pedopornografia e un aumento del 77% dei casi di vittimizzazione dei minori per grooming, cyber bullismo, furto d'identità digitale, sextorsion. Il 68% degli adolescenti risulta essere stato, nel 2020, testimone di casi di cyberbullismo (Terres des Hommes). Sono dati allarmanti, che non possono non esigere un’assunzione di responsabilità collettiva rispetto a soggetti, quali i minori, le cui vulnerabilità possono renderli le vittime elettive delle distorsioni del web.
Per altro verso, un accesso alla rete non supportato dalla prospettiva e dalle competenze dell’adulto- oltre che dai limiti da imporre doverosamente al quantum e al quomodo dell’uso del web- rischia di indurre, per la capacità attrattiva propria della rete, forme di dipendenza dalle quali è persino, a volte, più difficile emanciparsi per la sostanziale impossibilità, oggi, di prescindere totalmente dal ricorso ad internet. L’individuazione e la gestione del limite sono, per quelle che Massimo Recalcati definisce “le nuove melanconie”, ancor più difficili di quanto non lo siano per le dipendenze più tradizionali, relative cioè ad attività non socialmente accettate.
Rispetto a entrambi questi rischi, la disciplina di protezione dati offre tuttavia un ausilio importante, per un verso imponendo la supervisione degli adulti rispetto al trattamento dei dati personali degli infraquattrodicenni (e, dunque, anche rispetto all’uso, da parte loro, della rete) e, per altro verso, promuovendo quella pedagogia digitale, tanto più necessaria per un corretto approccio alla rete da parte degli adolescenti.
2. Solitudine digitale ed age verification
Con riguardo al primo dei profili su esposti, va considerato come una delle maggiori criticità che caratterizzano il rapporto tra i minori e la rete sia la clandestinità, come sinonimo di opacità ma anche di solitudine. Molti degli abusi perpetrati in rete coinvolgono infatti- soprattutto nella veste di vittime, ma talora anche in quella di agenti- minori alle primissime esperienze con i social, spesso molto piccoli e divenuti avventurieri solitari della rete, privi dunque delle necessarie competenze per comprendere la reale portata di ogni click, proprio o altrui.
Una buona parte dei minori vive, dunque, quella telematica come un’esperienza di solitudine e (illusoria) autonomia, resa possibile, in tutta la sua rischiosità, dall’apertura indiscriminata della rete. L’accessibilità generalizzata (salvo filtri particolari e comunque pur sempre limitati) di ogni tipo di contenuti in rete rende questo tipo di esperienza fortemente diversa rispetto a quella che i bambini di qualche generazione fa potevano fare dei media tradizionali. Lì bastava selezionare i canali per assicurare la fruibilità esclusiva di determinati contenuti e soprattutto, non vi era possibilità di interazione con terzi. La rete ha abolito anche questo tipo di barriere, aprendo a ogni possibile contenuto proveniente da qualsiasi parte del mondo in qualunque momento e l’interazione, il contatto, la condivisione ne costituiscono l’imperativo categorico.
Ma paradossalmente, nonostante i rischi propri della rete, essa rappresenta il luogo in cui i minori oggi vengono lasciati più frequentemente e per più tempo da soli, a confrontarsi senza strumenti con un mondo tanto affascinante quanto oscuro, ambivalente. E questa solitudine è ancor più grave e pericolosa rispetto ai social, che consentendo la più ampia interazione tra utenti sovente sconosciuti l’uno all’altro, coinvolgono purtroppo sempre più spesso bambini e ragazzi più fragili in “giochi” troppo più grandi di loro, capaci di determinare persino un’insana ed inspiegabile dipendenza.
Il Regolamento Ue 2016/679 ha, sul punto, previsto una norma assai lungimirante, legittimando soltanto i minori ultratredicenni (con soglia di età diversamente modulabile, da parte del legislatore interno, tra i tredici e i sedici anni) a prestare in via autonoma il consenso al trattamento dei propri dati personali. La norma (trasposta nel nostro ordinamento con previsione della soglia di quattordici anni per il consenso) bilancia, da un lato, l’esigenza di valorizzare la capacità di discernimento dei minori in aderenza a una realtà, peraltro, che li vede attivi on-line da molto prima. Dall’altro, la norma sottende la necessità di mantenere tale soglia di autonoma determinazione coerente con l’acquisizione di una minima maturità in capo al ragazzo, tale da non esporlo, con le sue stesse scelte, a rischi eccessivi. La norma sottende, è vero, una scommessa sulla capacità di autogestione del minore ultra14enne rispetto ai propri rapporti on-line. Si tratta di una scelta condivisibile, sia per la specifica soglia di età delineata (raggiunta la quale si può, ad esempio, avanzare, alle piattaforme e allo stesso Garante, istanza di rimozione di contenuti lesivi in materia di cyberbullismo), sia, appunto, per l’esigenza di scommettere su minori che, se adeguatamente formati, possano pian piano responsabilizzarsi rispetto a una realtà, quale quella virtuale, a cui li si può e li si deve preparare, ma da cui non li si può ragionevolmente alienare.
Ma se un ragazzo, a quattordici anni, dopo un’adeguata educazione “digitale”, può ritenersi anche in grado di provvedere, almeno in parte, alla gestione sicura di sé, della sua immagine e dei suoi rapporti on-line, oltre che ad un uso della rete che non trasmodi in dipendenza, certamente non può ritenersi tale un minore di età inferiore. Ecco, quindi, che a tal fine assume un’importanza determinante la corretta attuazione della norma sul consenso del minore nei rapporti on-line, che al di sotto dei quattordici anni deve essere rappresentato dai genitori, ai quali compete in senso sostanziale e non soltanto formale la scelta sulla gestione dei dati del figlio.
Tuttavia, le piattaforme non sempre adottano sistemi di verifica dell’età realmente efficaci, di modo che profili social di questo tipo possono essere aperti, con grande facilità, persino da bambini della scuola primaria, all’insaputa dei genitori e, dunque, in totale autonomia e solitudine. Ciò è esattamente quanto il Regolamento 2016/679 voleva evitare, almeno per i minori infratredicenni, nella consapevolezza della fragilità che caratterizza la personalità, ancora in formazione, dei bambini di quell’età e, quindi, della loro suscettibilità a farsi coinvolgere in situazioni pericolose o, per altro verso, a rendersi schiavi di un uso “addicting” della rete. Non a caso, Lacan definiva l’infanzia come il tempo dell’Absujet, dell’assoggettamento del bambino ad altri (nella fisiologia, i genitori), essenzialmente per l’assenza di una sua compiuta soggettività.
Non si tratta, è vero, di un adempimento così agevole da osservare. Il crinale stretto su cui ci si muove deve, da un lato, evitare la concentrazione in capo alle piattaforme di una sorta di anagrafe della popolazione mondiale, ma dall’altro deve anche consentire l’accertamento univoco dell’età dell’utente, minimizzando il rischio di condotte elusive.
Questo è, in sintesi, l’obiettivo perseguito dal Garante con l’azione di enforcement promossa, anche a livello europeo, rispetto a Tik Tok,con il provvedimento inibitorio e prescrittivo del 22 gennaio scorso e l’accoglimento- con riserva di costante monitoraggio - dell’impegno della piattaforma all’assunzione di misure considerate dall’Autorità significative. Si è, in tal modo, ottenuta una non trascurabile cooperazione del gestore nell’adempimento degli obblighi su di lui gravanti, proprio al fine di impedire un uso improprio della rete da parte dei minori, proprio perché privo del necessario sostegno degli adulti.
3. Pedagogia digitale e responsabilità
Naturalmente, l’age verification è una condizione necessaria, ma non sufficiente per rendere il web un ambiente se non sicuro, quantomeno non inospitale e meno “addicting” per i minori.
Per raggiungere quest’obiettivo si deve promuovere una reale pedagogia digitale e rendere effettiva la responsabilità per i contenuti illeciti diffusi (generalmente, peraltro e paradossalmente, quelli maggiormente suscettibili di ingenerare dipendenza).
Il primo aspetto (quello, appunto, della pedagogia digitale) è, infatti, determinante nel fornire agli adolescenti, che accedono al web autonomamente e senza mediazioni, le risorse necessarie a governarne l’uso in modo fisiologico, per impedire che trasmodi in patologia. E’ dunque indispensabile che i ragazzi comprendano, fino in fondo, le implicazioni di ogni loro azione “virtuale”, il possibile impatto sui destinatari, ma anche le modalità con cui l’ecosistema digitale si alimenta, la “dittatura” dei like che rischia di essere vissuta, da molti adolescenti, quale metro valutativo della propria persona, generando spesso crisi di autostima, intolleranza e conformismo. Ed è necessario che i giovani vivano l’esperienza del limite, delineando il confine tra uso corretto della rete e dipendenza patologica fin quasi alla schiavitù dal mezzo telematico, consentendo alla vita di darsi, come osserva Massimo Recalcati, “forme attraverso il desiderio”.
Il secondo aspetto involge il tema più generale della responsabilità delle piattaforme anche, appunto, per le condotte illecite realizzate dagli utenti tramite i loro spazi. Una, forse la più paradossale forma di dipendenza dal web riguarda proprio la fruizione di contenuti illeciti, violenti, persino istigativi al suicidio. Ecco, dunque, che il tema dell’internet addiction disorder può essere analizzato anche sotto la lente della responsabilità del gestore per i contenuti veicolati tramite la piattaforma. Come noto, ad oggi i provider – soggetti al divieto di monitoraggio preventivo e generalizzato sui contenuti immessi on-line – non rispondono dei contenuti (benché illeciti) immessi in rete dagli utenti, salvo in caso di inerzia rispetto a una richiesta di rimozione dell’autorità giudiziaria o amministrativa competente o comunque, per gli hosting attivi, laddove abbiano contezza del carattere illecito dei contenuti diffusi. Si tratta di un modello normativo che non riesce del tutto a contrapporre, al crescente potere privato delle piattaforme, forme adeguate di responsabilità delle stesse.
Proprio su questo equilibrio interviene, tuttavia, il Digital Services Act presentato dalla Commissione Ue il 15 dicembre, con la previsione di obblighi. soprattutto di carattere proattivo, in capo alle piattaforme, diversamente modulati sulla base del numero di utenti attivi, nel segno di una loro responsabilizzazione di tipo preventivo. Ribadendo - e, anzi, rafforzando con una nuova Good Samaritan Clause – l’esenzione di responsabilità secondaria dei gestori rispetto agli illeciti commessi dagli utenti sulle proprie piattaforme e il doveroso divieto di monitoraggio generale e preventivo sui contenuti, il DSA compensa tuttavia questo safe harbor con degli obblighi di regolamentazione tali da minimizzare il rischio di violazioni o da contenerne, comunque, gli effetti pregiudizievoli. A tal fine s’impone di procedure interne di decisione delle istanze di rimozione di contenuti illeciti o comunque contrari alle policies aziendali, con obblighi di motivazione e reclamabilità delle scelte adottate, nonché con la devoluzione delle controversie ad organi di AdR dotati di requisiti adeguati di indipendenza. 
In tal senso, si “positivizza” il percorso compiuto dalla giurisprudenza nel segno di una maggiore responsabilizzazione del gestore (si pensi alla figura pretoria dell’hosting attivo), volta a impedire che la rete, con la forza della condivisione virale e l’ubiquitarietà dei suoi servizi, divenga la cassa di risonanza di violazioni le più diverse dei diritti individuali.
La responsabilità del gestore è tema affrontato anche- sotto lo specifico profilo del contrasto della diffusione in rete di contenuti istigativi al suicidio- dal ddl AS 2086, Pillon, recante  Modifiche al codice penale in materia di istigazione alla violenza,all’autolesionismo e al suicidio, all’esame della Commissione giustizia del Senato in sede redigente.
Il disegno di legge, nel novellare l’articolo 414 del codice penale, introduce una fattispecie speciale di istigazione o apologia, finalizzata alla commissione di atti di violenza o autolesionismo da parte dei minorenni, aggravata peraltro in caso di verificazione dell’evento.  Si introduce, poi ,una fattispecie ulteriore di istigazione al suicidio, aggravata dall’uso di strumenti informatici o telematici. Si delinea inoltre una fattispecie specifica di concorso, relativa a chi contribuisca in qualsiasi modo, dolosamente o colposamente, alla diffusione “delle istigazioni o delle eccitazioni o degli aiuti” qualificati come illeciti.
In tale contesto s’inserisce la disciplina della responsabilità “primaria” delle piattaforme, da omesso controllo funzionale all’impedimento della diffusione di contenuti istigativi alla violenza, all'autolesionismo o al suicidio. Si introduce a tal fine, un articolo 57-ter al codice penale replicando, sia pur su di un terreno molto diverso, la fattispecie di responsabilità da omesso controllo del direttore del giornale a carico del “responsabile del sistema informatico o telematico il quale omette di esercitare sul contenuto del sistema il controllo necessario a impedire che col medesimo siano commessi i reati” di istigazione e apologia introdotti. La norma mira, condivisibilmente, a rafforzare la responsabilità delle piattaforme per i contenuti potenzialmente lesivi diffusi, pur senza normare i limiti  che i controlli svolti dai gestori debbano osservare, per non incorrere in quel divieto di sorveglianza preventiva dei contenuti che è un principio-cardine del diritto europeo in materia. Rispetto a tale profilo, dunque, sarebbe opportuno introdurre limiti specifici ai controlli svolti dai gestori, per non legittimare abusi suscettibili di tradursi anche in violazione della privacy degli utenti.
Tra le proposte emendative, meritevole di considerazione è la 3.1. che sostanzialmente traspone, sul terreno dei contenuti istigativi al suicidio, il modello di tutela remediale rimesso alla competenza del Garante in materia di cyberbullismo dalla l. 71 del 2017, con la facoltà di richiesta (anche da parte del minore ultraquattordicenne), al gestore o al titolare del trattamento (e in caso d’inerzia al Garante) di  oscuramento,  rimozione o blocco dei contenuti illeciti. Gli ottimi risultati cui sta conducendo l’attuazione della norma corrispondente in materia di cyberbullismo induce a sostenere, convintamente, tale proposta emendativa, che consentirebbe di bloccare il meccanismo deleterio delle condivisioni virali dei contenuti istigativi al suicidio, limitandone la circolazione e in ultima analisi rimuovendoli dal web in un termine adeguato alla contrazione dei tempi della rete.
Questa proposta emendativa, come anche il Digital Services Act, rappresentano innovazioni certamente auspicabili, che se combinate a una maggiore responsabilità anche dei genitori nell’educazione (al) digitale dei loro figli e nella vigilanza, discreta ma costante, sul loro agire on line, potrebbero  migliorare sensibilmente la qualità del web. In tal modo si potrebbe anche contribuire, in misura significativa, al contrasto delle cause della dipendenza da internet, promuovendone un uso fisiologico e persino proficuo, rinnovando quella promessa, troppo spesso tradita, della rete come uno spazio di promozione dei diritti, della libertà, dell’eguaglianza.

