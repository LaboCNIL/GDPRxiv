I
T
U
B
I
R
T
N
O
C

Atti del Convegno - 30 gennaio 2017
Atti del Convegno - 30 gennaio 2018

Atti del Convegno - 28 gennaio 2016

Antonello Soro, Presidente
Augusta Iannini, Vice Presidente
Giovanna Bianchi Clerici, Componente
Licia Califano, Componente

Giuseppe Busia, Segretario generale

Piazza di Monte Citorio, 121
00186 Roma
www.garanteprivacy.it

Uomini e Macchine
Protezione dati per un’etica 

del digitale

Atti del Convegno
30 gennaio 2018

www.garanteprivacy.it

In  questo  volume  sono  raccolti  i  contributi  di  studiosi  ed  esperti
intervenuti  al  Convegno “Uomini  e  macchine.  Protezione  dati  per
un’etica  del  digitale” organizzato  dal  Garante  per  la  protezione  dei
dati personali in occasione della “Giornata europea della protezione
dei dati personali” 2018.

Indice

Apertura dei lavori

3
Antonello Soro                                                                                                               

Intelligenza delle macchine e libertà dell’uomo                       15
Vito Mancuso
Antonio Punzi
Coordina: Augusta Iannini                                                                                          

Giocattoli intelligenti e oggetti che ci sorvegliano                       35
Luisa Crisigiovanni
Massimo Sideri                                                                                                              
Coordina: Licia Califano

Corpo elettronico e tecnologie indossabili                                      63
Edoardo Fleischner 
Francesco Grillo
Coordina: Giovanna Bianchi Clerici

Chiusura dei lavori

Maria Elena Boschi

95

Uomini e macchine
Protezione dati per un’etica
del digitale

APERTURA DEI LAVORI

Antonello Soro

Presidente del Garante 

per la protezione dei dati personali

Apertura dei lavori
Uomini e macchine
Protezione dati per un’etica
del digitale
Intervento di Antonello Soro, Presidente del Garante
per la protezione dei dati personali

Il 27 dicembre 1982 la rivista “Time” dedicava al computer
–  per  la  sua  “grande  influenza  nella  nostra  vita  quotidiana”  –  la
propria  copertina,  assegnando  per  la  prima  volta  la  qualifica  di
soggetto dell’anno a una “macchina” anziché a una persona. 

La  pubblicazione  –  che  sembrò  quasi  suggerire  la  fine
della centralità culturale e sociale dell’uomo – precedeva di poco
più di un anno quel 1984 in cui George Orwell prefigurava, già
settant’anni fa, la riduzione dell’uomo a codice e l’affermazione
della sorveglianza totale quale tecnica di governo della comples-
sità sociale.

Non si trattava, del resto, di una preoccupazione isolata se
pochi anni dopo Erich Fromm avrebbe osservato come “la civiltà
sta producendo macchine che si comportano come uomini e uomini
che si comportano come macchine. Il pericolo del passato era che
gli uomini diventassero schiavi. Il pericolo del futuro è che gli uo-
mini diventino robot”.

Il progresso tecnologico appariva pertanto – già prima del-
l’avvento di internet – come talmente capace di sconvolgere i para-
metri del vissuto individuale e collettivo, da rovesciare l’interrogativo
su cosa l’uomo possa fare delle macchine nel suo inverso: cosa le
macchine possano fare dell’uomo.

Se, dunque, il mero calcolatore suggeriva l’idea di un potere
smisurato della tecnica e del costo umano del progresso, la rivolu-
zione – cognitiva, simbolica, antropologica – determinata da internet

I n t e r v e n t o   d i   A n t o n e l l o   S o r o

3

(of things, of toys, of beings) e dall’intelligenza artificiale, dovrebbe
oggi indurci ad un supplemento di riflessione.

Essenzialmente perché il digitale è divenuto la trama stessa
delle  nostre  vite,  agente  potentissimo  di  trasformazione  sociale,
struttura e sovrastruttura insieme, testo e contesto: la cornice entro
cui si svolge ogni espressione dell’uomo, che condiziona secondo i
soli parametri della funzionalità e dell’efficienza. 

Con internet, la tecnologia da strumento si è fatta dimensione,
ecosistema in cui siamo così profondamente immersi da non renderci
conto, fino in fondo, delle sue implicazioni. Che si estendono dal
lavoro (con inquietanti interrogativi sulle prospettive di occupazione)
alla salute e alla ricerca scientifica ma anche alla giustizia, che finisce
con il divenire “predittiva”, affidando agli algoritmi persino quelle
decisioni dirimenti sull’uomo – colpevolezza, libertà, punibilità –
che sembravano l’ultimo baluardo della sovranità e, quindi, della
razionalità umana.

L’impatto  sull’esistenza  individuale  e  collettiva  non  è,  del

resto, meno rilevante. 

La genomica infrange il dogma dell’immutabilità del testo

del nostro futuro, così come scritto nei cromosomi. 

Con le tecnologie indossabili la persona è modificata nella
sua stessa fisicità: incorpora la tecnica e, quindi, la predisposizione
al controllo. Il corpo diviene una password che rende accessibile a
chiunque la nostra identità più remota; la fisicità è ridotta a superficie
di scrittura di un’identità indifesa.

Del resto, affidare a un algoritmo impronte digitali, reticolo
venoso, iridi, può sottrarci quanto di più intimo custodiamo come
riferimento ultimo del nostro essere.

Gli  algoritmi  determinano,  infatti,  non  soltanto  la  nostra
percezione del mondo, ma la nostra stessa identità, che con internet
diviene necessariamente plurale, affiancandosi a quella fisica anche
un caleidoscopio di identità digitali che concorrono, fin quasi a pre-
valere, sulla prima.

E finiremo con l’essere sconosciuti a noi stessi ma trasparenti

4

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

a  chiunque  sia  capace  di  estrarre  frammenti  di  noi  dalla  galassia
delle  nostre  tracce  on-line.  È  quello  che  Derrick  de  Kerckhove
chiama inconscio digitale: ciò che ancora non sappiamo di noi ma
che la rete sa, per effetto del pedinamento dello sciame informativo
prodotto dal nostro comportamento on-line.

Nel 2016 abbiamo generato tanti dati quanti ne ha prodotti

l’intera storia dell’umanità sino al 2015. 

Tra dieci anni questa quantità raddoppierà ogni 12 ore.
Attualmente il 70 % delle transazioni finanziarie è realizzato
mediante algoritmi e il valore dei dati personali cresce progressiva-
mente. L’innovazione digitale nel sistema finanziario darà un forte
impulso alla crescita dell’economia globale.

Le grandi compagnie tecnologiche sono impegnate a tradurre

i big data in megaprofitti. 

Scienziati e ingegneri in tutto il mondo puntano al prossimo
salto nella capacità di elaborazione, ai cosiddetti supercomputer alla
esascala, con capacità di calcolo fino a mille volte quelle dei migliori
supercomputer attuali: macchine in grado di risolvere problemi che
oggi non è possibile affrontare in campi diversi come la climatologia,
le energie rinnovabili, la genomica, la geofisica.

L’intelligenza  artificiale,  dal  canto  suo,  diviene  sempre  più

capace di auto-apprendimento e, quindi, di autonomia.

E viene usata sempre più spesso a fini di difesa, con il ricorso
a dispositivi la cui intrinseca predisposizione al dual use fa sfumare
il confine tra civile e militare.

Il passaggio dalla “guerra ibrida all’iperguerra informatica” si

annuncia come tutt’altro che irrilevante.

È significativo che personalità come Elon Musk, Bill Gates o
Stephen Hawking manifestino forti preoccupazioni sui rischi legati
agli sviluppi dell’intelligenza artificiale.

Per altro verso, è convincimento diffuso tra gli esperti che nei
prossimi dieci o al massimo vent’anni, circa la metà dei lavori attuali
saranno realizzati da macchine dotate di intelligenza artificiale.

E  non  solo  lavori  manuali,  ma  soprattutto  lavori  che 

I n t e r v e n t o   d i   A n t o n e l l o   S o r o

5

comportano lo sviluppo di processi intel ligen ti. Molti osserva-
tori  prevedono  una  grande  crisi  occupazionale,  non  delle  tute
blu ma dei colletti bianchi, e non è infondato il rischio di una
stagione di grandi tensioni sociali a livello globale.

Pur non accedendo alla teoria del pendio scivoloso e dunque
al netto di ogni visione apocalittica, ciò che è certo è che stiamo vi-
vendo la più radicale trasformazione sociale, economica, antropolo-
gica, persino politica, dalla fine della seconda guerra mondiale.

L’assunzione di lavoratori, la determinazione dell’affidabilità
per un prestito, la valutazione della capacità di un insegnante, persino
il rating di legalità ai fini dell’aggiudicazione degli appalti sono sem-
pre  meno  il  frutto  di  una  scelta  umana  e  sempre  più  l’esito  di
selezioni algoritmiche, alle quali deleghiamo, quasi fideisticamente,
il compito di decidere aspetti determinanti della vita delle persone. 
Presto ogni oggetto attorno a noi, persino il nostro abbiglia-
mento, sarà connesso: si stima che in 10 anni vi saranno 150 miliardi
di sensori in rete, 20 volte di più della popolazione mondiale. 

Ogni cosa, dunque, sarà “smart”: non solo i telefoni ma anche
le nostre auto, le nostre case, le nostre città; l’internet degli oggetti
e l’analisi dei big data convergeranno con l’intelligenza artificiale e i
sistemi biometrici: in definitiva vivremo in un pianeta “intelligente”. 
Tutto ciò favorirà certamente, per un verso, un netto miglio-
ramento della qualità della vita, liberandoci – come già oggi è evi-
dente – del peso di molte incombenze quotidiane e dischiudendo
possibilità prima precluse. 

Ma il processo di connessione di tutte le cose deve essere go-
vernato  con  lungimiranza,  per  minimizzare  i  rischi  cui  già  oggi
questi fenomeni ci espongono. 

L’apparente “innocuità” di oggetti di uso quotidiano (si pensi
alle  bambole-robot  o  alla  domotica)  ci  induce,  infatti,  a
sottovalutare in primo luogo la probabilità che essi rappresentino il
canale di accesso elettivo per attacchi informatici e hacker capaci di
sfruttarne le vulnerabilità. 

In  secondo  luogo,  di  questi  dispositivi  sottovalutiamo  la 

6

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

capacità di rivelare, mediante l’uso secondario dei dati raccolti, stili
di vita, capacità economica, persino patologie o dipendenze.

La normativa di protezione dati, sotto questo profilo, rap-
presenta un fondamentale presidio di garanzia, tanto in termini di
diritti esercitabili dall’utente quanto in termini di complessiva re-
sponsabilizzazione dei titolari, a vario titolo coinvolti, nella sempre
più articolata filiera in cui si snodano questi trattamenti.

E dovrebbe servire per minimizzare il rischio, inaccettabile
anzitutto  sul  piano  culturale,  di  intendere  la  cessione  dei  propri
dati, quale tributo necessario alla fruizione dei vantaggi offerti dal
pianeta connesso.

Numerose applicazioni hanno dimostrato che gli algoritmi
non sono matematica pura – infallibile e neutra – ma piuttosto opi-
nioni umane strutturate in forma matematica e riflettono quindi
spesso, in misura più o meno rilevante, le precomprensioni di chi li
progetta o le serie storiche assunte a riferimento.

Con il rischio, dunque, non soltanto di cristallizzare il futuro
nel passato, leggendo sempre il primo con gli schemi del secondo,
ma anche di assumere le correlazioni (quasi sempre contingenti) delle
serie storiche considerate, come relazioni necessariamente causali. 

Un algoritmo utilizzato negli Usa per il calcolo del rischio di
recidiva penale si è dimostrato, ad esempio, incline ad assegnare –
in assenza di ragioni criminologiche – un tasso maggiore ai neri ri-
spetto ai bianchi, solo sulla base delle correlazioni desunte da una
determinata serie storica assunta a riferimento.

Il risultato che si trae dall’impiego di tecnologie che dovreb-
bero assicurare la massima terzietà rischia dunque di essere, para-
dossalmente, più razzista, lombrosiano o anche solo antistorico di
quanto possa essere la pur fallibile razionalità dell’uomo.

Eppure la giustizia predittiva continua a esercitare un fascino
particolare, assecondando l’antica idea di un diritto talmente positivo
da essere capace di autoapplicazione senza l’intermediazione umana,
legittimato non dalla sovranità ma dalla sua stessa, sola, infallibilità. 
È  lecito  chiedersi  se  questa  giustizia,  paradossalmente  così

I n t e r v e n t o   d i   A n t o n e l l o   S o r o

7

performativa, sarà ancora umana e se, quando ad emettere le sen-
tenze sarà un algoritmo anziché un uomo, saranno garantite davvero
la giustizia e l’equità.

La discriminazione algoritmica rischia pertanto, se non sa-
pientemente governata, di approfondire le iniquità alle quali vorrebbe
ovviare, senza che ne siamo neppure consapevoli perché la precom-
prensione coperta da veste statistica non ci appare più tale e perché
le  modalità  di  decisione  algoritmica  non  sono  sindacabili  perché
neppure conoscibili. 

Non va poi sottovaluto l’impatto degli algoritmi sulla forma-

zione dell’opinione e della stessa coscienza individuale.

Secondo Dominique Cardon, il 95% degli internauti si con-
centra  sullo  0,03%  dei  contenuti  potenzialmente  disponibili  on-
line, per effetto della gerarchizzazione delle notizie determinata dai
motori di ricerca, in base a criteri tutt’altro che neutri perché desunti
anche dal nostro comportamento on-line. 

Con una sorta di cornice cognitiva basata non sul riconosci-
mento  dell’altro  ma  sul  rispecchiamento  del  sé,  ci  viene  dunque
proposto ciò che assomiglia di più all’immagine di noi che si è co-
struito il motore di ricerca. 

Traendo  informazioni  dal  nostro  comportamento  passato,
l’algoritmo  rafforza  e  conferma  le  nostre  opinioni,  indebolendo
quell’etica del dubbio che è il presupposto necessario del rispetto
della differenza e di ogni altra attitudine democratica. 

Come schiavi digitali, siamo così prigionieri di una bolla di
filtri  autoreferenziale,  capace  di  renderci  sempre  più  intolleranti
verso le differenze e di negare il pluralismo informativo e le stesse
straordinarie opportunità di arricchimento cognitivo che pur la rete
potrebbe offrire.

Sul piano politico, la possibilità offerta dagli algoritmi di “in-
formatica persuasiva” di  personalizzare  i  contenuti  proposti  agli
utenti per renderli maggiormente appetibili e appunto persuasivi,
ha sancito l’affermazione del “big nudging”. Ovvero dell’uso dei big
data  e  di  metodi  profilativi  per  esercitare  quel  tipo  di  intervento

8

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

pubblico  di  stampo  paternalistico,  fondato  appunto  sul  “nudge”
(pungolo), che consente di “guidare” la condotta dei cittadini per-
suadendoli all’adozione di comportamenti socialmente desiderabili.
Come dimostrano questi sommari esempi, dunque, il tema
della neutralità dell’algoritmo, dell’equità delle sue soluzioni e, più
in generale, della sostenibilità etica e giuridica della tecnologia di-
viene, oggi, una questione democratica cruciale.

Per scongiurare – o quantomeno minimizzare – i rischi con-
nessi al digitale, valorizzando peraltro le sue straordinarie opportunità,
è necessaria un’assunzione di responsabilità da parte di ciascun sog-
getto coinvolto nel governo della tecnologia, che per restare “umano”
deve incentrarsi su irrinunciabili principi etici e giuridici.

La tecnica dev’essere progresso, in primo luogo umano e so-
ciale, non cieco positivismo, pena la negazione delle essenziali con-
quiste di civiltà raggiunte nel corso della storia. In questo senso è
necessaria  un’etica  per  l’algoritmo  da  strutturarsi  nel  rispetto  dei
principi, in particolare di dignità e non discriminazione, fondativi
dello Stato di diritto. 

Vi è in gioco, del resto, anche una sfida culturale: non cedere
all’idea che la nostra persona sia definita dal punteggio attribuitogli
da un sistema di classificazione e valutazione  computerizzata, irre-
sponsabile e dal funzionamento opaco. 

Di  qui  l’importanza  delle  norme  del  Regolamento  generale
sulla protezione dei dati sulla contestabilità e la trasparenza del processo
decisionale  automatizzato,  dei  suoi  criteri  e  delle  sue  conseguenze,
esigendo la possibilità di un intervento umano, contrastando la delega
assoluta al cieco e neppure neutro determinismo dell’algoritmo.

Del resto, la disciplina sulla protezione dati delinea una cor-
nice generale al cui interno possono ricondursi i più complessi fe-
nomeni con i quali dobbiamo oggi confrontarci. 

Così per l’iperconnettività favorita dall’internet degli oggetti,
il nuovo quadro giuridico europeo sancisce alcune garanzie essenziali
per impedire che in questo flusso ininterrotto di dati l’uomo, da sua
fonte, divenga oggetto di un potere che lo trascende.

I n t e r v e n t o   d i   A n t o n e l l o   S o r o

9

La salvaguardia dell’autodeterminazione informativa, dell’au-
tonomia e della responsabilità delle scelte – articolata non soltanto
nei vari istituti del consenso informato, ma anche nella valutazione
di impatto privacy, della minimizzazione del trattamento, della pro-
tezione sin dalla progettazione e per impostazione predefinita – è in
questo senso presidio essenziale per mantenere il governo sulle nostre
tracce  digitali,  che  più  di  ogni  altro  aspetto  concorrono  oggi  a
definire la nostra identità e, con essa, la nostra libertà.

Tutto questo diverrà ancor più importante con l’avvento del-
l’internet of beings e, dunque, l’incorporazione delle nuove tecnologie
all’interno della nostra stessa fisicità, che determineranno mutamenti
radicali nell’antropologia, nel rapporto tra natura e cultura, biologia
e biografia, perdendo la prima la funzione di limite della seconda.
In tale contesto, noi pensiamo che nella dignità e non nella
materialità del dato biologico vada ricercato il limite oltre cui la tec-
nica non può e non deve spingersi. 

E in un mondo iperconnesso e in un’economia fondata sui
dati  e  alimentata  dall’intelligenza  artificiale,  presupposto  per  la
dignità e quindi anche per la libertà dell’uomo è la protezione di ciò
che,  come  i  suoi  dati  personali,  lo  caratterizza  più  emblematica-
mente.

E se il diritto in generale svolge oggi, sempre più, una funzione
di umanizzazione della tecnica – soprattutto quando il soggetto di
diritti rischia di divenire mero oggetto di calcoli predittivi e tecniche
manipolative  –  il  diritto  alla  protezione  dei  dati  rappresenta  una
straordinaria  risorsa  per  mantenere  la  persona,  nella  sua  libertà  e
nella sua responsabilità, al centro della società digitale.

10

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Intelligenza delle macchine 
e libertà dell’uomo

SESSIONE I

Vito Mancuso

Antonio Punzi

Coordina: Augusta Iannini

Vice Presidente del Garante 

per la protezione dei dati personali

Sessione I
Intelligenza delle macchine 
e libertà dell’uomo

Augusta Iannini

Il  Presidente  Soro  ha  posto  un  interrogativo  inquietante:
l’uomo rischia di divenire strumento della tecnica anziché suo do-
minus? E ancora cosa le macchine possono fare dell’uomo?

Dopo anni di frenetica e rapidissima evoluzione tecnologica,
ci rendiamo conto che stiamo assistendo ad una vera e propria rivo-
luzione sociale e culturale. Se, ad esempio, agli albori del web l’uso
di internet era visto come poco più che un gioco, oggi non vi è nes-
suno di noi che non abbia almeno una volta fatto acquisti online o
abbia prenotato un biglietto aereo, una vacanza o una crociera uti-
lizzando esclusivamente gli strumenti informatici messi a disposizione
dalla rete.

Attraverso  l’uso  delle  nuove  tecnologie  non  soltanto  usu-
fruiamo più agevolmente di servizi o prodotti già presenti sul mercato
ma assistiamo a profonde modifiche nel tessuto sociale: nuovi sbocchi
lavorativi, commerciali e culturali, mai prima esplorati, ma anche
nuovi desideri, nuovi bisogni, nuovi linguaggi dei quali solo qualche
anno addietro non si conosceva nemmeno l’esistenza.

Ragazzi che non si frequentano più in piazza o per la strada
ma che dialogano, forse anche più di prima e con maggiore libertà,
attraverso chat e applicazioni online o che giocano insieme pur se
distanti  centinaia  o  migliaia  di  chilometri.  Ma  la  loro  fisicità,  la
lettura di uno sguardo, la modifica di un’espressione è qualcosa di
irrimediabilmente perduto.

Venti anni fa chi avrebbe mai pensato che sarebbe stato in
futuro utile o addirittura necessario assumere qualcuno che si occu-

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

15

passe  quotidianamente  della  propria  reputazione  online?  O  della
propria  immagine  sui  social  media?  O  che  potesse  diventare  un
lavoro (peraltro ben remunerato) la difesa della propria rete interna
dagli attacchi hacker? O che esistessero delle monete solo virtuali,
prive del fondamentale collegamento con una specifica nazionalità
e con la sua reputazione internazionale?

Credo si possa tranquillamente parlare di una vera e propria
rivoluzione, assai simile alla rivoluzione industriale del primo nove-
cento; come un secolo addietro l’introduzione della catena di mon-
taggio e delle macchine a vapore ha trasformato l’intera società inglese,
europea e mondiale, richiamando milioni di persone verso le città,
spopolando le campagne e creando le basi della società moderna, così
oggi assistiamo ad un analogo fenomeno di “transumanza” dei lavo-
ratori dall’analogico al digitale, in una tendenzialmente infinita evo-
luzione dallo svolgimento materiale dei compiti alla mera supervisione
di macchine ed elaboratori che quei compiti svolgono per noi.

New Scientist, il settimanale di scienza e tecnologia più letto
al mondo, ha elencato una serie di esempi a proposito della rivolu-
zione degli algoritmi: le email inviate ad un supermercato britannico,
elencate in ordine di priorità e inoltrate da un’applicazione basata
sull’algoritmo tensor flow di Google. Oppure le applicazioni che ri-
spondono nei call center al posto di un addetto in carne ed ossa e
che ci chiedono cosa vogliamo ed inoltrano la chiamata in base alla
nostra risposta. Applicazioni di intelligenza artificiale già approvano
o respingono richieste di mutuo, stabiliscono i premi assicurativi,
scoprono le frodi fatte con le carte di credito. Ci sono algoritmi che
funzionano meglio degli esseri umani nel marketing on line, addi-
rittura  nella  previsione  di  sentenze  in  base  a  casi  analoghi,  nella
consulenza finanziaria ed altro.

Ma questo processo libererà risorse umane le quali, piuttosto
che lavorare, potranno occuparsi finalmente di cose più divertenti
ed appaganti? Oppure innescherà un percorso perverso al termine
del quale si decreterà la fine della razza umana? La medicina di pre-
cisione, con tutti i dati sulla storia clinica di un paziente, sul suo 

16

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

codice genetico e su quello dei genitori comparati con quelli di altri
milioni di casi può curare una persona in modo mirato come mai
prima d’ora. Questo significa che la professione di medico sarà can-
cellata? Immagino di no ma certamente la professione del medico
cambierà, così come molte altre professioni. Benedetti gli algoritmi
se distilleranno informazioni dall’enorme tsunami di dati che noi
stessi  produciamo  ma  questo  significa  anche  che  controlleranno
l’universo?

Domenica, non ricordo su quale giornale, ho letto che un ro-
bot addetto al servizio clienti ed all’accoglienza in un supermercato
è stato licenziato per inefficienza. Chissà perché mi sono sentita sol-
levata e non ho solidarizzato con questo lavoratore. Certo il vantaggio
per chi ha utilizzato il robot è che non ci sarà un giudice del lavoro
a reintegrarlo. È questo che ci aspettiamo dall’intelligenza artificiale?
L’arroganza di sottrarci a regole scomode perché utilizziamo

solo macchine? 

A prescindere dunque da quale sia la conclusione di questo
percorso, ormai inarrestabilmente intrapreso, c’è tutto un mondo
in  divenire  che  richiede  oggi  approfondimenti  e  valutazioni  non
soltanto di tipo tecnologico e giuridico, ma anche culturale, sociale,
religioso, in una parola visioni della vita che possono portare a con-
clusioni  anche  diametralmente  opposte  e  che  precedono  ormai  il
tema della tutela dei dati personali.

L’analisi  sui  valori  fondanti  dell’uomo  è  il  filo  conduttore
che ci deve guidare nelle difficilissime scelte che ci saranno richieste;
parlando semplicemente, senza questo filo conduttore l’evoluzione
tecnica “allo sbando”, senza controllo, non comporterebbe una con-
temporanea evoluzione dell’uomo, ma rimarrebbe confinata entro
pericolosi limiti di autoreferenzialità e rischierebbe di vanificare i
benefici di cui potrebbe godere l’intero genere umano.

È  concepibile  che  la  tecnologia  talvolta  indietreggi  se  si  è
certi delle conseguenze negative dell’innovazione o dobbiamo affi-
darci solo alla minimizzazione dei rischi, creando regole sempre più
contorte ma di fatto inefficaci?

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

17

Ne parliamo oggi con il teologo Vito Mancuso e con il pro-

fessor Antonio Punzi.

Vito  Mancuso  ha  una  storia  ed  una  bibliografia  che  sono
note  a  tutti. Traduco  in  una  domanda  diretta  il  titolo  di  un  suo
libro di successo: il bisogno di pensare è compatibile con la società
digitale,  con  l’energia  positiva  che  dovrebbe  scaturire  dal  nostro
corpo  quando  esercita  il  pensiero  per  vincere  la  paura  di  perdere
l’anima? Viviamo sui social ed esprimiamo le nostre emozioni con
le  “emoticon”.  La  diversità  di  espressione  di  questo  pensiero  sarà
sufficiente per controllare le “espressioni” dell’intelligenza artificiale?
Ci può essere amore nella libertà e nella consapevolezza tra

l’uomo e la tecnologia digitale?

Antonio  Punzi  è  professore  ordinario  di  metodologia  della
scienza giuridica alla LUISS, docente di diritto dei media e avvocato.
Ha scritto infiniti saggi e libri di filosofia del diritto. La sim-
biosi tra uomo e macchina, tema intrigante per il filosofo e per il
giurista diventa l’occasione per riflettere sulla convinzione che oggi,
nell’era dell’informazione, si è superato il concetto cardine del pen-
siero  moderno:  il  soggetto  e  l’oggetto  nettamente  divisi.  Oggi  la
tutela privacy si è trasformata da protezione di un ideale spazio del
sé, declinato in senso proprietario, a garanzia di un sé che si muove
nello spazio. Ed in questo viaggio, secondo il professor Punzi, l’io
potrà  dirsi  libero  solo  se  capace  di  una  consapevolezza  che  potrà
essere garantita solo con un massiccio processo di alfabetizzazione. 
Ma sarà sufficiente perché l’uomo mantenga il controllo delle

macchine?

Vito Mancuso

Rappresento una disciplina antica, la teologia, termine coniato
2400 anni fa in Grecia da Platone, e quindi il mio sarà un intervento
inattuale, per certi aspetti scontato: dovendo trattare di “Intelligenza
delle macchine e libertà dell’uomo”, farò un appello alla libertà. 

18

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

In un lontano giorno del 1778 il filosofo illuminista tedesco
Gotthold Ephraim Lessing dichiarava: “Se Dio tenesse nella sua
destra tutta la verità e nella sinistra il solo eterno impulso verso la
verità, e mi dicesse: scegli! io mi precipiterei umilmente alla sua
sinistra e direi: concedimi questa, Padre! La verità pura è soltanto
per  te!”.  Oggi,  quando  siamo  più  o  meno  tutti  inconsciamente
portati a sostituire l’onnipotenza di Dio con l’onnipotenza della
tecnologia (Emanuele Severino: “Dio è il primo tecnico, la tecnica
è  l’ultimo  dio”),  io  riformulerei  le  parole  di  Lessing  così:  Se  la
Macchina tenesse nella sua destra tutta l’efficienza e nella sinistra
il solo eterno impulso verso il lavoro e mi dicesse: scegli!, io sce-
glierei la sinistra dicendo: concedimi questa, Signora!, l’efficienza
pura è solo per te!

La mia tesi è molto semplice, afferma che l’essenza dell’uomo
è la libertà, e che quanto più si promuove la libertà, tanto più l’essere
umano fiorisce; quanto meno, meno. L’identificazione dell’essenza
umana nella libertà vale soprattutto per l’uomo occidentale, quello
nato nell’antica Grecia e che le parole di Eschilo definiscono al me-
glio.  La  regina  dei  persiani,  Atossa,  attende  impaziente  il  ritorno
dell’esercito  dalla  campagna  di  Grecia  e  siccome  l’esercito  tarda,
inizia a interrogare il dignitario di corte su chi siano questi greci, se
siano ricchi, forti, tecnicamente dotati nel tiro dell’arco e poi la do-
manda  centrale:  “Chi  è  il  loro  padrone?”.  Ecco  la  risposta  che
Eschilo, che combatté sia a Maratona sia a Salamina, le dà tramite il
dignitario  di  corte:  “Si  vantano  di  non  essere  schiavi  di  nessun
uomo, sudditi di nessuno”. Era il 472 a.C. e nasceva in Occidente il
concetto di libertà. 

Lungo la nostra storia la libertà ha avuto i suoi nemici e i
suoi difensori, li ha avuti indifferentemente in tutti gli schieramenti:
a destra e a sinistra, tra i credenti e non credenti, ma non ci sono
dubbi, a mio avviso, che ha costituito il faro più luminoso del cam-
mino della nostra società.

Ma come definire la libertà? Per libertà intendo l’insieme di

tre disposizioni: consapevolezza, creatività, responsabilità. 

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

19

La consapevolezza dice conoscenza, la creatività dice azione,
la responsabilità dice esercizio di tale conoscenza e di tale azione in
armonia con gli altri e con l’ambiente. Se quindi la pienezza della
vita umana si dà come vita libera in quanto consapevole, creativa e
responsabile, ne viene che l’intelligenza artificiale di cui dotiamo le
macchine che andiamo costruendo sarà tanto più da valutare posi-
tivamente quanto più promuoverà in noi consapevolezza, creatività
e responsabilità, e sarà tanto più da valutare negativamente quanto
più tali disposizioni verranno diminuite o addirittura inibite. 

Garantire la privacy, in altri termini, non significa solo tute-
lare  i  dati  personali.  Ben  più  radicalmente,  significa  garantire  la
possibilità  stessa  di  rimanere  persona,  cioè  agente  libero.  Siamo
così lontani dall’avvento di un potere tecnologico che garantendo
esattezza,  efficienza,  sicurezza,  comodità,  riduce  drasticamente  il
sapore più autentico dell’esperienza umana come impulso, slancio,
imprevedibilità, ribellione, caos, passione?

Il sogno di trasformare il mondo e l’uomo secondo la logica
della tecnologia è antico, il filosofo francese De la Mettrie scrisse 
L’homme machine nel 1747. Tale sogno si è incamminato sempre
più verso la realtà e nel 1964 Herbert Marcuse iniziava così L’uomo
a una dimensione: “Una confortevole, levigata, ragionevole, demo-
cratica non-libertà prevale nella civiltà industriale avanzata, segno
del progresso tecnico”. 

Non so se sia davvero realizzabile il sogno meccanicista del
mondo come macchina e degli esseri umani come tante ordinate
macchinine, tutti rigorosamente a una sola dimensione. Ciò di cui
sono abbastanza sicuro è che qualcuno può avere molto interesse a
ridurre gli esseri umani in tanti ingranaggi unidimensionali al servizio
di  un  grande  macchinario:  un  tempo  era  l’Impero  persiano,  poi
venne la Chiesa cattolica medievale con il suo assolutismo e la sua
inquisizione (emblematiche le date del 17 febbraio 1600 e del 22
giugno  1633  che  ricordano  due  tragici  eventi  accaduti  in  questa
città), poi il giacobinismo che nel nome della libertà finì per ghi-
gliottinare i cittadini con la stessa indifferenza con cui si tagliano le

20

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

teste di cavolo (il paragone si trova nella Fenomenologia dello spirito
di Hegel), poi le dittature di destra e di sinistra che hanno insangui-
nato il Novecento. Quali sono oggi i nemici della libertà? 

A costo di apparire antiquato, non nascondo l’inquietudine
generata in me al pensiero di un prossimo futuro fatto di macchine
con forma umana, con voce umana, con tatto umano, in giro per le
nostre case. Saranno anche come noi? O addirittura più di noi, at-
tuando così per l’ennesima volta la dialettica servo-padrone illustrata
dalla Fenomenologia dello spirito, questa volta però sotto forma di
inventore-invenzione? Leggeremo libri di filosofia, di diritto, di po-
litica, scritti da macchine umanoidi? Saranno loro i futuri maestri
dell’umanità? Tra meno di cento anni in questa stessa sala si ritrove-
ranno gli umanoidi a discutere cosa fare di questi umani, così poco
efficienti, così tanto costosi?

Vorrei tornare sull’impulso alla ricerca della verità che Lessing
giustamente preferiva al possesso della verità e che costituisce, a mio
avviso, il sale della vita umana in quanto umana. Da dove viene?

Viene dall’ignoranza e dalla conseguente meraviglia. Platone
e Aristotele posero nella meraviglia l’inizio della filosofia, intendendo
per filosofia la forma più alta di vita libera, non più solo produzione,
ma anche e soprattutto contemplazione. 

In  realtà  i  filosofi  antichi  si  potevano  permettere  il  loro
otium grazie  al  negotium coatto  della  moltitudine  degli  schiavi,
una situazione durata sostanzialmente fino a pochi decenni fa e
ancora presente in non poche parti del mondo. 

La tecnologia con le sue macchine non è quindi necessa-
riamente  nemica  della  libertà,  anzi  può  esserne  una  preziosa
alleata. Il punto però è un altro: è la meraviglia. 

Anche l’intelligenza artificiale suscita meraviglia, e non poca.
Ma si tratta pur sempre di una meraviglia limitata, perché noi sap-
piamo da dove viene la tecnologia e quindi il fatto che una tavoletta
mi colleghi con il mondo o che dentro di me un puntino metallico
potenzi  le  mie  prestazioni,  è  sì  meraviglioso  ma  fino  a  un  certo
punto. Quando arriva la spiegazione, la meraviglia non c’è più. 

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

21

Al suo posto subentra un’altra cosa: il potere. L’intelligenza
artificiale, che viene dalla potenza della mente umana, genera ulti-
mamente  potere  e  desiderio  di  potere.  Non  è  significativo  che  i
nazisti ad Auschwitz toglievano tutto ai prigionieri, ma assegnavano
a tutti rigorosamente un numero? Il numero è alla base del controllo
e del potere, è lo strumento privilegiato del controllo e del potere.
Per il pensiero umano le cose non stanno così. Noi non sap-
piamo da dove viene la vita, meno ancora sappiamo da dove viene
la coscienza in quanto sede del pensiero. Al riguardo c’è chi parla di
materia e di caso, chi di materia e di teleologia, chi di spirito e di
teologia, il Dalai Lama sostiene che “l’evento della coscienza non
emerge dal cervello o dalla materia”. Ma ciò che conta davvero è
che il destino dell’umanità è legato alla sua capacità di cogliere e di
indagare l’ignoto, è legato cioè alla sua ignoranza e alla conseguente
meraviglia. Dico ignoranza, ovviamente, non per rimanervi, ma per
superarla elaborando liberamente le informazioni. 

Nella misura in cui rimarrà in noi uno scarto tra il di più
della  vita  e  la  mente,  continuerà  a  esservi  spazio  per  la  libertà,  e
quindi per l’arte, la poesia, la filosofia, la spiritualità, la passione,
cioè per l’essenza più vera dell’essere umano. Ha scritto Goethe: “Il
fremito è la miglior parte dell’umanità; per quanto il mondo faccia
pagare caro il sentimento, l’uomo, quand’è commosso, tocca l’im-
mensità”. Se invece l’umanità, attraverso microchip o altri meccani-
smi, riuscirà a placare ogni tensione, essa, da passione indisciplinata,
verrà addomesticata, e sarà la fine, non dico solo della privacy, dico
del mistero della persona.

Il mondo è un esperimento e come tale può anche fallire, e a
mio avviso un’eventuale chiusura dell’umanità su se stessa nel totale
appagamento della propria intelligenza indirizzata solo a soddisfare
i propri bisogni e a incrementare i propri piaceri, costituirà il falli-
mento dell’esperienza umana. Tale neopositivismo tecnologico se-
gnerà la fine del nostro essere sapiens, saremo solo faber, o peggio
consumans, ammesso che si possa dire in latino. 

Sono stato invitato a parlare di “Intelligenza delle macchine

22

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

e libertà dell’uomo” e io concludo con il desiderio che le macchine
non ci tolgano il caos. È dal caos infatti, come insegnano tutte le
antiche cosmogonie, che prende forma la natura, anche la natura
umana, la quale, tra tutte le manifestazioni naturali, è la più caotica,
e per questo la più libera. 

Antonio Punzi

Ringrazio il Presidente, la vice-Presidente, le illustri Compo-
nenti  del  Collegio,  per  l’invito  a  partecipare  a  questa  prestigiosa
Giornata.

Dopo un teologo, l’Autorità Garante dialoga con un filosofo
del diritto. Il perché è nel titolo della giornata e della sessione che ci
ospita. È in gioco una questione ontologica: la simbiosi tra uomo e
macchina e i suoi effetti sulla tutela dei dati personali. 

Partiamo dalle parole. Anzitutto dal nome dell’Autorità, che
individua la sua funzione: Protezione dei Dati Personali. Per pro-
teggere qualcuno bisogna sapere dove si trova, bisogna poterne de-
finire l’identità e la sfera di azione. Ed oggi perimetrare la nostra
persona  fatta  anche  di  dati  è  impresa  titanica.  D’altronde  con  la
modernità è finita l’èra dei confini, con buona pace di Carl Schmitt.

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

23

Vi propongo uno schema e vorrei ragionare con voi sulle sue

odierne criticità: PERSONA - COSCIENZA - DIRITTO - TUTELA.

È  lo  schema  che  nella  modernità  si  dimostra  vincente  ed
inaugura l’età dei diritti, per dirla con Norberto Bobbio: diritti ri-
vendicati contro il sovrano, dichiarati nella fictio del contratto sociale,
consacrati nelle carte costituzionali.

La filosofia ci aiuta a vedere cosa c’è dietro quello schema. L’alba
dei diritti vede la luce nell’età della rivoluzione scientifica in cui si isti-
tuisce il dominio cognitivo e tecnico dell’uomo sul mondo: il soggetto
moderno (diciamo cartesiano) acquista certezza di sé prendendo le di-
stanze dall’oggetto per poi conoscerlo e trasformarlo. Forte del proprio
primato ontologico rispetto alla natura e alle macchine, cosciente della
propria dignità, l’io scende in piazza per rivendicare i propri diritti.

Qualche lustro fa era di moda qualificare – polemicamente –
il moderno soggetto di diritto come un io proprietario. Prendiamo
questa definizione per il verso giusto: il soggetto moderno chiede
diritti sul suo proprium – il proprio corpo, il proprio spazio abitativo,
il prodotto del proprio lavoro. De-finisce il proprio spazio tracciando
un confine, vi inscrive la propria signoria e la fa assurgere a diritto
naturale. Attraverso l’azione sul mondo esterno – mediante la scienza,
la tecnica, l’economia – il soggetto moderno consacra la consapevo-
lezza di sé e della propria superiore dignità.

24

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Ed è questa consapevolezza di sé guadagnata attraverso il rap-
porto con un mondo-oggetto esterno a sé a costituire oggi il nostro
problema. Di qui la fine della modernità: la caduta del muro. Non
solo  quello  di  Berlino,  evidentemente,  ma  il  muro  di  confine  tra
soggetto  e  oggetto.  Senza  di  esso,  però,  risultano  quasi  invisibili  i
confini della nostra persona. E ciò in un duplice senso: l’oggetto entra
a far corpo con l’io mentre l’io a sua volta esce fuori di sé.

Da un lato, infatti, l’oggetto non è più esterno – posto di fronte,
ob-jectum, gegen-stand – ma innestato in me come nuovo organo con
cui scambio informazioni: lo smartphone, il rilevatore cardiaco, l’elet-
tromiografo,  il  sensore  sulla  pelle,  il  microchip  cerebrale.  Dall’altro
lato, l’io esce fuori di sé, si fa flusso di dati che non sono più solo
espressione del sé (i dati della persona), ma parti di sé, della propria
persona digitale: dati biometrici, abitudini di spostamento, di acquisto,
di lettura, reputazione. La nostra realtà cognitiva non è più confinata
nella coscienza cosicché l’io perde il contatto con, e forse anche memoria
di, quei dati che sono parti di lui. Di qui la formazione di quell’inconscio
digitale su cui riflette da tempo Derrick De Kerckhove. 

Ecco perché il problema è la coscienza di sé, che – non dimen-
tichiamolo – nello schema della modernità era presupposto per riven-
dicare ed esercitare il proprio diritto. Certo, grazie alle nuove macchine
– sempre più invisibili ed organicamente integrate – la nostra identità

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

25

accresce il suo potenziale cognitivo, emotivo – il sé aumentato – le
chances di cura della salute, di protezione della sicurezza, ma perde il
contatto con le proprie oggettivazioni. Di più: perde di vista il proprio
modo di oggettivarsi.

Rispetto allo scenario di 20 anni fa – gli anni della L. 31 di-
cembre 1996 n. 675 e poi d. lgs. 30 giugno 2003 n. 196 – si coglie
uno scarto significativo: allora il problema era garantire alla persona
consapevolezza dei propri dati (dove sono, chi li può trattare, quando
li si può modificare o chiederne la cancellazione, ecc.). Oggi il problema
è garantire alla persona la possibilità di formare la propria identità.
Non basta più proteggere lo spazio del sé – dallo sguardo indiscreto
delle  Agenzie  per  la  sicurezza,  dalle  Aziende  Sanitarie,  dall’Agenzia
delle Entrate, dall’assicuratore, dalla Banca, ecc. – bensì mettere l’io in
condizione di ri-comporre il sé.

A  ragione  codesta  Autorità  ha  in  più  occasioni  sottolineato
come  tutela  dei  dati  personali  oggi  non  possa  più  significare  difesa
della privatezza, bensì garanzia della libera costruzione della personalità,
della sovranità su di sé. Lo ricordava il Presidente Soro nella Relazione
2016. L’oggetto di tutela diviene, dunque, il diritto della persona: a)
ad essere se stessa, mappando i luoghi dell’infospazio in cui sono stoccati
i pezzi della sua identità; b) a diventare se stessa, facendo un uso consa-
pevole di sé e dei propri dati. In gioco è proprio il diritto all’identità,

26

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

non solo, evidentemente, nel senso rivendicato da Mario Costeja Gon-
zález di fronte al Vostro omologo spagnolo o del più risalente, celebre
caso Veronesi che fece scuola nella nostra Giurisprudenza.

Torniamo dunque allo schema iniziale: la tutela del diritto im-
plica la consapevolezza di sé. Si chiede tutela per un bene di cui si ha
coscienza, così avvertendone il valore. Il problema è che l’info-persona
che noi siamo difetta di autocoscienza, sa poco di sé e del mondo in
cui  si  muove,  è  un  animale  per  lo  più  primitivo.  In  fondo:  come
animali razionali analogici siamo stati addestrati – in famiglia, a scuola,
in  società  –  ad  acquisire  coscienza  di  noi  stessi,  ad  orientarci  nello
spazio, a ragionare, a decidere. Come info-persone, invece, siamo au-
todidatti, procediamo a tentoni. Un procedere che il grande epistemo-
logo  e  alfiere  della  società  aperta  Karl  Popper avrebbe  definito  per
Trial and Error. Solo che gli errori possono essere fatali, pensiamo al
caso di Tiziana Cantone.

Qui spesso si obietta: l’utente della rete cede i propri dati senza la
dovuta prudenza. L’eccezione è sensata eppure non coglie il centro del
problema. È come censurare la cattiva calligrafia di chi non è mai andato
alle elementari o l’imperizia nello smontare un carburatore di chi non è
mai entrato in officina. D’altronde: i mezzi modificano i processi cognitivi
– lo sapeva già Mac Luhan – e noi come infopersone pensiamo e deci-
diamo sempre più grazie a dispositivi artificiali divenuti sensi del nostro
orizzonte percettivo e ingranaggi del nostro processo cognitivo.

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

27

Solo che non sappiamo come fare. Peggio: l’info-persona viene
ancora addestrata come se vivesse in un mondo diciamo analogico,
abitato  da  oggetti  utilizzabili  come  strumenti.  E  quindi  rischia  di
muoversi nell’infopazio senza bussola, procede per intùito e imita-
zione, un po’ come nella tela “La parabola dei ciechi” del geniale pit-
tore fiammingo Brueghel il Vecchio. In sintesi: lanciamo a grande
velocità, in uno spazio che conosciamo poco, un’identità – la nostra
– che stentiamo a riconoscere. Di qui, se è consentita una nota quasi
di costume, quella compulsione a “googlare” il nostro nome confi-
dando che la rete possa restituirci il nostro mosaico identitario.

Ma se le cose stanno così viene da chiedersi: che fine ha fatto
quel valore della consapevolezza intorno al quale ruota la normativa
privacy  dalla  Direttiva  46/1995/CE  in  poi?  Qui  bisognerebbe  dare
ascolto al monito di Virgilio, quando nell’Eneide fa dire a Laocoonte
“Timeo  Danaos  et  dona  ferentes”.  Ma  quali  sono,  nella  fattispecie,  i
doni minacciosi? Qual è il cavallo di Troia? Forse la gratuità dei servizi
offerti in rete in cambio della cessione dei nostri dati? Dati ceduti in
modo consensuale. Ma consensuale in che senso? “Consenso della per-
sona interessata” per la citata Direttiva del 1995 era “manifestazione di
volontà libera, specifica e informata di accettazione del trattamento”.

Non lo si può negare: il consenso – dunque il fondamento

della disciplina in materia – oggi costituisce un problema. 

28

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Certo codesta Autorità Garante ha fatto molto, penso ad esem-
pio al Provvedimento dell’8 maggio 2014 sull’acquisizione del consenso
per l’uso dei cookies: il banner da voi prescritto ci mette in condizione
di essere consapevoli prima di fare indigestione di invisibili ma insidiosi
‘biscottini’. Un provvedimento scritto in punta di penna, bilanciando
l’esigenza di un “consenso espresso e specifico” (come previsto dall’art.
23 del Codice) con l’esigenza di garantire “il minore impatto possibile”
per la “continuità della navigazione”.

Qualche recente dato, però, dà da pensare. Da un sondaggio
presentato  da  Altroconsumo  al  Festivalfuturo  2017,  risulta  che  “il
91% degli utenti accetta le condizioni di utilizzo dei servizi online
senza leggerle”. Un consenso inconsapevole? Ed è singolare che l’84%
dello stesso campione richieda, al contempo, maggiori possibilità per
definire le proprie impostazioni di privacy. L’utente sembra confuso.
Mi chiedo: gli si chiarirebbero le idee se, ad esempio, venisse messo in
condizione di scegliere, in alternativa al cavallo di troia imbottito di
cookies, il pagamento del servizio senza alcuna cessione di dati?

Il vero è che per diventare padroni del nostro consenso dob-
biamo acquisire nuove competenze. La simbiosi tra uomo e macchina
esige di ripensare tutto il percorso di formazione delle competenze
dell’animale  razionale,  a  partire  dalla  formazione  primaria.  Non  si
tratta  solo  di  installare  nelle  aule  lavagne  elettroniche  o  distribuire
opuscoli sull’uso prudente della rete. La posta in palio è ben più alta:
uscire dal nuovo stato di minorità in cui rischiamo di scivolare. 

I n t e l l i g e n z a   d e l l e   m a c c h i n e   e   l i b e r t à   d e l l ’ u o m o

29

C’è bisogno di un nuovo Illuminismo, di una nuova risposta
alla domanda fondante la nostra civiltà dei diritti: la domanda di Kant
“cosa  significa  orientarsi  nel  pensiero”.  D’altronde  l’illuminismo  fu
l’epoca della rivoluzione della lettura: ha avuto successo perché la bor-
ghesia, avendo imparato a leggere, andava nei caffè per ragionare. Ecco:
dobbiamo nuovamente imparare a leggere, a ragionare, a decidere.

D’altronde siamo appena entrati in una nuova fase del processo

di civilizzazione, legata al connubio tra linguaggio ed elettricità.

E si sa che ad ogni cambiamento del linguaggio umano mu-
tano i sistemi di valore e i principi fondanti della vita civile. L’èra
della stampa ha portato con sé la Riforma, l’Illuminismo, le carte
dei diritti. Solo che la scrittura aveva creato divisioni e etica indivi-
duale, mentre l’elettricità abbatte i muri, connette, crea intelligenza
collettiva. Di qui l’esigenza di un nuovo umanesimo elettrico e di
una nuova declinazione della dignità umana.

E  di  una  simile  impresa  codesta  Autorità  dovrà  costituire
l’asse portante, riconducendo a sistema – a sistema dei diritti intendo
– le competenze di esperti di intelligenza artificiale, genetica, neu-
roscienze, psicologia cognitiva, logica.

Non credo davvero che le istituzioni possano nutrire dubbi
in ordine al ruolo che codesta Autorità, domani più di oggi, dovrà
svolgere: in gioco è il diritto all’identità in un orizzonte tecnologi-
camente rigenerato. Anche perché la strada da percorrere è stata già
tracciata nella nostra Costituzione, di cui quest’anno ricorre il set-
tantesimo anniversario. Non sono stati forse i nostri costituenti ad
attribuire alla Repubblica il compito di “rimuovere gli ostacoli” –
art. 3 co. 2 – “che, limitando di fatto la libertà e l’eguaglianza dei
cittadini, impediscono il pieno sviluppo della persona umana”?

Solo  un  imponente  processo  di  civilizzazione  digitale  con-
sentirà di dare piena esecuzione a tale mandato in uno scenario abi-
tato da uomini e da macchine.

E non avremo paura neanche della fusione con le macchine
se  avremo  chiara  e  informata  coscienza  della  nostra  dignità  e  dei
nostri diritti.

30

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Giocattoli intelligenti 
e oggetti che ci sorvegliano

SESSIONE II

Luisa Crisigiovanni

Massimo Sideri

Coordina: Licia Califano

Componente del Garante 

per la protezione dei dati personali

Sessione II
Giocattoli intelligenti 
e oggetti che ci sorvegliano

Licia Califano

Il tema dell’Internet of Toys rappresenta una porzione del più
ampio tema dell’Internet of Things. A quanto risulta da un recente
studio della Juniper Research (Smart Toys, 13 giugno 2017), non ne
è neanche la più insignificante: si prevede infatti che nel 2020, dei
25 miliardi di dispositivi intelligenti stimati in commercio, 11,3 di
questi saranno proprio smart toys (quindi, il 45,2% del mercato IoT
complessivo).

Questi “giocattoli intelligenti” negli ultimi tempi hanno sol-
levato un elevato livello di allarme all’estero, soprattutto in territorio
americano  e  nordeuropeo,  dove  questi  prodotti  sono  pienamente
entrati nel mercato, commercializzazione che invece in Italia risulta
ancora indietro.

Ma cosa sono questi giocattoli intelligenti?
In estrema sintesi, si tratta di bambole, pupazzi, robot, dotati
di funzionalità avanzate, in grado di interagire con i bambini che li
maneggiano,  collegati  alla  rete  Internet,  tendenzialmente  tramite
una connessione bluetooth, e azionabili dallo smartphone dei genitori
mediante  apposite  applicazioni.  Queste  funzionalità  sono  spesso
rappresentate da: una telecamera che riprende chi gli sta di fronte e
l’ambiente circostante; un microfono che raccoglie le frasi e i suoni
emessi;  un  sensore  di  riconoscimento  vocale;  un  altoparlante  in
grado di interagire con il bimbo; un dispositivo di geolocalizzazione,
grazie al quale tracciare gli spostamenti del giocattolo (e quindi del
figlio che se lo porta con sé).

La  frontiera  più  avanzata  potrebbe  però  essere  costituita  da

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

35

robot in grado di assistere costantemente le persone cui si affiancano.
Massimo Sideri (uno dei relatori), in un editoriale dello scorso
settembre per il Corriere della Sera, aveva documentato il progetto
Mario Kompai, promosso (tra gli altri) dal Cnr, basato sul ricorso ad
un automa in grado di svolgere alcune funzioni in favore dei malati
di Alzheimer (tra cui pure esami clinici), dando così il cambio al
personale sanitario “umano”. Non è quindi difficile pensare che a
modelli  del  genere  si  possano  ispirare  anche  giocattoli,  visto  che
anche i bambini, soprattutto quelli più piccoli, versano in condizioni
di dipendenza dall’aiuto altrui.

Perché questi smart toys si stanno diffondendo sempre più?
Essenzialmente, i benefici che offrono sono costituiti dalla
possibilità di aumentare e diversificare gli stimoli nei confronti dei
bimbi, consentendo loro di potenziare le capacità di apprendimento.
Si pensi all’insegnamento della lingua inglese: in un Paese in
cui spesso i genitori non hanno una grande consuetudine con una
lingua diversa da quella madre, e dove l’offerta educativa in questo
settore  appare  sicuramente  migliorabile,  allora  potrebbe  risultare
utile un peluche che parli costantemente in inglese al bimbo, facili-
tandogli l’apprendimento. Questi strumenti sono appetibili perché
risultano efficienti.

Tutto questo, però, avviene a quale prezzo?
Non voglio approfondire le problematiche che questo feno-
meno potrebbe sollevare in termini strettamente pedagogici o so-
ciologici. Infatti, i vantaggi di cui ho provato a dare qualche esempio
devono essere messi a sistema con ricadute negative di più lungo
periodo, concernenti gli effetti che un controllo costante possono
avere sulla crescita personale, sociale ed etica del minore stesso.

Non si può infatti trascurare il rischio di abituare i bambini,
adulti di domani, a vivere in una dimensione di controllo persistente
e capillare, di sorveglianza di massa, accettandola come fosse la nor-
malità, e quindi rinunciando ad una parte fondamentale dei propri
diritti e delle proprie libertà.

È la logica di una società uniformata, conformata, omogeneizzata,

36

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

dove la libertà di cui si è parlato in precedenza, fatta di passione e con-
sapevolezza, va via via sfumando.

Ritengo tuttavia doveroso aggiungere che il tema delle libertà
necessariamente deve essere declinato non soltanto con le categorie
della  consapevolezza,  della  creatività  e  della  responsabilità,  come
detto in precedenza da Vito Mancuso, ma certamente anche con la
categoria dell’eguaglianza.

Soprattutto, nella tradizione culturale e giuridica dell’Occi-
dente, cogliendo l’occasione del fatto che oggi stiamo parlando di
protezione dei dati personali, la categoria della libertà non può pre-
scindere dal valore della dignità della persona. La libertà non può
mai  impattare,  incrociare  e  limitare  la  dignità  della  persona,  e  il
diritto alla protezione dei dati personali, come noto, ha il suo fon-
damento proprio nella tutela della dignità delle persone. Per questo
i temi di oggi sono così importanti.

Infatti, molti dei giocattoli intelligenti di cui oggi si discute
impattano incisivamente sulla protezione dei dati personali. I nu-
merosi e assai penetranti dati raccolti tramite i giocattoli intelligenti
(immagini, voci e pensieri del bambino, sua posizione geografica)
vengono archiviati presso server detenuti da società terze; informa-
zioni che a loro volta possono essere facilmente incrociate con i dati
di  base  (nome,  età,  recapiti)  indicati  dai  genitori  al  momento  di
iscriversi tramite l’applicazione sul telefonino.

Il tema che si pone è allora quello dei Big Data, con tutto il

portato delle criticità che ciò comporta.

In primo luogo, va sottolineato che un Big Data, in estrema
sintesi, rappresenta un’enorme banca dati che si contraddistingue
rispetto ad un archivio statico per il fatto che le informazioni al suo
interno vengono automaticamente interconnesse e rielaborate (deep
learning), in base a imperscrutabili e implacabili algoritmi, per dare
vita  a  informazioni  di  secondo  grado  (data  mining),  riutilizzabili
per altri fini. Se anche volessimo ammettere che tali risultati non
consentono la re-identificazione degli interessati che avevano ini-
zialmente (ed inconsapevolmente) fornito i loro dati “grezzi” – il

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

37

che è tutto da vedere –, sta di fatto che questo perfetto automatismo,
basandosi sulle sole asettiche leggi probabilistiche, potrebbe condurre
a categorizzazioni e classificazioni della società che, oltre ad essere
discutibili sul piano dell’esattezza e della correttezza (come sottoli-
neato dal Presidente Soro nella sua relazione introduttiva), potrebbero
anche  generare  discriminazioni,  giudizi  e  pregiudizi:  ci  piace  una
società, per fare un esempio, in cui è permessa la diffusione di mes-
saggi come il dato, puramente statistico, per cui i bambini italiani
sono più portati a pronunciare parolacce, oppure quelli australiani
a raccontare segreti sui loro genitori, o quelli sudamericani a pre-
sentare difetti di pronuncia? Ma poi, possiamo dire che la realtà è
veramente quella così freddamente descritta? Questo è lo scenario
che si paventa quando la rielaborazione dei dati, anche di quelli rac-
colti tramite bambole o robot interattivi, viene rimessa a calcoli che
scompongono e riassemblano le informazioni secondo logiche non
pienamente decifrabili (si parla infatti di black box).

Visto che si tratta di prodotti per lo più statunitensi, come il
caso Snowden ha dimostrato, tali informazioni sarebbero a disposi-
zione anche delle autorità federali: quindi, al Grande Fratello privato
appena descritto si affianca il Grande Fratello pubblico (e di polizia).
E questo problema si aggrava se pensiamo che si stanno imponendo
sul mercato importanti operatori di ICT provenienti da Paesi non
pienamente in linea con la tradizione liberaldemocratica occidentale,
dove appunto è più facile aspettarsi un occhio governativo ancor
più penetrante rispetto a database sicuramente ritenuti appetibili (e
che contengono anche i nostri dati di consumatori europei).

Un’altra  questione  non  secondaria  è  quella  della  sicurezza:
l’inadeguatezza  delle  misure  di  tecnologiche  adottate  interessa  da
vicino lo stesso uso quotidiano che di questi dispositivi viene fatto.
La trasmissione dei dati raccolti dal giocattolo avviene spesso
tramite connessioni wi-fi o bluetooth prive di idonei certificati di
garanzia,  captabili  abbastanza  facilmente  (ad  esempio,  entro  un
raggio di 10 metri) proprio nella fase iniziale del flusso anche da
parte di “pirati informatici” di medio-basso livello. In alcuni casi le

38

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

forme di accreditamento sono così blandamente presidiate da con-
sentire anche a telefonini diversi da quello del genitore (un passante
che si trova al parco mentre il bimbo sta correndo con il suo pupazzo
intelligente in mano) di utilizzare l’applicazione e quindi intercettare
le  parole  del  minore  e  magari  sfruttare  le  funzionalità  consentite
dall’altoparlante  per  instaurare  addirittura  un  dialogo.  Per  questo
motivo lo scorso febbraio l’Agenzia federale tedesca per le teleco-
municazioni ha bandito dal commercio la bambola My Friend Cayla,
considerandola un vero e proprio strumento di spionaggio, mentre
il Norwegian Consumer Council ha rappresentato, anche con rife-
rimento all’I-Que Intelligent Robot, la facilità con cui è possibile im-
possessarsi del controllo del gioco per chiunque. 

D’altronde, se questi giocattoli devono essere economicamente
accessibili  al  grande  pubblico,  allora  non  è  pensabile  che  siano
protetti da accorgimenti tecnici troppo sofisticati.

A ciò si aggiungono i rischi che attengono alla sicurezza delle
stesse banche dati dove tali immagini, parole e versi di bimbi vengono
convogliati (e quindi oggetto di banale commercializzazione tra pro-
duttore del dispositivo e titolare del server), visto il preoccupante
aumento del fenomeno dell’hackeraggio. Appena un anno fa cyber-
criminali si erano impossessati di 800.000 dati personali e 2 milioni
di registrazioni vocali (quindi, le frasi ed i pensieri dei bambini) rac-
colti tramite gli orsacchiotti Cloud Pets, per poi richiedere un vero e
proprio riscatto alle singole famiglie.

Questi problemi, assieme ad altri (come la scarsa trasparenza
sulle caratteristiche del trattamento, compresa l’identità dei partner
terzi destinatari dei dati), all’estero sono stati evidenziati pubblica-
mente  da  numerose  realtà:  l’FBI  (attraverso  la  divisione  Internet
Crime Complaint Center), autorità pubbliche, soprattutto organiz-
zazioni dei consumatori.

Il BEUC, cioè l’unione a livello europeo delle organizzazioni
di consumatori – di cui Luisa Crisigiovanni (altra relatrice) è uno
dei massimi esponenti – circa un anno fa ha presentato un’apposita
lettera di denuncia in diverse sedi (anche al Gruppo “Articolo 29”).

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

39

Anche per rispondere a queste sollecitazioni, il Garante pochi
giorni  fa  ha  pubblicato  sul  proprio  sito  web  un  vademecum  dal
titolo “Smart toys: i suggerimenti del Garante per giochi a prova di
privacy”. Si tratta di un primo documento di carattere informativo
e di facile comprensione destinato alle famiglie, volto a suggerire al-
cuni  accorgimenti  nell’utilizzo  dei  giochi  intelligenti,  al  fine  di
evitare o comunque minimizzare i rischi che prima ho illustrato.

Se questo è il panorama, seppure tratteggiato in maniera ve-

loce, cosa si può fare?

La protezione dei dati personali, come da sempre postulata
dal legislatore e dal giudice europeo, deve essere necessariamente bi-
lanciata  con  l’esigenza  di  circolazione  delle  informazioni,  quale
espressione ultima delle quattro libertà su cui è costruita e sviluppata
l’Unione europea.

In altre parole, i trattamenti non devono essere aprioristica-
mente impediti, poiché il mercato, in primis quello digitale, deve
trovare lo spazio per crescere. Questi trattamenti però devono essere
collocati in un ambiente sicuro, presidiato da regole chiare e sotto
la severa vigilanza di organismi competenti e indipendenti.

A questa domanda di maggiori garanzie risponde il Regola-
mento Ue 2016/679, che a partire dal 25 maggio 2018 potrà pie-
namente esplicare i suoi effetti.

Di fronte ai problemi posti dagli smart toys, ma più in generale
dall’Internet of Things, posso dire in estrema sintesi che sono due i
principi guida posti dal Regolamento:

1) la minimizzazione dei dati, secondo cui devono essere trat-
tati i dati effettivamente necessari, tralasciando quelli eccedenti e
non pertinenti: quindi, ci si dovrà chiedere quali informazioni sono
effettivamente necessarie per poter attivare il giocattolo con l’appli-
cazione sullo smartphone; quali immagini e suoni è indispensabile
che  vengano  captati,  e  come  questi  devono  essere  tradotti;  quali
dati  effettivamente  identificativi  devono  continuare  a  camminare
lungo l’intera filiera, oppure se questi possano essere anonimizzati o
pseudonimizzati;

40

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

2) l’integrità e riservatezza di dati e sistemi, cioè la garanzia
di una sicurezza adeguata rispetto a trattamenti illeciti o non auto-
rizzati: dunque, dai filtri contro le intercettazioni, anche ambientali
(il  passante  nel  parco),  ai  più  sofisticati  presidi  contro  i  grandi
attacchi cibernetici.

Principi, questi, che fanno da corollario al più generale prin-
cipio di accountability, che, nel lasciare al titolare del trattamento
un più ampio margine di discrezionalità nell’organizzare la propria
attività, al contempo lo responsabilizza maggiormente rispetto ai ri-
sultati da raggiungere in termini di tutela dal rischio di lesioni per i
diritti e le libertà degli interessati.

Nel perseguire questi obiettivi, il Regolamento disciplina una
serie di strumenti e funzioni. In questa occasione vorrei segnalarne
in particolare due:

1)  la privacy by design e by default contribuisce  a  superare
una logica esclusivamente sanzionatoria e successiva, per puntare
sulla prevenzione quale chiave di volta per garantire una tutela del
dato ancora più effettiva. Intervenire in sede di progettazione (by
design) e di implementazione (by default), puntando su accorgimenti
quali la pseudonimizzazione e la minimizzazione dei dati personali,
vuol  dire  risalire  la  catena  del  trattamento  a  monte  rispetto  al
titolare, indirizzandosi così al produttore di una determinata tec-
nologia. Infatti, spesso il titolare si trova a dover ricorrere a dispositivi
già configurati in maniera predefinita, con nulle o limitate possibilità
di modifica delle impostazioni; invece, con la privacy by design e by
default l’intenzione è quella di intervenire sul processo di creazione
e configurazione dei prodotti, al fine di renderli compliant rispetto
alle esigenze di tutela, e quindi prevenire le criticità che si possono
produrre a valle;

2) sul piano della sicurezza, il Regolamento va ben oltre le
misure minime a cui si limita il Codice privacy attualmente vigente,
alzando l’asticella fino al concetto di adeguatezza (del livello di sicu-
rezza) in relazione al rischio (che a sua volta deve essere calcolato in
base a probabilità e gravità). Rientrano pertanto in questa logica la

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

41

già citata pseudonimizzazione, la cifratura dei dati, la resilienza dei
sistemi, piani di disaster recovery e di audit. Ma vi rientra altresì la
procedimentalizzazione  dei  rimedi  di  fronte  ad  episodi  di  data
breach, a partire dalla notifica all’Autorità (obbligatoria, salvo ecce-
zioni) fino alla comunicazione agli interessati stessi (necessaria solo
in alcuni casi).

Tutto ciò, dovrà avvenire sotto la supervisione dell’Autorità
di controllo, in Italia rappresentata dal Garante per la protezione
dei dati personali, che nel nuovo quadro normativo esce sensibil-
mente rafforzata sul piano della vigilanza (penso all’inasprimento
dell’aspetto sanzionatorio) ma altresì su quello regolatorio. 

Di tutto ciò parleremo in questa sessione con i nostri ospiti.
Luisa Crisigiovanni è una personalità nel mondo della tutela con-
sumeristica, in quanto segretario generale di Altroconsumo e mem-
bro dell’Esecutivo del BEUC, l’unione a livello europeo delle or-
ganizzazioni di consumatori.

A lei chiederei se il panorama attuale di giocattoli e oggetti
intelligenti disponibili sul mercato mondiale è veramente così cri-
tico per la libertà e la sicurezza dei loro fruitori, a partire dai bam-
bini, ma anche di quelli indiretti, cioè chi vive intorno ai bambini
e coloro a cui ricondurre l’ambiente circostante allo spazio di gioco
(genitori, fratelli e sorelle, amici, ecc.).

Luisa Crisigiovanni

Buongiorno a tutti. Intanto vi ringrazio dell’invito. Qui oggi
rappresento, come diceva la dottoressa Califano, le associazioni di
consumatori: Altroconsumo in particolare, che è l’associazione con
oltre 390 mila soci in Italia nel 2016, ma anche il BEUC, che è la
federazione cui Altroconsumo appartiene e che stabilmente rap-
presenta in Europa oltre 43 associazioni di consumatori, che cer-
cano di interagire con le istituzioni, sia in relazione all’ambito di
cui  parliamo  oggi,  la  tutela  dei  dati  personali,  che  anche  in 

42

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

relazione  alle  diverse  tematiche  e  diverse  dimensioni  in  cui  si
esprime il diritto dei consumatori. 

Per altro il fatto che io sia anche un membro del bureau ese-
cutivo e suo tesoriere e rappresentante legale di Altroconsumo, mi
fa vivere anche dall’altra parte tutte le responsabilità e gli oneri
della gestione dei dati personali dei nostri stessi soci. 

Sono associazioni indipendenti, quelle che io rappresento
qui, che vuol dire che il 90%, grosso modo, delle nostre risorse
economiche, deriva dalle quote associative. Questo fa sì che ci si
interfacci con il mercato in modo maturo, non tanto con un ap-
proccio paternalista, come è stato detto prima molto bene da chi
mi ha preceduto, perché spesso le regole non bastano. Ci propo-
niamo di essere aperti al dialogo con grossi player perché ci pro-
poniamo di essere degli agenti di cambiamento forti della nostra
indipendenza. Sono stati citati diversi wearables, che sono com-
mercializzati sulle piattaforme come Amazon, ciò ci dice che di-
verse sono le sfide dei dispositivi connessi nel mondo, non solo i
giocattoli. 

Secondo dati della Commissione europea 31 miliardi entro
il 2020 e 75 miliardi entro il 2025 saranno i dispositivi connessi,
quindi non solo i giocattoli, ma anche le auto e chissà quant’altro,
magari anche i vestiti che misureranno dal battito cardiaco alla
pressione sanguigna. Con la crescita dell’Internet delle cose, a cui
Altroconsumo ha dedicato un festival all’inizio di novembre 2017
occorre far crescere la consapevolezza che gli oggetti interconnessi
ci possono facilitare la vita, ma possono chiaramente portare anche
dei rischi. Tali rischi sono connessi non soltanto alla tutela della
privacy ma, appunto, anche alla sicurezza. Si stima ci siano stati
oltre 4000 attacchi al giorno e questo è un aumento del 300% ri-
spetto al 2015. Secondo i dati di un rapporto di Eurobarometro
sulla cybersecurity del settembre 2017 l’86% dei consumatori ri-
tiene che il rischio di diventare vittima di un crimine informatico
sia in aumento. Anche rispetto a questo nuovo timore, spesso ab-
biamo un atteggiamento quasi rassegnato. 

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

43

Sicuramente dovremmo essere capaci di educare meglio i con-
sumatori a tenere puliti i propri device dai virus, dovessi utilizzare una
metafora di Agid, tanto quanto si cerca di tenere pulito il cavo orale
lavandosi i denti. L’atteggiamento ed il monito a prevenire deve essere
trasferito anche ai minori. Però spesso la generazione di mezzo, quella
parentale, non ha tutte le competenze e neanche il riflesso di farlo,
perché non appartiene alla generazione dei millennial, non siamo tutti
nativi digitali. Questa mia introduzione è partita dai dati che sono
stati illustrati dal BEUC in Parlamento europeo qualche settimana fa
e a mio avviso costituiscono lo scenario in cui si collocano i casi dei
giocattoli intelligenti. Gli smartwatch ad esempio sono stati concepiti
per rassicurare i genitori rispetto agli spostamenti di bambini non così
grandi da gestire un telefonino, benché abbiano molte caratteristiche
di un portatile perché, come è stato ricordato, sono collegati ad Inter-
net e presentano diversi problemi di sicurezza. Vi faccio vedere tra
poco un brevissimo filmato, realizzato dall’Organizzazione dei consu-
matori norvegese per promuovere campagna #Watchout sui rischi dei
giocattoli interconnessi. Il messaggio che attraverso la campagna si
cerca di veicolare è quello di una maggiore consapevolezza su come i
bambini siano esposti alla possibilità di essere geolocalizzati altrove e
di essere hackerati da persone che possono guidarli dove vogliono o
comunque simulare il numero di telefono del genitore. 

44

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Esattamente l’opposto di quello per cui sono stati concepiti. 

Ovviamente hanno fallito sia i test sulle condizioni generali
di contratto che quelli sulla tutela dei dati personali: i dati non ven-
gono cancellati dopo un tempo predefinito, la cronologia delle po-
sizioni è facilmente accessibile all’esterno e non è stato assolutamente
rispettato quanto si diceva prima, la proporzionalità della raccolta
dei dati e le finalità per cui sarebbero stati raccolti. Il paradosso è
che viene meno proprio il senso di libertà che avrebbe dovuto assi-
curare questo tipo di tecnologia, visto che vengono registrati indirizzi
e simulati percorsi. 

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

45

Il potenziale mercato di questi wearables, date comunque le
diverse applicazioni positive legate alla telemedicina rappresenta tut-
tavia una crescita che sarà davvero esponenziale: +92% fino al 2020.
Attualmente ci sono circa 125 milioni di questi orologi o si-
mili, o magliette, o altri dispositivi nati magari per il fitness fino ad
arrivare a stimolare anche degli stili di vita corretti, come fossero dei
coach. Alcuni di questi tuttavia, registrando dati sensibili sulla nostra
salute, se male utilizzati potrebbero portare a discriminazioni in
campo assicurativo. 

46

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Quegli stessi dati utilizzati in modo aggregato possono allo stesso
modo diventare big data e favorire la ricerca e la prevenzione di patologie. 
In realtà, quindi, bisogna trovare un equilibrio e soprattutto ac-
cettare che queste sfide comportano di fatto uno sforzo supplementare
da parte sia delle aziende, sia delle organizzazioni dei consumatori, sia
anche dei regolatori. In Europa spesso si dice che bisogna abbandonare
silo thinking perché le sfide che abbiamo di fronte non sono solo regola-
torie, ma si vincono con creatività, con approcci trasversali, sfruttando
soluzioni tecnologiche senza esserne schiavi.

Un altro esempio di oggetto interconnesso è rappresentato dalla
ormai famosissima Cayla, una bambola che sempre i colleghi del Consiglio
norvegese hanno testato. Anche qui sono stati scoperti seri problemi di
sicurezza perché l’interazione, il dialogo tra la bambola e i bambini poteva
essere intercettato da chiunque. Dopo circa due anni solo due Stati mem-
bri, Germania e Francia, hanno preso davvero provvedimenti per richia-
mare questo giocattolo dal mercato. È vero che nel nostro Paese Cayla
non era commercializzata, ma si poteva pur sempre comprare online.

Poiché siamo anche consumatori digitali, in realtà bisogna fare in
modo innanzitutto che non ci siano prodotti non sicuri messi in circola-
zione online e offline e in secondo luogo, che quando ci sono provvedi-
menti di ritiro siano meglio comunicati. Questo è stato un caso abbastanza

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

47

virale e ben conosciuto, ma è bene le autorità intervengano in modo co-
ordinato per evitare che siano in circolazione prodotti non sicuri.

I problemi di sicurezza secondo i colleghi di altre associazioni
di consumatori europee persistono e solo in alcuni casi ci sono state
delle reazioni anche volontarie di ritiro sia di robot che della bambola.
In Europa si sta rimettendo mano al regolamento sulla sicu-
rezza generale dei prodotti che ovviamente non è stato pensato a suo
tempo per prodotti che avessero dentro di loro dei software, ma
ormai siamo circondati dagli smart meter, da tutta la tecnologia degli
apparati più complessi, quindi bisogna attrezzarsi anche legislativa-
mente, per affrontare questi problemi legati alla sicurezza anche in-
formatica dei prodotti, non solo meccanica. 

48

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Questa è un’altra delle sfide che abbiamo di fronte e speriamo
che anche da questa Autorità possa arrivare un sostegno affinché il
legislatore europeo pensi in questi termini, quindi con una legisla-
zione che sia future-proof da questo punto di vista, assicurando una
tutela by default e by design come è stato detto prima. 

Il professore che mi ha preceduta ha citato un’indagine stati-
stica che ha investigato un campione di 995 utenti Internet tra i 18
e i 64 anni che si è svolta nel maggio 2017. Era un’indagine condotta
da Altroconsumo perché è vero che ci sono le aziende, è vero che ci
sono i regolatori, ma, appunto, siamo tutti consumatori e dobbiamo
essere consumatori sempre più consapevoli. È vero che è un mestiere
a tempo pieno perché è un mondo sempre più complesso, però dob-
biamo fare anche noi la nostra parte. Noi come organizzazione dei
consumatori, come abbiamo detto prima, non possiamo più per-
metterci di avere un approccio paternalista per questo vogliamo far
parlare i numeri e i fatti.

Il fatto è che il 91% delle persone che abbiamo intervistato
non legge o non legge attentamente le condizioni generali di con-
tratto quando scarica una app. Questo perché ovviamente tutti noi
quando abbiamo bisogno di quell’app in un dato momento, quel
bisogno è prevalente. Bypassiamo, quindi, quello che il legislatore
con tanta fatica ha messo in piedi, magari collaborando con le stesse

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

49

organizzazioni dei consumatori. Ma il consumatore non legge le
clausole forse perché sono troppo lunghe. Qualcuno diceva che forse
c’è un problema di confusione; forse c’è un problema di non ade-
guatezza dello strumento rispetto alla regola. È per questo che si deve
ragionare sempre con un atteggiamento proiettato verso il futuro o
semplicemente attento all’implementazione delle stesse regole, per-
ché a nulla servono se rimangono sulla carta.

L’84%, si dice, vorrebbe poter ridefinire le proprie imposta-
zioni ma spesso non è semplice farlo, sono dei contratti standard, se
vuoi quel servizio devi accettare per poter andare avanti e avere ac-
cesso a tale servizio.

Un dato interessante, però, è che il 60% delle persone pensa

di dover essere ricompensata per il valore creato dai dati rilasciati.

In un certo senso, quindi, si fa avanti la consapevolezza del
valore economico dei propri dati perché viviamo in una società di-
gitale che, come è stato detto più volte, di questi dati fa il massimo
motore del proprio sviluppo anticipando i nostri bisogni. 

È nel giugno scorso che in Europa è stata lanciata da diverse
organizzazioni europee Deco, Test Achat, Ocu e Altroconsumo una
petizione My data is mine! #imieidaticontano che intendeva promuo-
vere da una parte il riconoscimento del valore economico del dato e
dall’altra il diritto alla portabilità. Abbiamo raccolto circa 3.000

50

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

firme, ma il fine era principalmente creare consapevolezza e sensibi-
lizzare le persone rispetto a qualcosa cui non abbiamo fin d’ora at-
tribuito valore.

Infine, insieme alle altre organizzazioni europee, non solo
BEUC ma anche Consumers International, ANEC (che si occupa
di standardizzazione) e ICRT che sviluppa test e ricerche compara-
tive, abbiamo redatto nel novembre 2017 una serie di raccomanda-
zioni  volte  a  migliorare  la  sicurezza  dell’Internet  delle  cose,
richiedendo che le diverse dimensioni, quella tecnica, quella giuri-
dica e se volete anche quella legata ai codici di condotta delle im-
prese, possano essere integrate. 

Le organizzazioni svolgono i loro test in modo indipendente
sostanzialmente per assicurarsi, anche attraverso i progetti di ricerca
europei, che i prodotti rispettino le norme e siano prodotti inter-
connessi attraverso i quali la raccolta dei dati venga fatta in modo
sicuro e appropriato nell’interesse dei consumatori. Se si tratta di un
giocattolo, quindi, deve rimanere un giocattolo e avere tutte le ca-
ratteristiche adatte al fatto che verrà utilizzato da un minore di una
determinata età.

Come è stato ricordato in mattinata, laddove non arrivano le
regole però deve intervenire l’etica, devono intervenire i valori, che
però non possono essere solo dei proclami di giustizia, di libertà, 

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

51

di efficienza, ma devono vedere le varie parti in gioco collaborare,
pronte a fare ognuna la propria parte. 

Termino il mio intervento invitandovi a vedere il famoso
video di Cayla disponibile su youtube, che ha ricevuto anche un pre-
mio come una delle migliori campagne di sensibilizzazione europee
#Toyfail campaign. 

Licia Califano

L’altro relatore è Massimo Sideri, noto giornalista del Corriere
della Sera, sia in qualità di editorialista che di responsabile del ma-
gazine “Corriere Innovazione”, ed esperto di economia, innovazione,
tecnologie e telecomunicazioni.

Vorrei approfittare della presenza di un giornalista proprio
per sottolineare la rilevanza centrale dell’informazione, anche critica,
nei confronti dei cittadini sugli sviluppi e sulle potenzialità dell’IoT,
ma anche sui limiti degli scenari prossimi futuri come quelli che con-
cernono la robotica e l’intelligenza artificiale. Prendendo spunto
dalla sua ultima pubblicazione dedicata al diritto all’oblio e al con-
trapposto diritto alla memoria (“Diritto all’oblio, dovere della memo-
ria. L’etica nella società interconnessa”, 2017, realizzata assieme ad
Umberto Ambrosoli), vorrei chiedere a Massimo Sideri come sarà

52

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

possibile declinare l’efficienza assicurata dalle incalzanti conquiste
tecnologiche con valori insopprimibili quali la libertà e la dignità
della persona.

Massimo Sideri

L’elemento chiave che è emerso sino ad ora, e che in qualche
maniera rientra anche in questa domanda, è che esiste una tensione
molto forte tra questi due argomenti che appaiono contrapposti. Ma
dal punto di vista giornalistico noto che c’è stato un processo di ma-
turazione sia da parte di chi scrive sia da parte di chi legge. Se ricor-
date, sino a poco tempo fa, si assisteva normalmente a posizioni
contrapposte tra chi era assolutamente ottimista e che difendeva la
tecnologia a spada tratta e chi invece rasentava il luddismo.

Oggi ci stiamo rendendo conto che in realtà la tecnologia
ha in nuce una tensione molto forte ma che questi due opposti
non sono separabili. Ha detto bene il professor Mancuso prima,
parlando di uomo, che è fatto di “ignoranza e meraviglia”. I ter-
mini “ignoranza e meraviglia” mi hanno risvegliato purtroppo
un’esperienza personale che ho avuto. A un certo punto il profes-
sore ha detto: “Tutti voi sapete quello che è successo nel 1633”.
Io non lo ricordavo, allora ho fatto quello che facciamo
tutti in maniera compulsiva, sempre più diffusamente: sono an-
dato su Google e ho inserito “1633”. È uscito “processo a Galileo
Galilei”, la risposta giusta.

Qui c’è l’ignoranza dell’uomo, nella fattispecie Massimo Si-
deri, e c’è la meraviglia della tecnologia, dell’algoritmo Google che
riesce a dare immediatamente la risposta. Questa contrapposizione
tra ignoranza e meraviglia in qualche maniera è quello che ci spinge
anche a sperimentare la tecnologia, ci spinge anche a provarla e ad
essere curiosi, ma allo stesso tempo dovrebbe essere anche in qual-
che maniera l’elemento che ci spinge a stare attenti nel nostro rap-
porto con essa.

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

53

Questo contrasto tra uomo e macchina ritorna sempre nella
storia: faceva parte già della conoscenza degli antichi. Si dice che il
dio della tecnologia fosse Prometeo che, ricorderete, era la divinità
che aveva rubato il fuoco per darlo agli esseri umani. Allo stesso
tempo, regalando la tecnologia del fuoco agli esseri umani, era stato
però punito dagli altri dei perché aveva portato una capacità tecno-
logica dal mondo divino al mondo degli esseri umani. 

Evidentemente già nel mito antico c’era la consapevolezza che
la tecnologia aveva al proprio interno una tensione molto forte, po-
teva portare benefici ma anche disgrazie, sofferenze, esattamente
come era accaduto a Prometeo.

Questa tensione ritorna nella storia e la troviamo nella lette-
ratura. Cito en passant soltanto Cˇapek, scrittore ceco del 1920, che
è molto importante perché la parola “robot” è un neologismo che
nasce proprio dal suo libro R.U.R., peraltro una pièce teatrale molto
divertente. Consiglio sempre la lettura del racconto: siamo nel 1920,
poco dopo la rivoluzione russa, e ci sono questi robot umanoidi che
lavorano come schiavi per gli esseri umani. Succede quello che potete
immaginare visto il clima storico in cui è calato: i robot formano il
primo sindacato dei robot. Anche lì emerge questa tensione, questo
conflitto tra uomo e macchina che ritorna nella storia.

Ma non potendo far concorrenza al professor Mancuso sui
temi della divinità, visto che non ne ho assolutamente le capacità,
vi parlo di tecnica, regolamentazione e necessità, che secondo me
sono i tre elementi chiave che sono emersi anche dall’introduzione
del Presidente Soro. Oggi il dibattito è se dobbiamo regolamentare
la tecnologia. Questo è un elemento molto sensibile: Me ne rendo
conto perché, ogni volta che scrivo di regolamentare la tecnologia,
chiaramente le reazioni sono molto forti e differenziate in base anche
alla generazione di appartenenza. Qui mi sembra che siamo tutti ap-
partenenti a quelli che io definisco “NAID”, nativi analogici invec-
chiati digitali, vedo poche persone nate veramente digitali. Diciamo
che in noi “NAID” c’è una percezione anche più prudente e attenta.
Io faccio parte anche del progetto alternanza scuola–lavoro 

54

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

e quando parlo ai liceali di regolamentare la tecnologia vedo le loro
facce preoccupate perché la tecnologia, nelle loro menti, non va as-
solutamente regolamentata. Vengo visto quasi come un luddista.

Per raccontare questo legame tra tecnica, regolamentazione e
anche stato di necessità, che è l’elemento chiave del mio intervento,
mi rifaccio alla storia. Non a caso: credo che tante cose siano state di-
sintermediate ma non la storia, che ancora ci aiuta a comprendere que-
sto mondo. E visto che dobbiamo ricollegarci al mondo dei giocattoli,
come cita il titolo del nostro intervento, vi parlo della bicicletta. La
storia della bicicletta racconta meglio di altre quella che chiamo la
“curva dell’innovazione”. È molto interessante perché la bicicletta è il
giocattolo per eccellenza. Oggi i bambini stanno più spesso sullo smar-
tphone ma il fascino della bicicletta continua a rimanere molto forte,
un bambino si sente già adulto quando inizia finalmente ad andare
sulla bicicletta a 6-7 anni. La bicicletta, quindi, rimane secondo me il
simbolo di questo nostro rapporto con la tecnica.

Noi parliamo di giocattoli intelligenti ma che cos’è la Google
car se non un grande giocattolo per adulti? Se la guardate come im-
magine è effettivamente un giocattolone, è stata disegnata e proget-
tata come un giocattolone. 

Questo rapporto tra bambini e giocattoli in realtà dovrebbe
essere ampliato. L’Internet delle cose rischia di essere un mondo di
grandi giocattoli non solo per bambini ma anche per adulti.

Raccontando la storia della bicicletta può emergere la neces-
sità e anche l’importanza della regolamentazione. La bicicletta nasce
201 anni fa, nel 1817, e la storia è molto interessante perché nasce
come risposta a uno stato di necessità. Nel 1815 esplode il vulcano
Tambora in Indonesia, il cielo viene oscurato in tutta Europa, c’è
una moria di cavalli – allora il mezzo di trasporto fondamentale per
l’essere umano – quindi il conte Drais pensa a un mezzo che possa
sostituire il cavallo nel trasportare l’essere umano. Nasce così la drai-
sina, come la chiameranno i francesi dal nome del conte Drais, che
è quella che usano ancora oggi i bambini, cioè senza pedali e che ri-
chiede la spinta al suolo con le gambe.

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

55

Nel 1818 a Milano viene regolamentato l’utilizzo della bici-
cletta, c’è quindi un editto regio che dice che non si può usare la
draisina in determinate condizioni. Perché interviene un editto regio?
Facile, perché c’era la novità della tecnologia e chi usava la bi-
cicletta investiva le persone. Si interviene con un editto regio perché
c’è la tecnologia ma non c’è la conoscenza né la capacità di utilizzarla
bene, quindi iniziano ad esserci molti incidenti. Ricordate che in
quel momento non ci sono i pedali e non ci sono nemmeno i freni,
quindi la tecnologia c’è ma non si è evoluta. Pensate che la prima
multa per la bicicletta arriva nel 1842, quindi devono passare diversi
anni. Almeno è la prima multa che ricorda la storia. 

In Scozia un ciclista investe un bambino, gli fa molto male e

gli viene comminata la prima multa di 5 scellini. 

Macmillan fu il primo ciclista multato della storia.
Nel 1861 un francese porta a riparare dal fabbro la propria
draisina e qui succede una cosa molto interessante. Il figlio del fabbro
prova la draisina e dice: è totalmente inefficiente, faccio fatica, devo
spingere con i piedi, ci vorrebbe qualcosa di più efficace. 

Il figlio insieme col padre introducono il concetto del pedale.
Questa è quella che io chiamo la “curva dell’innovazione”:
1817 arriva la tecnologia, 1818 arriva la prima regolamentazione,
1842 arriva la prima multa, 1861 finalmente la tecnologia si evolve.
Secondo me questo schema può essere utilizzato anche oggi,
anche se ci appare in qualche maniera non adatto, perché noi par-
liamo dell’Internet delle cose come di una tecnologia matura, ma in
realtà è una tecnologia molto giovane. Lo vediamo anche dalla rea-
zione dei soggetti che gestiscono questo mondo.

Pensate alla maturazione che va riconosciuta in persone come
Marc  Zuckerberg,  il  fondatore  di  Facebook,  soltanto  nell’ultimo
anno. Ricorderete che, dopo il tema delle elezioni di Trump negli
Stati Uniti, Zuckerberg disse: “Facebook non c’entra assolutamente
nulla, noi siamo una tecnologia neutrale”. Dopo un po’ il caso delle
fake news e dell’influenza che possono avere sulle elezioni emerse for-
temente e Zuckerberg intervenne di nuovo dicendo: effettivamente

56

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

forse dovremmo fare qualcosa anche se non si spinge a dire che non
sia neutrale. È l’altro elemento che ha richiamato il professor Soro: la
neutralità della tecnologia, che è una chimera evidentemente; a noi è
chiaro ma non è chiaro a tutti, soprattutto al mercato.

Leggevo anche stamattina che per le elezioni italiane è stata
introdotta una squadra esterna proprio in Facebook che dovrebbe
aiutare a comprendere e a controllare se ci sono delle notizie false
nel processo che ci porterà verso le elezioni. È evidente che se guar-
diamo alla tecnologia odierna non siamo alla bicicletta con tutti i
pedali e con i freni, siamo forse alla draisina. Internet ci appare già
come una bicicletta totalmente completa, ma sbagliamo.

L’altro elemento che secondo me è chiaro per comprendere
questo mondo è lo stato di necessità. L’innovazione spesso è legata
al concetto di necessità (abbiamo detto che la bicicletta nasce per la
moria di cavalli). Ne parlavamo anche prima, la bambola Cayla, che

in qualche maniera è la piccola sorella ‒ siamo passati dal grande
fratello orwelliano alla piccola sorella ‒ entra in casa e spia i nostri

bambini, ma potrebbe anche essere necessaria, potrebbe avere delle
funzioni molto utili: un giocattolo che finalmente parla con un per-
fetto accento oxfordiano ai nostri bambini potrebbe effettivamente
essere quella che viene chiamata una killer application: in pochissimi
anni i nostri figli potrebbero parlare tutti benissimo inglese. 

Questo sarebbe un risultato sociale e culturale molto impor-
tante. È quindi evidente che lo stato di necessità spesso è un ele-
mento chiave in questo contesto.

Allora: perché dobbiamo regolamentare? Ovviamente questa
è la mia opinione, che difendo. Dobbiamo regolamentare perché un
altro elemento che ha sempre caratterizzato l’essere umano è la pi-
grizia. È stato citato prima anche dal professor Mancuso l’otium, la
pigrizia è il grande elemento creativo dell’essere umano. È la stessa
cosa che torna quando vediamo quello studio di Altroconsumo che
mi sembra anche ottimista, perché asserisce che più del 91% dice di
non leggere la normativa del contratto quando apre un’applicazione.
Io direi che probabilmente è il 99,9%. Forse qualcuno inizia

G i o c a t t o l i   i n t e l l i g e n t i   e   o g g e t t i   c h e   c i   s o r v e g l i a n o

57

a leggere le prime tre righe. D’altra parte sono contratti complica-
tissimi e lunghi. Ho seguito per il Corriere della Sera i casi Parmalat,
Cirio, tutti i grandi crac finanziari, e quelli attuali delle app mi ri-
cordano i contratti che c’erano tra banche e aziende al tempo quando
ti vendevano un’obbligazione della Parmalat. Era impossibile com-
prendere qualcosa, anche con due master in finanza.

In qualche maniera, quindi, l’elemento della pigrizia secondo
me è un elemento chiave perché ci dovrebbe indurre a pensare che
non possiamo demandare all’individuo la difesa della privacy, ma ci
deve essere un cappello molto forte, che appunto può essere quello
della privacy by design, che andrà raffinato. Deve esserci comunque
un cappello che va oltre l’individuo perché è evidente che queste so-
cietà sanno che noi esseri umani siamo pigri e quindi l’introduzione
di questi giocattoli non solo per bambini ma, come dicevamo, anche
per adulti, con tutte le impostazioni della privacy aperte, fanno sì
che probabilmente tutti noi, pur avendo maturato una consapevo-
lezza molto forte, non riusciremo a stare dietro a questo mondo che
sta cambiando così velocemente.

Concludo dicendo che sono assolutamente favorevole a una
regolamentazione perché mi sembra l’unico modo per dare in qual-
che maniera anche un aiuto, mi permetto di dire, allo sviluppo della
tecnologia. Esattamente come è avvenuto con la bicicletta dove forse
anche l’arrivo delle prime regolamentazioni e delle prime multe ha
aiutato lo sviluppo della tecnologia in maniera tale che divenisse uno
dei giocatori più belli della storia. Grazie.

58

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Corpo elettronico 
e tecnologie indossabili

SESSIONE III

Edoardo Fleischner

Francesco Grillo

Coordina: Giovanna Bianchi Clerici

Componente del Garante 

per la protezione dei dati personali

Sessione III
Corpo elettronico 
e tecnologie indossabili

Giovanna Bianchi Clerici

Cominciamo ora il terzo segmento di questa mattinata. 
Inizierei presentando i due ospiti che hanno cortesemente

accettato il nostro invito.

Si tratta, alla mia destra, del professor Edoardo Fleischner,
docente di Nuovi media e comunicazione all’Università statale
di Milano e di Scrittura crossmediale al Politecnico della cultura
di Milano. È consulente per aziende e istituzioni, progettista e
autore per tv digitale e Web, cura programmi di successo come
quello in onda su Radio Radicale dal titolo “Media e dintorni”,
collabora  con  Rai  News.  È  Vicepresidente  della  società  Neos
Logos, impresa sociale senza finalità di lucro fondata nel 2011
con l’obiettivo di diffondere la cultura e la fruizione del patri-
monio culturale dei territori, stimolare la formazione, la ricerca
scientifica e lo sviluppo di progetti partecipati o coprodotti tra-
mite l’utilizzo di tecnologie interattive e multi-device capaci di
facilitare la comunicazione.

Il secondo ospite è il professor Francesco Grillo, docente
presso la Scuola superiore Sant’Anna di Pisa e il St Antony’s Col-
lege di Oxford. Durante il dottorato presso la London School of
Economics si è occupato degli investimenti pubblici in ricerca e
sviluppo. Amministratore delegato della società di consulenza Vi-
sion & Value che gestisce progetti per multinazionali e istituzioni
pubbliche tra cui la Commissione europea, la Presidenza del Con-
siglio e il Ministero dell’economia. Direttore del Think Tank Vi-
sion dove dirige progetti sull’università del futuro e l’innovazione
sociale. Consigliere del Ministro per l’educazione. Editorialista di

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

63

alcuni giornali tra cui il Corriere della Sera, si occupa in partico-
lare di argomenti relativi a economia e politica internazionale e
agli effetti delle tecnologie, dell’informazione e della comunica-
zione, nonché alla sfida dell’integrazione corpo e macchina, che è
il tema di cui ci occupiamo proprio oggi in questa ultima sessione.
Vorrei introdurre il tema con qualche rapidissima considerazione. 
Il proprio corpo è la prima cosa attraverso cui un bambino
conosce sé stesso. Si afferra un piede, si tocca il naso, scopre i
movimenti ed il funzionamento della mano. Attraverso il corpo
sperimenta i cinque sensi ed esplora la tridimensionalità della
realtà circostante. Col tempo comprenderà sempre più piena-
mente le potenzialità ed i limiti del proprio corpo, che per alcuni
sono quelle di Usain Bolt, per altri quelli dell’uomo comune,
ma comunque dettati dalla natura e contenuti entro l’umana-
mente possibile.

Il corpo umano è il metro che abbiamo avuto per afferrare
appieno la fisica: il tempo scorre solo in avanti e mai indietro, se
avvicino il dito alla fiamma mi scotto, se abbasso il tono della
voce nelle ultime file non mi sentono più, se mi rompo il menisco
dovrò rinunciare a gareggiare in uno slalom gigante, ma anche la
consapevolezza che per visitare le Piramidi devo recarmi fisica-
mente in Egitto, che non riesco a vedere dietro la mia testa, che
per conoscere cosa desidera qualcuno devo chiederglielo perché
non sono in grado di leggere nella sua mente e che il ricordo di
un fatto, per quanto importante, pian piano che passa il tempo
si fa sempre più sfumato nei suoi dettagli. E tutto ciò a causa di,
o grazie a come è fatto il nostro corpo ed a come funzionano i
nostri organi.

Il corpo è una parte importante della nostra identità, la fi-
sicità  della  persona:  attraverso  di  esso,  come  dicevamo,  cono-
sciamo noi stessi e ci presentiamo agli altri. Anche l’educazione
della nostra anima, intellettuale e spirituale, è condizionata dalla
coscienza di quei limiti e di quelle potenzialità.

Nei primi anni 2000, Stefano Rodotà parlò per la prima
volta in Italia di “corpo elettronico”: quasi vent’anni fa, il grande

64

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

giurista guardava a certe prospettive come ai confini di un mondo
futuribile, ma soltanto ipotizzabile e s’interrogava sulle trasfor-
mazioni di un’identità umana che vivesse la realtà attraverso un
corpo dotato di potenziamenti tecnologici applicati direttamente
su di esso.

Quelle che per Rodotà erano soltanto congetture, sono per
noi attualità: i Google Glass sono addirittura già caduti in disgra-
zia, i visori 3D sono stati fra i luxury toys più richiesti per Natale
in America, iHealth è il ramo di Apple che produce gadget ed ap-
plicazioni per iPhone e iWatch che rilevano battito cardiaco, pres-
sione  arteriosa,  composizione  della  massa  corporea,  glicemia,
l’attività  fisica  che  facciamo  durante  il  giorno  e  la  qualità  del
sonno nella notte e che, connettendo tutti questi dati, possono
stilare un quadro del nostro stato di salute in costante aggiorna-
mento, da condividere in tempo reale col nostro medico curante
e, perché no, anche con l’assicuratore. 

La biorobotica ci consente di avere braccia in grado di sol-
levare sei volte il nostro peso, di scavalcare muri, di ridare l’udito
ai sordi e la motilità ad un paraplegico. E poi i microchip, quanto
possono facilitarci la vita! Niente più documenti d’identità, pre-
lievi del sangue, disorientamento, utilizzo di denaro contante o
carte di credito, pubblicità che non c’interessa. 

Indumenti intelligenti, che percepiscono l’ambiente circo-
stante e ci riscaldano quando fa freddo o rinfrescano quando fa
caldo, reagiscono alle condizioni meteo o ai nostri stati d’animo,
ci proteggono dagli urti ed interagiscono fra loro scambiandosi
informazioni, registrando molto meglio di noi immagini e suoni
del presente, sicché, nel futuro, del nostro passato non ci sfugga
più nulla.

Che cosa è tutto questo se non un insieme di espansioni
del nostro corpo fisico? I limiti di cui dicevamo si spostano sempre
più in là e, come un bambino, dobbiamo riprendere le misure di
una nuova realtà, che infatti chiamiamo aumentata. 

Professor Fleischner, prego.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

65

Edoardo Fleischner

Il corpo “Smart Vitruvian” crea la nuova specie umana

dell’“Artificial sapiens”

La mia storia inizia da questo logo. Complimenti, è esatta-
mente il filo conduttore di tutta la conversazione che si è dipanata
oggi. I miei complimenti per come questo visual ha intuito in anti-
cipo la sintesi di tutte le narrazioni di questo libro.

Volevo ricordare che comunque, al di là di tutti i nuovi de-
vice e le nuove apparecchiature che ci mettiamo addosso, cosid-
dette “wearable”, tutti noi abbiamo un oggetto, lo smartphone,
che è molto wearable, perché lo abbiamo sempre in tasca, lo in-
dossiamo, c’è chi lo porta puntualmente anche a letto, lo tiene
addosso nel sonno. Lo confermano tante ricerche: gran parte di
noi porta lo smartphone a letto, lo indossa come una camicia. 

È un piccolo pezzettino di metalli, anche preziosi, ma di
fatto è una camicia. Lo curiamo come una camicia, lo laviamo, lo
cambiamo spesso.

Torniamo al logo dello sdoppiamento del Vitruviano digitale.
Il Vitruviano vinciano estrude il Vitruviano digitale che è punti-
forme, perché fatto di bit. Il Vitruviano digitale è pieno zeppo di
dati – in entrata e in uscita – perché ora indossa un cellulare, nella

66

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

maggior parte dei casi uno smartphone, che abbiamo detto, è come
una camicia, è nel taschino della camicia.

Ora aggiungiamo uno smart watch che offre al vitruviano di
tutto (appuntamenti, letture, musica, percorsi, battiti cardiaci, ecc.).
Il vitruviano lo guarda parecchie volte al giorno, per il cellulare la
media è di 150 volte al giorno, l’orologio un po’ di più. Questo vi-
truviano incomincia quindi a indossare due oggetti e inizia a fornire
a mille soggetti esterni i propri dati. Produce Big Data.

Arrivano poi i fitness checker e chi li usa sa a che cosa ser-
vono: numero di calorie che si consumato, i metri percorsi, dove

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

67

ci si trova, i luoghi attraversati, quante volte si fa un dato percorso.
Sono wearable al polso, all’avambraccio, alle caviglie, nelle scarpe.
E se si indossa una cintura, la cintura è “smart”, ovviamente.

La cintura ha un piccolo trasmettitore (si scelga una delle tante
tecnologie disponibili) diventando così una “cosa” connessa ad Inter-
net, alla IoT, all’“Internet of Things. Così magari la lunghezza della
cintura e l’altezza del vitruviano che la indossa, avviseranno il vitru-
viano che se perdesse 4-5 chili sarebbe meglio. E qualcuno, forse in
molti, lo sanno già. Il vitruviano se ne accorge subito, mentre ancora
sta correndo gli arrivano messaggi e inviti a usare una certa dieta, un
certo prodotto alimentare, acquistabile proprio nel supermercato gi-
rato l’angolo, gli indica il navigatore verbale.

Oggetti utili, sia ben chiaro, per esempio per l’enorme mac-
china della sanità. Oggetti che offrono alla grande macchina della
sanità zettabyte di big data per la prevenzione di massa delle ma-
lattie cardiocircolatorie, dell’obesità, ecc.. I preziosi big data fanno
risparmiare una volta raccolti, sistematizzati e interpretati, un’im-
mensa quantità di soldi, visto che la sanità è la prima voce di spesa
in tutte le società cosiddette avanzate. 

A questo non possono non aggiungersi gli “smart glass” che ag-
giungono alla normale visione dei nostri occhi tanta “augmented reality,
realtà aumentata: segnalazioni sul traffico, spiegazioni su un monu-

6 8

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

mento che guardiamo, frecce che indicano un ristorante vegano, perché
qualcuno sa che il nostro vitruviano che li indossa è proprio vegano.

Gli occhiali faranno vedere quali manifesti ci interessano. Quelli di
propaganda elettorale non si usano più, ma quelli pubblicitari sì. E mentre
noi giriamo la testa perché interessati a una vetrina e guardiamo un’auto
più del tempo che serve per schivarla, oppure saliamo su un autobus che
va verso il centro, gli smart glass ci dicono quanto costano i modelli non in
vetrina, il costo e le rate per acquistare quell’auto e quanti minuti e secondi
ci impiegherà il bus ad arrivare a destinazione, mentre ci vengono forniti
tutti questi dati, saremo noi, negli stessi istanti, a fornirne molti di più, in
tempo reale, a cumulare nelle casseforti dei dati ancora tanti bei big data.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

69

Il nostro vitruviano sta indossando altri “smart devices”: cerotti,
che mandano segnali elettrocardiaci (non solo per i cardiopatici), mi-
surano la temperatura, l’acido lattico per gli sportivi, l’attività cerebrale,
l’idratazione della pelle per gli anziani e per i neonati. Tutto sotto con-
trollo, insomma. Coprono sempre più il corpo del nostro vitruviano.
Alcuni di questi saranno utilissimi, come si è detto, per esempio
per la telemedicina da casa, per la prevenzione. Anche loro sono sempre
attivissimi nella raccolta dei nostri dati, che vanno a comporre i gigan-
teschi silos dei soliti big data.

Ci sono poi i dati identificativi, che conosciamo tutti: il badge
con foto, i dati biometrici, l’iride, le impronte digitali, la voce, la faccia
tutta intera. Il nostro vitruviano si sta coprendo sempre di più di wea-
rable, di oggetti indossati.

Non voglio stare a Pechino
Il riconoscimento facciale fa esclamare al vitruviano digitale

“Non voglio stare a Pechino!” 

Molti avranno letto l’inchiesta del giornalista della BBC che è
andato a Pechino, una città di 22 milioni di abitanti, superficie circa
come il Lazio, dove ogni giorno arrivano 10 milioni di pendolari. Quel
giornalista ha voluto fare una prova. È andato alla centrale di Polizia, ha
consegnato  la  sua  carta  d’identità  con  la  foto  frontale,  tipica  degli 

70

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

strumenti di identità di solito abbastanza inespressivi (non si può sorri-
dere, non si può stare di profilo), e ha detto: adesso mi butto in Pechino,
in questo momento del giorno con 32 milioni di persone, vediamo
quanto tempo ci impiegate ad arrestarmi. Parte il cronometro, lui si
butta dentro Pechino, quindi metropolitane, folle, strade, corre, ecc., e
dopo 7 minuti, inquadrato da più di sei telecamere, viene arrestato da
cinque poliziotti. Ovviamente è un arresto fake, recitato, però l’esperi-
mento era questo. In 7 minuti, con 40.000 telecamere in Pechino. 

Ora è attivo un investimento per costruirne in Cina 400 milioni.
La Cina dichiara che ogni suo cittadino è identificabile, ma è
identificabile non solo come volto, quindi come identità, ma anche
come etnia, come sesso (facile) e con tutta una serie di altri parametri
catalogabili. Ancora big data in quantità più che soddisfacente.

Anche il nostro doppione vitruviano è notevolmente coperto di
device che ricevono dati e ne forniscono molti di più dei cittadini cinesi,
almeno per ora.

A questo punto al vitruviano digitale si aggiungono pezzetti di 
e-skin, la pelle digitale che va a coprire le braccia e poi le gambe, infine
tutte le parti del corpo non digitalizzate dai device indossabili. Il nostro
vitruviano forse è arrivato al massimo della sua digitalizzazione: ogni
pezzo del suo corpo trasmette dati. Ho immaginato che a questo punto
pensasse al paradosso: “Com’era bella la privacy nei social, nell’home ban-
king, nei motori di ricerca, nell’e–commerce... quattro dati in uscita e
tanta utile pubblicità e ottime notizie selezionate in entrata”. 

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

71

Tutti sono consapevoli che esiste il mercato interno a tutto ciò,
in grande perenne sviluppo. Quelli citati, tutti device indossabili, tro-
vano come primi acquirenti probabilmente gli ospedali, le aziende
per strumentazione tecnologica ospedaliera, le aziende farmaceutiche,
le assicurazioni e, ovviamente, miliardi di singoli individui. 

Nel 2018 si parla di un mercato di 19 miliardi di dollari per

centinaia di milioni di pezzi venduti.

Il mercato, quindi, c’è e sarà sempre più esteso. Forse con la

meta finale dei quasi 8 miliardi di persone del Pianeta. 

Noi trasudiamo dati in uscita e “loro” ci offrono beni, servizi
e opportunità in entrata, ottimizzando la soddisfazione dei nostri
bisogni, se non proprio quella dei nostri desideri. Forse abbiamo
costruito il più perfetto sistema di incontro fra la domanda e l’of-
ferta che per ora l’umanità è riuscita a inventarsi. Il dato del “con-
trollo” continua a proporsi come un piccolo prezzo collettivo da
pagare. L’esempio della Cina, ormai uno fra i tanti, ci avvicina a
comprendere, se ce ne fosse ancora bisogno, lo status di controllo
totale, il pedaggio da concedere: 1 miliardo e 400 milioni di cinesi
che diventano 1 miliardo e 400 milioni di controllati totali, indivi-
duabili, seguibili, in qualunque punto della Cina.

Ma, si diceva, c’è il mercato, la domanda e l’offerta, la sua ot-

timizzazione globale.

72

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Meno male che Nico c’è
Ho un amico che si chiama Nico e lo trovate in rete. Con
Nico discutiamo spesso di queste cose. Lui è un utilizzatore estremo
del digitale e della rete. Ci sono miliardi di consumatori estremi,
che nascono dall’analogico, immigrano nel digitale e diventano di-
gitali estremi, totali. Forse per complesso di inferiorità nei confronti
dei nativi digitali, fanno in modo di possedere tutti i device possibili
e abitare in tutte le piattaforme della rete. 

Una volta o due al mese spendo due o tre ore con Nico e

lui mi convince che tutto ciò di cui ho appena detto è ‒ così dice
il quarantenne Nico ‒ “fortissimo”, “ganzissimo”. “È tutto regolato

dalla rete” insiste Nico. Io lo guardo tentando di capire e lui per
un attimo mi dice “Certo che è un problema!”, all’estremista Nico
riesco a cavare solo questa frase volatilmente problematica, non
certo critica. 

Non c’è niente da fare: Nico, è granitico, giustificherebbe
ogni preoccupazione, ogni dubbio, ogni paura, ogni deficit di pri-
vacy. Non è un fanatico digitale, è un esperto totale. Nico per me è
proprio l’antidoto assoluto alla mia rassegnata voglia di privacy.

Abbiamo, allora, il nostro vitruviano digitale che fa incon-
trare la domanda con l’offerta. Nico dice sempre questo: nessuno
mi obbliga a comprare, la pubblicità mi martella, ma io adoro la
pubblicità. Perché bisogna dire no ai “cookies” che sanno cosa sto
cercando e mi offrono esattamente quello? Vedete che quello che
sto dicendo è esattamente quello che chi offre i “biscottini” vuole?
Il perfetto incontro fra la domanda e l’offerta. La perfetta

privacy della non privacy. 

Il nostro vitruviano emette dati da ogni suo poro, che sa-
ranno conosciuti da molti e, molto probabilmente ci saranno infi-
niti  dati  di  noi  stessi  che  non  conosciamo  e  che  invece  altri
conoscono, aggregano, approfondiscono, ma non ce li restituiscono.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

7 3

A questo punto ho aggiunto al nostro vitruviano digitale il
“Mantello di IoT”, di Internet delle cose, di tutte le cose, gli oggetti
che lo circondano. 

Il nostro vitruviano ormai è quasi fuori dal vitruviano vin-
ciano e, in più ha ora uno sciame, una nube digitale che lo avvolge
perennemente. Poi il vitruviano digitale perderà tutti i device indos-
sati, pezzetti ormai inefficienti di tecnologie non più innovative, la-
sciando spazio a una totale pelle digitale. Non ci sarà più bisogno di
tutti questi wearable “ingombranti”: una doccia alla mattina, una
doccia digitale, un totale refresh e saremo pronti a ricevere dati e so-
prattutto inviarli per tutta la giornata. 

74

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Poi aggiungiamo “Il Mantello di IoT” fatto – questa è la vera

svolta – di tessuto particolare, di intelligenza artificiale.

Da “Full smart body” a “Smart vitruvian”
I big data ci sono sempre, a questo punto in quantità esorbi-
tanti. Il nostro vitruviano ha ormai una specie di full smart body,
un corpo completamente intelligente. Il nostro vitruviano è diven-
tato uno “Smart Vitruvian”.

Siamo partiti da qualche smart thing, da alcuni oggetti smart,
e siamo arrivati alla doccia digitale, al Mantello di IoT e infine allo
“Smart Vitruvian”. Perché è smart? Perché produce trilioni di dati e
sappiamo che i dati, sono il vero oro, il vero coltan.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

75

Questa pelle digitale completamente smart e questo mantello
che fanno vivere lo Smart Vitruvian che rappresenta il nuovo algo-
ritmo della nostra vita. Noi siamo già da tempo e saremo sempre di
più un algoritmo. Altrui? Ciascuno di noi è un enorme, complessis-
simo algoritmo, che non comprende più solo dei dati sensibili, i dati
personali, e i dati di identità ma comprende tutte le relazioni digitali
fra i dati in uscita dalla nostra pelle digitale e i pochi dati restituiti.
In questo caso l’algoritmo è anche uno sciame e ognuno di
noi è uno sciame, uno sciame di dati collegati ad altri miliardi di es-
seri umani, miliardi di sciami. All’Internet of Things si è aggiunto
“Internet of Humans”, creando uno sciame personale collegato a
tutte le persone e le cose del mondo. Creando un algoritmo di ulte-
riore estrema complessità.

Allora la privacy che io chiedo di garantirmi è la privacy di
questo algoritmo. Ma ormai non c’è tecnologia che freni la emissione
dei dati in libera uscita dal mio sciame.

C’è qualcuno che ha detto: forse una soluzione tecnica/tec-

nologica c’è, quella del blockchain utilizzato in crittografia. 

I blockchain sono una passabile soluzione, ma in questo mo-
mento c’è già chi con l’intelligenza artificiale riesce a sbloccarli. Dun-
que la lotta fra buoni e cattivi, fra scassinatori e guardie, continua e
i cattivi molto spesso in questo campo sono avanti. Non arrivano
dopo, arrivano prima.

76

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Una domanda fra le tante. È saltata fuori discutendo con i
miei studenti di intelligenza artificiale e dei gusti privati, più semplici,
ma meglio posseduti. L’abbiamo confezionata insieme. La prima parte
è stata suggerita da una studentessa e la seconda da uno studente. 

È una domanda molto semplice, forse ovvia, però in realtà ci
ha fatto discutere per numerose lezioni. Pensando a tutti questi algo-
ritmi, parlando di intelligenza artificiale, gli studenti mi hanno detto:
- Quando ci fermeremo al chiosco di un fioraio con gli amici e sen-
tiremo diversi profumi saremo noi, oppure l’altro di noi, lo Smart
Vitruvian, a scegliere il mazzo di rose giuste? Saremo influenzati
non dai dati “in arrivo” ma dall’amico che ci dice prendi quelle
rose sono le migliori?

- Che vuoi che sia per gli algoritmi, per l’intelligenza artificiale, in-
dividuare il fiore che tu preferisci, che lei preferisce, che lui pre-
ferisce?

Da Smart Vitruvian all’Artificial Sapiens
Poi con gli studenti abbiamo discusso delle tecnologie che
fanno evolvere il vitruviano vinciano nel vitruviano digitale che di-
venta poi smart, ma soprattutto diventa altro, diventa “un altro”.

E ci siamo detti: questa storia della tecnologia è la storia del-
l’uomo che vuole diventare Dio. Strumento dopo strumento, pezzo

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

77

dopo pezzo, l’umano stia arrivando al punto in cui creerà un altro
vitruviano, un altro uomo, “a sua immagine e somiglianza”.

Dopo millenni di evoluzione tecnologica, si è arrivati alle in-
telligenze artificiali, ai robot, ai vestiti digitali, all’ e-skin, ai big data,
al flusso continuo dei nostri dati, mai restituiti, ma che paghiamo
sull’altare di un fine ultimo collettivo che sarebbe il miglior incontro
possibile della domanda con l’offerta e viceversa. Di tutte le infinite
domande con tutte le infinite offerte. D’ogni tipo. Interiori, esteriori,
reticolari, singolari e plurali.

Davvero è questo? Sono convinto invece che la storia della
tecnologia ci dica altro, giorno dopo giorno, anche passando per il
buon vecchio Frankenstein e i rozzi robot, e poi paleolitici replicanti
d’ogni sorta.

Io penso che la storia della tecnologia e l’accelerazione attuale
facciano capire molto bene che noi abbiamo una mai sopita, mai su-
perata, anzi sempre alimentata, invidia di un qualsivoglia Signore.
Noi vogliamo da sempre semplicemente essere Dio e non saremo
soddisfatti neanche quando creeremo, come stiamo creando pezzo
dopo  pezzo,  qualcuno  a  sua  immagine  e  somiglianza,  neppure
quando saremo riusciti a far evolvere lo Smart Vitruvian, oltre l’-
Homo sapiens sapiens, nella nuova specie dell’Artificial Sapiens.

78

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Giovanna Bianchi Clerici 

Fra un paio di giorni Netflix manderà in onda “Altered Car-
bon” una nuova serie che rappresenterà un futuro nel quale la co-
scienza umana potrà essere digitalizzata e trasferita, alla morte, con
ricordi e personalità in un nuovo corpo.

Il corpo diventa un involucro. Nella serie tv lo chiamano una
custodia, la custode di un’anima, che in questo modo sopravviverà
alla morte fisica. 

Francesco Grillo

Nel sentire quello che, prima di me, diceva il professor Fleischner,
possiamo forse dire che la cosa più straordinaria (e spaventosa) di ciò di
cui parliamo – l’integrazione tra macchina e uomo – è un po’ il contrario
dell’intelligenza artificiale. L’intelligenza artificiale è la creazione in una
macchina di processi che in qualche maniera imitano i processi cognitivi.
Qui invece stiamo discutendo della possibilità che un uomo si trasformi
in macchina, che ne acquisisca la forza meccanica che va ad essere mon-
tata su un’intelligenza naturale, molto superiore. Era l’approccio del-
l’Economist nella storia di cui mi sembra utile riprendere la copertina.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

79

Visto però che ci siamo quasi tutti riferiti anche a quello che
diceva il professor Mancuso, ci sono due concetti che vanno forse
qualificati.

Da una parte quest’idea del contrasto tra nemici della libertà
e apostoli della libertà, il contrasto tra verità e aspirazione alla verità,
che è anche imperfezione, che è anche passione.

Rispetto a questo devo dire che l’ulteriore complessità è che
spesso gli amici della libertà diventano nemici della libertà. È para-
dossale, ma tutto quello di cui stiamo parlando nasce a Silicon Valley,
che è la terra della libertà. Il paradosso è che l’amore per la libertà
può produrre tecnologie che possono ridurla. C’è quindi uno scam-
bio, Eros e Thanatos come direbbero i filosofi. L’innovazione al suo
più alto livello, le piattaforme globali rischiano di strozzare l’inno-
vazione, ponendo delle restrizioni alla concorrenza rispetto alle quali
gli antitrust nazionali, ma anche continentali, sono abbastanza im-
potenti. In qualche maniera l’innovazione nega se stessa. C’è, dun-
que, questa complessità che secondo me è fondamentale.

Secondo aspetto. Il professor Mancuso faceva riferimento,
come anche il professor Fleischner, ad atteggiamenti, stilemi che ri-
corrono nella storia umana. Secondo me, stavolta però, siamo in pre-
senza di una discontinuità veramente epocale, che è molto diversa
da quella che abbiamo avuto nei 500.000 anni di preistoria e poi
storia dell’uomo.

Se consideriamo la curva del reddito pro capite, la storia del-
l’uomo fino al 1700 registra un reddito pro capite che è più o meno
piatto, tra l’altro i romani erano abbastanza più ricchi rispetto a
quanto  non  lo  fossero  gli  uomini  del  Medioevo.  Nel  1700  c’è
un’esplosione perché c’è la rivoluzione industriale cominciata in In-
ghilterra.

Adesso noi siamo in presenza di una rivoluzione. A mio avviso
non è la quarta rivoluzione industriale, c’è qualche problema di nu-
merazione, secondo me è una rivoluzione al quadrato o al cubo per-
ché comincia come quella di Gutenberg ed è elevata alla potenza dai
progressi della fisica e della biologia. 

80

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Internet, è all’inizio tecnicamente questo: una riduzione dra-
stica di centinaia di volte nel costo di elaborazione, recezione, me-
morizzazione di informazioni; esattamente quello che succede con
l’invenzione della stampa nel 1450 più o meno. 

Poi, però, a questa rivoluzione di Gutenberg molto veloce-
mente si affiancano una rivoluzione nei nanomateriali e nella biolo-
gia, fino ad arrivare alle cose di cui stiamo parlando oggi. In qualche
maniera, quindi, è la rivoluzione di Gutenberg più la rivoluzione in-
dustriale, quindi è veramente un cambio di mondo.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

81

Le questioni di cui stiamo parlando sono ancora più fonda-
mentali rispetto alla regolazione della bicicletta di cui parlava Mas-
simo Sideri. Quando c’è stata la rivoluzione industriale noi abbiamo
avuto persone, che rispondono al nome di Carlo Marx, piuttosto
che Stuart Mill e più tardi John Maynard Keynes, che hanno riela-
borato il modo in cui noi dobbiamo leggere e governare una società.
Il concetto di liberismo e socialismo non sono delle categorie im-
manenti, sono delle categorie relative e storicizzate a un determinato
periodo storico. Non c’è, quindi, soltanto la questione della privacy
di cui ci stiamo occupando oggi: stiamo parlando di capire innanzi-
tutto che c’è un vuoto intellettuale sul futuro molto importante e
poi provare a governare una realtà completamente diversa.

Il discorso dell’integrazione tra corpo e macchina. Il profes-
sor Fleischner è arrivato fino alla pelle digitale, in realtà i sensori
stanno entrando nel corpo, tra l’altro non solo il corpo umano ma
da tempo avviene anche per gli animali non umani. Inoltre, un po’
tutte le cose che ci siamo detti stamattina mi fanno pensare non
soltanto ai grandi pensatori del passato ma ai film (si parlava prima
della bambola).

La  suggestione  dell’integrazione  tra  corpo  e  macchina  ci
porta indietro a un film, quando io avevo meno di 5 anni, lo stesso
anno in cui inventano Internet. 

Tra l’altro Internet nasce dai militari, dal Pentagono, quindi
è di nuovo uno scambio: militari che creano un qualcosa che doveva
dare a tutti libertà. 

Questo è un film del 1966 con Raquel Welch e l’idea è quella
di una navicella che entra nel corpo di un astronauta per salvarlo.
È un po’ questa la nuova frontiera di Internet. Io non la chiamerei
“Internet of the Things”, la stiamo ribattezzando “Internet of the
Beings” perché qui stiamo parlando di connettere tra di loro corpi.
Il sensore entra nel corpo, anche umano. 

82

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Sempre nell’ottica del ripasso, le cose di cui stiamo parlando da
anni nascono da questo, l’abbiamo detto tutti noi i relatori, ma è una
quantificazione, è l’esplosione dei dati che sono contenuti negli oggetti
digitali. Per avere un’idea di che cosa stiamo parlando, tutta la cono-
scenza prodotta dagli uomini fino al 1999, se si considerano tutti quanti
i testi, tutti quanti gli audio, tutti quanti i film, tutte quante le fotografie
e tutte quante le riproduzioni, occupava 16 exabyte. Nel 2015 negli
oggetti digitali c’era già 10 volte tanto la conoscenza che l’uomo era
riuscito a immagazzinare fino a quel momento.

Questo trend esplosivo, che segue una legge che se si chiama

legge di Moore ‒ che peraltro è parzialmente in difficoltà ma il com-
puter quantistico in qualche maniera la spingerà di nuovo avanti ‒ si

legge anche nel confronto fra due oggetti iconici di Steve Jobs. 

Nel 1984 c’è il Macintosh 128 e questo è l’iPhone 7, che è il me-
glio riuscito. Il confronto tra i due oggetti comunque è tale per cui quel-
l’iPhone ha 125.000 volte la capacità informativa del Macintosh 128
ma costa una ventina di volte in meno. Tra l’altro, a proposito di mettere
in discussione tutti quanti i nostri parametri, questa cosa ha un effetto
micidiale ad esempio sull’inflazione, perché noi stiamo parlando di una
cosa che costa decine di volte di meno ma rende 125.000 volte di più.
Tutto ciò, per parlare di una cosa che sembra non entrarci ma
c’entra moltissimo, ha degli impatti immediati rispetto a come gli 

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

83

economisti dovrebbero leggere la realtà. Ha senso che la Banca centrale
europea abbia ancora un target di inflazione del 2% in una realtà di
questo genere? Probabilmente no, allora dobbiamo ripensare, perché
siamo in un nuovo mondo, gli strumenti attraverso i quali leggiamo e
governiamo la realtà.

Gutenberg nel 1455, a proposito di potere di cui parlava il
professor Mancuso, che probabilmente è la cosa che assomiglia di
più a Internet, riproduce peraltro la Bibbia e da quella cosa quasi
immediatamente comincia il Rinascimento, che tra l’altro è un ten-
tativo artistico dell’uomo di riprodurre Dio, ma soprattutto comin-
cia la Riforma protestante proprio nel paese di Gutenberg. 

È sostanzialmente la stessa cosa che innesca Internet: la Ri-
forma protestante era quello, disintermediazione, Lutero non crede
più nella necessità di avere una Chiesa che intermedia tra il fedele e
il Padreterno. Tutto ciò innesca dei processi storici che sono assolu-
tamente esplosivi e alla fine dei quali abbiamo inventato delle isti-
tuzioni completamente diverse da quelle che avevamo prima.

Vado avanti perché queste sono cose che abbiamo già detto.
Sostanzialmente, ripeto, l’idea è che non siamo semplice-
mente a osservare un’evoluzione di Internet of the Things, ma pro-
babilmente siamo in una terza fase di Internet. Nella prima fase
Internet ha collegato fra loro i computer, nella seconda le cose, nella
terza sta collegando i corpi con delle conseguenze molto importanti. 

84

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Massimo Sideri mi è venuto in mente che invece dovrebbe essere ri-

La quarta rivoluzione industriale, quindi ‒ mentre parlava
voluzione industriale al quadrato o al cubo ‒ è in realtà la conver-

genza di tre rivoluzioni che stanno avvenendo contemporaneamente:
biologia, tecnologie digitali, nanomateriali.

C’è un aumento abbastanza importante ma non esponenziale
di oggetti legati in qualche maniera al concetto di integrazione tra
corpo e macchina. Questa è la questione relativa all’espansione degli
oggetti digitali indossabili, laddove ancora il consumatore, quindi i
giochi che stanno facendo la parte del leone, è il motivo per i quali
l’idea di Internet of the Beings è un’idea che ha anche un impatto
positivo, non è soltanto un incubo ma può essere anche un sogno.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

85

Intanto, al livello più basso, l’idea di avere dei sensori nel
corpo umano consente delle grandi capacità di monitoraggio e ab-
batte drasticamente il numero di morti per infarto evitabili, lo az-
zera praticamente. 

Al secondo livello c’è l’idea che il corpo si possa autoripa-
rare: sempre in caso di infarto se ho delle molecole che possono
sciogliersi automaticamente, prima ancora dell’intervento dell’au-
toambulanza, quando i valori fisiologici superano certe soglie, il
paziente si salva.

La terza cosa è probabilmente quella più importante: l’uti-
lizzo dei corpi senza particolari stress come laboratori di medicina
personalizzata. 

Questo l’ha detto qualcuno. 
Ogni farmaco, ogni vaccino ha dei risultati diversi a seconda
della persona e a seconda del tempo di assunzione della medicina
stessa. 

Chiaramente  se  posso  monitorare  che  cosa  succede  nel
corpo umano rispetto a determinati stimoli, ho la possibilità addi-
rittura di saltare i trials, che nell’industria farmaceutica costano
tantissimo.

86

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Vado velocemente a dire quest’ultima cosa e poi mi fermo,
sperando che ci siano altre occasioni perché questi sono temi su cui
ci giochiamo il futuro. C’è un terzo aspetto che mi sembra impor-
tante citare. Pur essendo in presenza di una rivoluzione tecnologica
al cubo che rischia di mettere in crisi i processi cognitivi, gli stru-
menti di lettura ancora prima di quelli di governo, questa rivoluzione
al quadrato praticamente è solo cominciata.

Questo è quello che dice Robert Solow, premio Nobel per
l’economia nel 1986: i computer stanno dappertutto tranne che nelle
statistiche della produttività. 

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

87

Incredibilmente in questi anni di esplosione dei computer e di
informazioni contenute nei computer, la produttività è rimasta sta-
gnante, addirittura è in riduzione in tutti i paesi occidentali, anche negli
anni della ripresa più recenti, il che contraddice tra l’altro le assunzioni
della endogenous growth theory. L’informatica non sta facendo fare al-
l’economia e al nostro benessere il salto che dovrebbe. È l’innovation
paradox che forse è uno dei temi più importanti dei prossimi anni.

88

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Probabilmente la risposta è quella di Thomas Eliot, poeta,
che nel 1922 si chiede: dov’è finita la sapienza che abbiamo perso
nella conoscenza e dov’è finita la conoscenza che abbiamo perso nel-
l’informazione? Non necessariamente più informazione significa più

conoscenza ‒ lo sappiamo ‒ e non necessariamente, di nuovo ci-

tando per la quarta volta il professor Mancuso, più conoscenza si-
gnifica maggiore saggezza.

La sfida rispetto al Garante della privacy, ne parleremo la
prossima volta, è che sicuramente su base nazionale questi problemi

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

89

non si affrontano e forse stiamo parlando di problemi che veramente
mischiano strutturalmente competenze che sono del Garante della
privacy con quelle dell’Antitrust. Stiamo parlando di un rimescola-
mento di competenze e di conoscenze che necessariamente compor-
tano un ripensamento delle istituzioni.  

Giovanna Bianchi Clerici

Quella nel corpo elettronico è una nuova incarnazione, ma
come si è detto all’inizio di questa giornata, cosa distingue l’uomo
che si è fatto macchina dalla macchina stessa? 

Che ne è della sua identità umana? L’unità simmetrica fra
essa ed un corpo viene scomposta e sbilanciata dai suoi nuovi arti
dotati di autonome intelligenze. Qual è l’identità personale di un
corpo al contempo fisico ed elettronico e che vive, al contempo,
nella realtà fisica ed in quella virtuale?

È una nuova incarnazione, ma è anche paradossalmente una

dematerializzazione del corpo fisico. 

La persona che agisce per il tramite di un corpo in cui scor-
rono dati al posto del sangue, che può abbattere la parete delle tre
dimensioni e disseminarsi nello spazio della Rete, che non conosce

90

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

le regole della fisica e dove il corpo fisico, nella sua irriproducibilità
genetica (unico pregio residuo nel confronto col corpo elettronico,
infinitamente più performante), è ridotta alla mera funzione di pas-
sword, come scriveva anche Rodotà, quasi si potesse esigere di eser-
citare il copyright sul DNA.

Questo nuovo corpo ci costringe a ripensare ogni scienza: di
quali malattie può soffrire il corpo elettronico? E se la risposta è che
sarebbe in grado di curarsi da sé e rendersi ogni volta più immu-
nizzato, vuol dire che è in grado persino di sopravviverci. 

Ma se invece un bug micidiale ne causasse lo shut down, cosa

ne sarebbe della nostra persona?

I sensi diventano più o meno di cinque? Le emozioni provate
vogando su un kayak fra le rapide, dal divano di casa, attraverso
una maschera per la realtà virtuale, formano un’esperienza piena-
mente vissuta del mio bagaglio?

Ed anche dal punto di vista giuridico andrebbero rivisti
nella loro essenza istituti e concetti come l’habeas corpus (già di-
ventato, piuttosto, habeas data), la libertà personale (quali misure
restrittive  applicare  al  corpo  elettronico?),  il  furto  d’identità
(quale?) e perfino la privacy, nella sua accezione più antica, irridu-
cibile ed innegabile di diritto ad essere lasciati da soli, almeno nella
propria testa e coi propri pensieri, sarebbe smentita da un chip
temporale che rileva e registra per molteplici pur legittime finalità
l’attività cerebrale.

Ebbene,  paradossalmente,  salvaguardia  dell’integrità  del-
l’identità,  e  quindi  della  persona,  sarebbe  proprio  considerare  il
corpo elettronico alla stregua di quello fisico, estendendo ad esso,
con le dovute differenze, le medesime tutele, considerazione e cura,
educandosi alla responsabilità di questa espansione di possibilità e
dei sensi, che diventa, piuttosto che del fisico, una protesi della
mente, affinché anche il corpo elettronico abbia un’anima umana.

C o r p o   e l e t t r o n i c o   e   t e c n o l o g i e   i n d o s s a b i l i

91

Uomini e macchine
Protezione dati per un’etica
del digitale

CHIUSURA DEI LAVORI

Maria Elena Boschi

Sottosegretaria di Stato 

alla Presidenza del Consiglio 

dei Ministri

Chiusura dei lavori
Uomini e macchine
Protezione dati per un’etica
del digitale
Intervento di Maria Elena Boschi
Sottosegretaria di Stato alla Presidenza del Consiglio
dei Ministri

Buongiorno a tutti.
Vorrei ringraziare innanzitutto il Presidente Soro per l’invito,
scusarmi con tutti i presenti, in modo particolare con i relatori, per
non aver partecipato all’intera sessione ma, come avevo anticipato,
purtroppo si svolgeva in contemporanea l’inaugurazione dell’anno
giudiziario al Consiglio di Stato, quindi dovevo presenziare anche
lì. Le nuove tecnologie, però, consentono di favorire in qualche
modo l’ubiquità perché è possibile seguire in differita, anche se ov-
viamente non con la stessa efficacia, i lavori e quindi ho potuto in
qualche modo raccogliere i contenuti degli interventi di questa mat-
tina, molto preziosa anche per il Governo.

Rispetto all’appuntamento annuale dell’Autorità garante per
la protezione dei dati personali, che ci offre sempre riflessioni signi-
ficative, quest’anno siamo anche a un giro di boa per noi particolar-
mente  importante.  È  tempo  forse  di  consuntivi  a  poco  più  di
vent’anni dall’introduzione di un primo corpus organico di norme
per la protezione dei dati personali nel nostro Paese, a quindici anni
dal primo codice per la protezione dei dati personali e soprattutto a
qualche mese ormai dalla piena applicazione del nuovo regolamento
europeo. Credo che in tutto questo percorso i diversi Governi che si
sono succeduti hanno sempre avuto un ruolo di impulso e di stimolo
anche con riguardo alla legislazione nazionale, lavorando chiara-

I n t e r v e n t o   d i   M a r i a   E l e n a   B o s c h i

95

mente insieme al Parlamento, ma con un ruolo fondamentale di
spinta iniziale.

Ovviamente oggi le riflessioni che abbiamo sentito ci pon-
gono degli interrogativi di portata molto più ampia e di carattere
culturale e sociale, non solo strettamente giuridico o legislativo. Ecco
perché è ancora più prezioso il contributo arrivato dai lavori di que-
sta mattinata. Credo che chi ha la responsabilità di rappresentare le
istituzioni, quindi anche di doversi porre nell’ottica della tutela dei
cittadini e delle imprese, debba chiedersi che cosa può fare in più il
Governo per affrontare queste tematiche, che cosa può fare in più
uno Stato nazionale.

Sapendo, peraltro, che non si tratta più di immaginare il fu-
turo ma semplicemente di gestire il presente, perché tutto quello che
abbiamo sentito raccontare in termini di Big data, di Internet, di
Web, di passaggio dall’analogico al digitale è new normal, è la nostra
quotidianità. Del resto non si tratta più di un tema settoriale, non è
più questione da addetti ai lavori, ma è ormai trasversale perché ri-
guarda la vita di tutti noi in aspetti che nemmeno immaginiamo.

Parlavamo prima dei dati che vengono trasmessi addirittura
sulla nostra pelle, sul nostro fisico, sulle nostre funzioni vitali e
quanto possano essere pervasivi anche i controlli che ci possono es-
sere sulla nostra quotidianità, sulla nostra attività.

Da un lato, quindi, porsi il problema di come affrontare que-
ste sfide che ormai sono presenti, consapevoli della grande difficoltà
anche per chi ha responsabilità istituzionali, di coglierne fino in
fondo la portata e la complessità, quindi poi poterli ridurre a sintesi
per avanzare proposte di disciplina organica.

Le grandi sfide, allora, quali sono? Innanzitutto difesa e sicu-
rezza, perché è ovvio che la gestione di questi dati, spesso anche molto
fragili rispetto alla possibilità di garantire l’inaccessibilità proprio du-
rante la stessa trasmissione dei dati, pone un tema anche di tutela dei
dati medesimi rispetto a tentativi di sottrazione o manipolazione.

Sicuramente un tema di garanzia dei singoli individui, dei cit-
tadini, nella loro libertà, nella loro autodeterminazione e giusta-

96

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

mente, come diceva la professoressa Califano, anche nella loro di-
gnità, nell’onore delle singole persone attraverso la gestione dei loro
dati personali.

Inoltre credo che ci si debba porre anche il problema di come
questi strumenti possano essere utilizzati per contribuire all’attività
che lo Stato deve compiere in alcuni settori. 

Lo stesso Presidente nella relazione iniziale faceva riferimento
alle potenzialità che questi nuovi strumenti offrono ma anche ai rischi
di una eccessiva tecnicità e meccanicità nell’applicazione di algoritmi,
per esempio, quando si tratta di amministrazione della giustizia o
quando si tratta di profilature che possono servire per gli accertamenti
di carattere tributario, fiscale. 

Credo che questo sia uno dei nuovi orizzonti che dobbiamo
tenere in considerazione, ma sapendo che deve essere bilanciato dal-
l’elemento di riservatezza e di tutela della libertà e dell’autodetermi-
nazione degli individui.

Altro  punto  secondo  me  di  non  secondaria  importanza  è
quello di cogliere anche le potenzialità economiche dello sfrutta-
mento di questi dati. Come Stato, quindi, porsi il problema della
utilizzabilità di dati, ricavandone anche per lo stesso Stato e per le
pubbliche amministrazioni eventualmente un vantaggio economico
o meno, o eventualmente di limitazione per il trasferimento tra pri-
vati. In sostanza chiedersi come gestire e regolamentare la diffusione
di tali dati.

Molte sono le sfide che abbiamo davanti ma che, a mio av-
viso, partono dalla tutela della persona, dell’individuo e di quelle
che sono le sue prerogative. Quando sentiamo parlare di giocattoli
intelligenti che in qualche modo rappresentano anche un elemento
di accesso alla vita dei minori, ci poniamo dei nuovi interrogativi.
Noi lavoriamo assieme all’Osservatorio contro la pedofilia e
la pedopornografia e uno dei primi elementi che, con la sensibilità
acquisita su questi temi mi viene in mente è quello di come garantire
in primis la sicurezza dei bambini, perché sono dati che possono es-
sere vulnerabili e accessibili anche da parte di terzi.

I n t e r v e n t o   d i   M a r i a   E l e n a   B o s c h i

97

A mio avviso, però, la prima forma di tutela è quella di far ac-
quisire ai cittadini la consapevolezza dei rischi a cui possono andare
incontro e quindi anche agli strumenti che hanno a disposizione per
tutelarsi. Penso che in passato, ad esempio, sia stato fatto un lavoro
significativo in un campo molto diverso: quello dei consumatori. 

C’è voluto del tempo perché si acquisisse la consapevolezza

delle proprie possibilità, dei propri diritti. 

Nel campo della tutela dei propri dati forse siamo ancora un
po’ indietro, nonostante un lavoro eccellente da parte dell’Autorità
garante che è molto attenta anche alla parte divulgativa, alla forma-
zione e alla sensibilizzazione dei cittadini. 

Dobbiamo fare ancora di più perché si sia consapevoli dei pro-

pri diritti.

La professoressa Iannini parlava di una rivoluzione paragona-
bile a quella industriale dei secoli scorsi: forse oggi i cittadini sono
meno consapevoli della possibilità di chiedere e rivendicare dei diritti
rispetto a quello che è avvenuto in altri passaggi storici importanti,
anche per quanto riguarda il settore della gestione dei propri dati
personali. Su questo sicuramente possiamo fare molto e possiamo
lavorare in modo intenso.

Un altro dei punti chiave per una legislazione che voglia tu-
telare i dati personali e che voglia proteggere gli individui, al giorno
d’oggi, è anche salvaguardare il diritto all’oblio, il diritto ad ottenere
in alcuni casi la cancellazione di alcuni dati. Sembra quasi che, pa-
rafrasando un vecchio film, una volta che si è venuti al mondo sia
impossibile nascondersi. 

Una volta che si entra in contatto o che in qualche modo

qualcuno ha accesso ai tuoi dati, è quasi impossibile “sparire”. 

Si pone allora il problema non tanto del nascondersi ma del
tutelare la propria reputazione, la propria dignità e quindi anche
quei dati che sono sensibili e che raccontano molto delle proprie
scelte e della propria vita.

Queste sono a mio avviso, in estrema sintesi, le sfide che ab-

biamo davanti. 

98

U o m i n i   e   M a c c h i n e .   P r o t e z i o n e   d a t i   p e r   u n ’ e t i c a   d e l   d i g i t a l e

Il regolamento europeo comunque ha consentito ai diversi
Paesi anche dei margini di discrezionalità nella sua attuazione con-
creta e ha rappresentato un passo in avanti per quanto riguarda il
diritto all’oblio perché per la prima volta si estende anche ai Big
data  e  non  semplicemente  ai  dati  che  sono  a  disposizione  dei
grandi portali.

Molta, però, è ancora la strada da fare. Asimov ha scritto che
purtroppo “la scienza raccoglie conoscenza molto più velocemente
di quanto la società raccolga saggezza”. 

Noi allora dobbiamo, consapevoli di questa velocità e di que-
sta urgenza, essere altrettanto pronti ad acquisire saggezza e, quindi,
a consentire di sfruttare queste grandi potenzialità e queste grandi
opportunità che la scienza ci offre, mettendo sempre e comunque al
primo posto la difesa della persona, dell’individuo e dei suoi diritti. 

Grazie.

I n t e r v e n t o   d i   M a r i a   E l e n a   B o s c h i

99

Redazione
Garante per la protezione dei dati personali

Piazza di Monte Citorio, 121
00186 Roma
tel. 06 69677.1
www.garanteprivacy.it
e-mail: garante@gpdp.it

A cura del
Servizio relazioni esterne e media 

Stampa:
UGO QUINTILY S.p.A.

 

i

e
l
a
t
i
g
d
 
l
e
d
a
c
i
t
e
’
n
u
 
r
e
p

 

 
i
t
a
d
e
n
o
i
z
e
t
o
r
P

i

 
.
e
n
h
c
c
a
M
e
 
i

 

i

n
m
o
U

