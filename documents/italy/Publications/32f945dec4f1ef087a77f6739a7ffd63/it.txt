copertina atti 2021 DEFINITIVA_STAMPA.qxp__  21/07/21  14:12  Pagina 1

 

 

 

e
z
n
e
i
c
s
o
r
u
e
n
e
l
l
e
d
o
p
m
e
t
 
l
a
a
n
o
s
r
e
p
a
L
 
.
i
t
t
i
r
i
d
o
r
u
e
n
e
y
c
a
v
i
r
P

 

 

 

Privacy e neurodiritti
La persona al tempo delle neuroscienze

I

T
U
B
I
R
T
N
O
C

Atti del Convegno - 30 gennaio 2017
Atti del Convegno - 28 gennaio 2021

Atti del Convegno - 28 gennaio 2016

Privacy e neurodiritti
La persona al tempo delle neuroscienze

Atti del Convegno
28 gennaio 2021

www.gpdp.it

In  questo  volume  sono  raccolti  i  contributi  di  studiosi 
ed  esperti  intervenuti  al  Convegno  “Privacy  e  neurodiritti:
la  persona  al 
tempo  delle  neuroscienze” organizzato  dal 
Garante  per  la  protezione  dei  dati  personali  in  occasione 
della “Giornata europea della protezione dei dati personali” 2021.

Indice

Apertura dei lavori                                                                                7
     Pasquale Stanzione
     Presidente del Garante per la protezione dei dati personali

Relazione introduttiva                                                                          9
     Pasquale Stanzione
     Presidente del Garante per la protezione dei dati personali

Interventi                                                                                                                        
     La dignità della persona al centro dello sviluppo gentile                 21
     Paolo Benanti
     Professore straordinario della Facoltà di Teologia, 
     Pontificia Università Gregoriana

     Neurodiritti: storia di un concetto e scenari futuri                       3 5
     Marcello Ienca
     Senior Researcher at the Health Ethics & Policy Lab, 
     Department of Health Sciences and Technology - ETH Zurich

     Quale futuro per il Post-umano? L'Umano                                            55
     Giacomo Marramao
     Professore emerito di Filosofia teoretica, Università Roma Tre

     Costituzionalismo, privacy e neurodiritti                                               69
     Oreste Pollicino
     Professore ordinario di Diritto costituzionale e dei media,
     Università Bocconi

Conclusioni                                                                                                                    
     Note sul “potenziamento cognitivo”                                                         85
     Pietro Perlingieri
     Professore emerito di Diritto civile, Università del Sannio

Chiusura dei lavori                                                                                                  95
     Pasquale Stanzione
     Presidente del Garante per la protezione dei dati personali

Privacy e neurodiritti
La persona al tempo delle neuroscienze

APERTURA DEI LAVORI

Pasquale Stanzione
Presidente del Garante
per la protezione dei dati personali

APERTURA DEI LAVORI

Pasquale Stanzione

Diamo inizio ai lavori della Giornata europea della privacy.

Innanzitutto, benvenuti a tutti, ai nostri ascoltatori, ai presenti. 

Vorrei ringraziare intanto i nostri relatori: Paolo Benanti,
Marcello  Ienca,  Giacomo  Marramao,  Oreste  Pollicino,  Barbara 
Carfagna che ci modera. 

Se permettete, un saluto particolare, un ringraziamento al
mio Maestro Pietro Perlingieri, che ci sente da remoto e che con
generosa disponibilità ha accettato di svolgere le conclusioni.

Illustre e caro professore, buongiorno. 
Vorrei  ricordare  altresì  il  collegio  della  nostra  Autorità: 
Ginevra Cerrina Feroni, Guido Scorza, Agostino Ghiglia, Fabio
Mattei,  che  hanno  accolto  l’idea  di  dare  alla  Giornata  europea 
questo contenuto. 

Senza la collaborazione intelligente e discreta di Federica
Resta, di Baldo Meo, di Michela Rossi, la Giornata non si sarebbe
svolta: quindi a loro va il mio più cordiale ringraziamento. 

Perché il 28 gennaio è la giornata europea della privacy?
28  gennaio  1981,  40  anni  fa,  a  Strasburgo  si  firma  la 
Convenzione sulla protezione delle persone rispetto al trattamento
automatizzato di dati a carattere personale.

In 40 anni cosa è successo? 
Ci  sono  state  tappe 

la  Direttiva, 
la  legge  in  Italia,  il  Codice,  il  GDPR.  Noi,  sulla  scorta  di
tale disciplina, ci vogliamo muovere nella scia dei nostri predeces-
sori: Stefano Rodotà, Franco Pizzetti, Antonello Soro. 

importantissime: 

Anton  Machado  scriveva:  “caminante,  no  hay  camino, 
se hace camino al andar” (“il cammino si apre percorrendolo”). 
Ebbene, questa Autorità, questo Collegio, intende orgogliosamente
continuare a costruire il proprio segmento di tradizione.

A p e r t u r a   d e i   l a v o r i .   P a s q u a l e   S t a n z i o n e

7

RELAZIONE INTRODUTTIVA
Privacy e neurodiritti
La persona al tempo delle neuroscienze
Pasquale Stanzione

Un tempo complesso quale è il nostro difficilmente può
essere  contraddistinto  in  ragione  di  una  sola,  specifica
caratteristica, che non ne esaurirebbe mai l’intrinseca ricchezza,
varietà, eterogeneità degli aspetti e delle implicazioni. 

Ma  tra  i  caratteri  che  connotano,  in  maniera  più
significativa  e  simbolica,  nell’ora  presente,  il  rapporto  con  la
tecnica  è,  forse,  il  più  rilevante,  perché  non  tocca  una  sola
dimensione del nostro vivere, ma le investe tutte, trasversalmente
e alla radice, mutando lo sguardo prima ancora che il suo oggetto
e  delineando  una  diversa  antropologia  e  nuove  domande  di
senso. 

E se il potere della tecnica si era già manifestato, in tutta
la  sua  pervasività,  nel  Novecento  (la  celebre  lezione  di  Martin
Heidegger  è  del  1953),  oggi  assistiamo,  con  la  rivoluzione  del
digitale  e,  soprattutto,  dell’intelligenza  artificiale,  ad  un
passaggio epocale.

Un passaggio in cui il superamento prometeico del limite
finisce con il rovesciare, nel suo inverso, il mito antropocentrico
dell’uomo  dominatore  della  tecnica,  considerata  estensione  del
suo stesso Io. 

Nel Frankenstein di Mary Shelley l’uomo ricrea la vita da
sé,  recidendone  ogni  legame  con  il  divino  e  finendo  con  il
sottrarre  alla  natura  il  segreto  della  vita.  L’  autonomia  nella
creazione  carica  l’uomo  anche  di  una  responsabilità  nuova  nei
confronti di (e per ciò che) si è creato. 

L’omicidio  realizzato  dalla  creatura  di  Frankenstein

R e l a z i o n e   i n t r o d u t t i v a .   P a s q u a l e   S t a n z i o n e

9

simboleggia,  in  fondo,  i  rischi  del  ‘dominio  della  tecnica’,
evidenti  più  che  mai  rispetto  a  una  tecnologia,  l’intelligenza
artificiale,  fondata  proprio  sulla  mimesi  (e  persino 
il
superamento!) della razionalità umana, capace di apprendere e,
per questo, di autonomizzare buona parte della sua azione. 

Non vi è, forse, esempio più plastico del capovolgimento
del  tradizionale  interrogativo  su  cosa  gli  uomini  possano  fare
della tecnica nel suo inverso: cosa la tecnica possa fare dell’uomo
(Severino). 

Ma  nel  solco  delle  -  innumerevoli  e  sempre  nuove  -
implicazioni ed applicazioni dell’intelligenza artificiale, quelle in
ambito  neuroscientifico  e  neurotecnologico  aprono  scenari
davvero inesplorati, incidendo su un substrato, quello cerebrale,
irriducibile a mera biologia, così forti essendo le connessioni tra
attività neurologica, coscienza, identità. 

È, del resto, almeno a partire da Cartesio che l’identità, 
la  soggettività,  la  stessa  differenza  dell’uomo  (come  singolo  e
come specie) viene identificata nel pensiero - il cogito ergo sum -,
la cui proiezione organica è il cervello: limite invalicabile persino
per il più coercitivo e totalitario dei poteri (che pur avesse tentato 
di  orchestrare  consensi  e  costruire  culture),  proprio  perché
correlato neurale della coscienza. 

Ecco, quindi, che se la tecnica si spinge dove neppure il
più  pervasivo  dei  poteri  statuali  è  potuto  giungere,  finisce  con
l’acquisire  una  potenza  senza  precedenti  e  con  il  superare  il
confine che nel pensiero greco separava l’ardire dalla hybris. 

Tra  i  più  significativi  progetti  neurotecnologici  vi  è 
quello  (Neuralink)  elaborato  da  Elon  Musk  per  l’installazione, 
nel  cervello,  di  chip  che  non  solo  consentiranno  di  contenere 
gli  effetti  di  patologie  neurodegenerative  e  di  potenziare  le
capacità cognitive ma che, oltretutto, permetteranno di “salvare”
i ricordi e “scaricarli su un altro corpo o robot”, amplificandoli o
cancellandoli selettivamente. 

10

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

stati  mentali  e 

influenzare  così,  addirittura,  gli 

E se, oggi, strumenti diagnostici avanzati quali la risonanza
magnetica funzionale, possono decodificare diversi tipi di segnali
cerebrali e correlati neurali di informazioni mentali, in un domani
non lontano potranno accedere ai contenuti, leggendo i pensieri 
e 
il
comportamento, agendo direttamente sulla sfera neuropsicologica.
Queste  ed  altre  forme  di  “brain  reading”,  fondate
sull’analogia 
la  decodificazione  dei  dati  neurali  e
l’interpretazione  funzionale,  semantica,  dei  contenuti  lasciano
dunque intravedere la possibilità, almeno in un prossimo futuro,
di  analisi  e  “lettura”  (ma  anche  condizionamento  e  persino
predizione)  di  intenzioni,  di  emozioni,  di  asserzioni  di  verità  o
menzogna  (il  famoso  “siero  della  verità”  assurto  a  simbolo 
del divieto di utilizzo processuale di prove atipiche idonee a ledere
la libertà morale della persona: art. 189 cpp). 

tra 

Il  rilevante  incremento  del  potere  epistemico  di  queste 
applicazioni  neuroscientifiche  e  neurotecnologiche  solleva  alcuni
interrogativi  e  riflessioni,  su  cui  vorrei  suggerire  un  confronto, 
essenzialmente su questi aspetti. 

In primo luogo, va distinto l’uso strettamente terapeutico delle

neurotecnologie dal loro utilizzo a fini di potenziamento cognitivo.

fare,  ad  esempio,  per 

Positivo  è  indubbiamente  l’uso  che  di  tali  tecniche  si 
potrebbe 
la  cura  di  malattie
neurodegenerative,  che  va  promosso  secondo  il  diritto  a  fruire
delle possibilità offerte dal progresso scientifico di cui all’art. 15
del Patto internazionale sui diritti economici, sociali e culturali. 
Se  tali  innovazioni  possano  contribuire  a  contenere  gli
effetti invalidanti di determinate patologie, restituendo ai processi
neurali  la  fisiologia  e  la  funzionalità  perdute,  esse  vanno
certamente promosse, a tutela del diritto fondamentale alla salute,
in tutta la complessità che ne caratterizza il significato (in tal senso
sembra  deporre  anche  il  documento  del  Comitato  Nazionale  di
Bioetica  del  2010  “Neuroscienze  ed  esperimenti  sull’uomo:
osservazioni bioetiche”). 

R e l a z i o n e   i n t r o d u t t i v a .   P a s q u a l e   S t a n z i o n e

11

Ben  più  problematico  è  il  ricorso  a  tali  tecniche  a  fini  di 
potenziamento cognitivo. Le attuali interfacce cervello-macchina
per  il  controllo  motorio  già  consentono  non  solo  di  amplificare 
capacità proprie dell’uomo, ma anche di fornirne ulteriori, trans-
umane, quali il controllo telepatico di dispositivi. 

Si tratta non tanto e non solo del “pendio scivoloso” e di
una  lettura  rigorosa  del  principio  di  precauzione  (Prometeo  del
resto  è,  etimologicamente,  colui  che  pensa,  oltre  che  vede  in
anticipo), quanto della definizione del limite oltre il quale non sia
tollerabile 
ingenerare  nuove
discriminazioni nei confronti di quanti potenziati non siano e non
accettino di essere. 

anche  per  non 

andare, 

Del  resto,  non  tutto  ciò  che  è  tecnicamente  possibile  è,
infatti,  anche  giuridicamente  lecito  ed  eticamente  ammissibile,
perché non possiamo fare tutto ciò che è possibile fare (Nietzsche).
Ogniqualvolta la scienza amplia la sfera delle possibilità, sorge il
problema del katechon, del limite di ammissibilità e di sostenibilità
etica, giuridica, sociale dell’innovazione. 

Così, le neurotecnologie fondate sul brain reading in senso
stretto e dunque con funzione essenzialmente analitico-descrittiva
dei processi cerebrali, qualora dovessero effettivamente riuscire a
decodificare  i  contenuti,  avrebbero  conseguenze  principalmente
sotto il profilo della trasparenza e visibilità del pensiero. 

Esse  attingerebbero,  dunque,  alla  dimensione  della
segretezza del foro interno, la cui inaccessibilità è garantita in ogni
ambito  (dal  processuale  con  il  diritto  al  silenzio  e  l’esenzione
dall’obbligo  di  dire  la  verità  per  l’imputato,  all’elettorale  con  la
segretezza del voto, sino al principio di materialità che esclude il
mero pensiero, non estrinsecatosi in comportamenti sia pur solo
verbali, dall’area del sanzionabile). 

Le tecnologie capaci, invece, di apportare condizionamenti 
e modificazioni nel processo neurale, prospetterebbero invece un
problema  di  libertà  cognitiva  come  presupposto  fondativo  del
diritto di autodeterminazione individuale.

12

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Interventi di questo tipo sul processo cognitivo e finanche 
volitivo  avrebbero,  naturalmente,  riflessi  rilevantissimi  in  ogni
campo  della  vita  e  del  diritto  ma,  soprattutto,  sul  terreno  della 
capacità  di  discernimento  (quale  parametro  valutativo  ormai
centrale  in  ambito  civilistico)  e  della  stessa  imputabilità  penale,
ben  oltre  il  mero  accertamento  della  suitas,  della  reale
partecipazione psicologica del soggetto al fatto a lui ascritto. 

Non si tratterebbe più soltanto del ricorso alle neuroscienze
ai  fini  della  valutazione  della  capacità  d’intendere  e  volere
dell’imputato,  su  cui  le  sentenze  nei  casi  Bayout  e  Albertani
segnando  un  punto  di  riflessione  importante1.  Per  quanto
indubbiamente  problematica, 
l’assunzione 
delle  lesioni  organiche  o  funzionali  della  corteccia  prefrontale 
tra  i  criteri  valutativi  dell’infermità  mentale  e,  quindi,  della
capacità di discernimento, appare meno controvertibile di quanto
sia invece la neurotecnologia invasiva. 

infatti,  persino 

Con essa, infatti, non si pone tanto il tema della “devianza
genetica” e del “gene guerriero”, quanto della eterodeterminazione
della condotta umana da parte dell’algoritmo, con la conseguente
commistione,  quasi  indistinguibile,  tra  atti  effettivamente
imputabili  alla  volontà  reale  e  non  condizionata  del  soggetto  e
quelli,  invece,  ascrivibili  all’algoritmo  che  quella  volontà  abbia
alterato. 

Il rischio, insomma, non è tanto e non è solo l’hackeraggio
del  cervello  (prospettiva  di  un  tale  riduzionismo  biologico  da
atterrire  chiunque)  quanto,  prima  ancora,  la  legittimità  e
l’ammissibilità  etica  di  un  intervento  eteronomo  sul  processo
cognitivo:  il  terreno  sinora  immune  (sacer  esto!) da  ogni
interferenza esterna. 

1 In cui, ai fini della valutazione del vizio parziale di mente dell’imputato, sono stati
effettuati imaging morfologico e cerebrale e test di genetica molecolare, finalizzati a
evidenziare anche l’eventuale substrato biologico dei disturbi del comportamento,
come se il delitto potesse ritenersi “scritto nei geni” del reo. 

R e l a z i o n e   i n t r o d u t t i v a .   P a s q u a l e   S t a n z i o n e

13

La  gravità  di  queste  implicazioni  sarebbe,  naturalmente, 
ancora  maggiore,  laddove  simili  applicazioni  neurotecnologiche 
venissero utilizzate al di fuori dell’ambito clinico (con le relative 
garanzie  anzitutto  deontologiche),  come  dimostra  il  programma
d’interfacce  cervello-computer  elaborato  da  Facebook  nel  2018, 
per  condividere  contenuti  on-line  direttamente  con  il  pensiero, 
eludendo l’azione umana. 

Saremmo, dunque, ben oltre il pur pervasivo neuromarketing,
che segmenta il mercato secondo parametri psicometrici e modella
l’offerta  sulla  base  delle  preferenze  ascritte  a  ciascuno  da  sistemi 
di profilazione predittiva a carattere neuroscientifico. 

La  suggestione  si  combina  pertanto  con  l’attitudine 
predittiva che è, del resto, uno dei tratti caratteristici della società 
dell’”anticipazione”,  così  definita  per  il  pervasivo  ricorso  ad 
algoritmi  capaci  di  prevedere  il  comportamento  di  ciascuno,
secondo il profilo stilato sulla base del comportamento passato. 

Riecheggia, in forma nuova, la distinzione tra persuasione,
suggestione  e  soggezione  psichica  la  cui  insondabilità  indusse 
la Consulta a dichiarare incostituzionale il reato di plagio nel noto
caso  Braibanti.  Ma  si  profila  una  prospettiva  ulteriormente
riduzionistica, laddove il singolo è ridotto a mero elemento di un
cluster, negandogli ogni residua individualità. 

Con  le  neurotecnologie  di  brain  reading ci  si  muove, 
naturalmente,  su  di  un  terreno  ancor  più  scivoloso,  in  ragione 
dell’intervento  diretto  sul  processo  cognitivo  e  volitivo,  per
renderlo,  in  un  futuro  ormai  prossimo,  trasparente  e  almeno  in
parte manipolabile, con il rischio addirittura di uno sfruttamento
a fini commerciali delle informazioni. 

Si  delinea,  così,  una  congiunzione  tra  neuroscienze  e
capitalismo  digitale  -  definita,  con  una  crasi  significativa,
neurocapitalismo  (Ienca)  -  idonea  tuttavia  a  determinare
implicazioni  potenzialmente  dirompenti  sulla  vita  individuale  e
collettiva, di una pervasività tale da scardinare gli assunti fondativi
dell’intero sistema delle garanzie costituzionali. 

14

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Siamo  di  fronte  a  una  nuova  antropologia,  che  esige  una 
più  profonda  ed  effettiva  difesa  della  dignità  dal  rischio  di  un 
riduzionismo  (non  semplicemente  biologico,  ma)  neurologico, 
capace di annullare conquiste di libertà ormai talmente risalenti e
consolidate da essere ritenute di fatto acquisite. 

Quale significato avrebbe, infatti, la tutela dell’intangibilità
della  sfera  privata,  in  ogni  sua  articolazione,  se,  poi,  i  pensieri 
fossero  leggibili  e  venisse  così  negata  la  riservatezza  di  quei
“thoughts,  emotions, sentiments  and  sensations”  che  già  Warren  e
Brandeis,  nel  1890,  indicavano  come  fondamento  essenziale  del
right to privacy? Può darsi realmente libertà se l’uomo, mediante
la  tecnica,  diviene  osservatore  delle  più  intime  percezioni,
aspirazioni, volontà altrui (e persino proprie, se ignote)?

Analogo  argomento  può  valere,  del  resto,  per  ogni  altra 
garanzia democratica: dal diritto di difesa comprensivo, appunto
anche del diritto al silenzio e dell’inammissibilità di prove lesive
dell’autodeterminazione,  al  divieto  di  perizia  criminologica,  alla 
segretezza  del  voto,  alla  libertà  confessionale,  al  pluralismo
informativo, politico e via enumerando. 

In  uno  scenario  del  genere  -  tutt’altro  che  asimoviano  -
emerge  con  forza  l’esigenza  di  garantire,  anche  rispetto  a  tale
nuova  tipologia  di  rischi,  l’inner  world,
il  foro  interno, 
l’Intimsphäre dalla  cui  libera  formazione,  gestione  e  sviluppo
dipende ogni altra libertà. 

Nessun  esercizio  di  diritto  o  libertà  potrebbe,  infatti, 
mai dirsi tale se realizzato per effetto del condizionamento, anche
soltanto  indiretto  o  parziale,  da  parte  delle  neurotecnologie  sul 
processo  cognitivo.  Né,  del  resto,  realmente  libera  potrebbe  mai 
ritenersi  alcuna  scelta  o  condotta  realizzata  nel  timore  della
trasparenza, della leggibilità, financo della predittività dei propri
pensieri,  delle  proprie 
intime
convinzioni, appunto. 

intenzioni,  delle  proprie 

Se,  dunque,  l’habeas  corpus,  nel  proteggere  fin  nella  sua 
corporeità  la  persona  da  atti  coercitivi,  ha  rappresentato  il

R e l a z i o n e   i n t r o d u t t i v a .   P a s q u a l e   S t a n z i o n e

15

fondamento dello Stato di diritto e l’habeas data - come diritto di
autodeterminazione informativa - ha costituito il baricentro della
tutela  della  persona  nella  società  dell’informazione,  l’habeas
mentem  dovrebbe  allora  rappresentare  il  fulcro  di  veri  e  propri
neurodiritti.

Sia  che  si  creino  ad  hoc,  sia  che  siano  desunti,  con
interpretazione  evolutiva,  dal  sistema  normativo  vigente  (come
parrebbe  preferibile),  tali  diritti  -  mai  come  in  questo  caso  di
libertà - rappresenterebbero l’argine essenziale rispetto alla deriva
riduzionistica  e  neurodeterministica,  scaturente  da  un  uso
improprio di queste innovazioni così dirompenti. 

Intorno ai neurodiritti (e alla privacy, nella sua declinazione
soprattutto  informazionale)  si  dovrebbe  delineare  uno  statuto
giuridico  ed  etico  essenziale  in  base  al  quale  coniugare
l’innovazione e il diritto a fruire dei benefici offerti dal progresso
scientifico con la dignità della persona, intesa qui kantianamente
come fine in sé. 

La  difesa  dell’Io  sovrano,  per  dirla  con  Musil,  dovrebbe 
rappresentare il presupposto necessario per l’esercizio di ogni altro
diritto  di  libertà,  che  esige  anzitutto  una  libera  e  indipendente 
determinazione  del  soggetto.  Il  rischio,  altrimenti,  è  che
innovazioni  scientifiche  potenzialmente  preziose  per  la  cura  di
stati  neurodegenerativi  divengano  lo  strumento  per  rendere
l’uomo,  come  ha  scritto  Michel  Foucault,  un  “caso”,  una  non-
persona,  l’individuo  da  addestrare  o  classificare,  normalizzare  o
escludere. 

Il dibattito di oggi, prima che risposte, vorrebbe suggerire
domande  su  di  un  tema,  quello  dei  neurodiritti,  che  segnerà  il
nostro futuro prossimo. 

“L’albero  della  scienza  non  fu  mai  l’albero  della  vita”,
asserisce  il  Manfred  di  Byron.  Ha  ragione,  laddove  intende 
che 
il  riduzionismo 
scientifico  non  può  comprendere;  che  la  biografia  non  coincide
con la biologia.

la  vita  contiene  un’eccedenza  che 

16

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Ma  la  scienza,  se  guidata  dal  diritto  e  dall’etica,  può,
restituendo fisiologia nella patologia, rendere la vita più umana e
persino più giusta.

R e l a z i o n e   i n t r o d u t t i v a .   P a s q u a l e   S t a n z i o n e

17

Privacy e neurodiritti
La persona al tempo delle neuroscienze

INTERVENTI

Paolo Benanti
Marcello Ienca
Giacomo Marramao
Oreste Pollicino

La dignità della persona al
centro dello sviluppo gentile*
Intervento di Paolo Benanti 

Per me è un onore essere qui non solo per l’altezza dei profili
coinvolti in questa giornata, ma proprio per lo scopo di questa 
istituzione, cioè poter contribuire a qualcosa che guarda al bene di
tutti i singoli cittadini e al bene comune è qualcosa che da italiano,
da qualcuno che ha anche dei nipoti che guardano a un futuro, mi
tocca nel profondo. 

Oltre quindi ringraziare per questo gentile invito, devo dire
che vedendo il video dell’Autorità garante sono veramente colpito
dalla capacità di poter divulgare quella che è un core business, una core
mission di questo ufficio, che secondo me diventa fondamentale in
una vita che, prima ancora di farsi storia, si fa dati, si fa qualcosa che
diventa comunicabile, e anche sfruttabile, da una serie di soggetti. 
Bene, provo un attimo a descrivere qual è il taglio che vorrei

dare io a questo intervento e con quale prospettiva. 

Ho imbattuto il tema delle neuroscienze e delle neurotecno-
logie accademicamente quando, nel 2008-2009, sono stato visiting
scholar nell’Università di Georgetown per preparare parte della mia
dissertazione dottorale, che è stata proprio sulla valutazione etica
delle neurotecnologie per il miglioramento umano. Ecco, quell’ap-
proccio  ha  un  po’  segnato  anche  il  mio  orizzonte  intellettuale; 
diceva Popper: “Sono le idee che fanno le scoperte”; nel mio caso
direi: sono le domande che guidano verso alcune risposte. 

Sono alcuni i punti che intellettualmente vorrei anteporre

per dire qual è l’orizzonte di questo mio piccolo contributo. 

Il primo è questo: è un testo del 2002 pubblicato dalla Dana

*Il testo riproduce la trascrizione dell’intervento orale.

I n t e r v e n t o   d i   P a o l o   B e n a n t i

21

Foundation, che sono i “proceedings”, gli atti di un convegno, che
furono “Neuroethics: mapping the field”. Cioè quando noi parliamo
di questo tema, dobbiamo avere consapevolezza che è una disciplina
giovanissima. 

La neuroetica nasce nel 2002 come una convergenza inter-
disciplinare - erano presenti filosofi, giuristi, eticisti, teologi anche,
fisiologici,  medici  e  neuroscienziati  -  per  descrivere  un  ambito 
disciplinare  che  non  si  riassumeva  in  una  singola  competenza, 
ma che richiedeva una sorta di costruzione di una nuova piazza, 
per una nuova polis, dove diverse istanze si confrontavano per ga-
rantire che cosa? 

Ecco, questa è forse la prima vera novità. 
Per garantire la coesistenza di conoscenze e tecnologie che
stavano cambiando la possibilità di esistenza dell’umano nella so-
cietà contemporanea. Chi di noi andasse a leggere quei “proceedings”
si accorgerebbe immediatamente che esistono di fatto alla voce neu-
roetica due prospettive tra loro complementari e non facilmente
conciliabili. 

C’è  una  prima  prospettiva,  che  è  la  prospettiva  più 
europea, continentale, dove neuroetica è da declinarsi nell’ottica
della neuroscienza dell’etica. Cioè quali sono quelle basi - come 
abbiamo sentito nella relazione del Garante - quali sono quelle 
basi che rendono ancora possibile dire la persona, quanto della per-
sona  è  semplicemente  computabile,  quanto  -  per  parafrasare 
Minsky nella macchina del cervello - dovremmo semplicemente 
riconoscere che il re è nudo; quel soggetto, quell’idea ottocentesca
che ci ha accompagnato fino a oggi potrebbe - secondo alcune 
prospettive delle neuroscienze - essere null’altro che una competi-
zione tra sottosistemi neurologici tra loro che danno l’apparenza 
di un soggetto. 

Se Paul Ricoeur, ancora, ci poteva dire che di fatto c’erano i
maestri del sospetto - Nietzsche, Freud e Marx - che dubitavano
della coscienza, ma che risolvevano questo dubbio nell’ottica di una
coscienza risvegliata, di una nuova presa di coscienza, ecco secondo

22

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

alcune visioni delle neuroscienze i maestri del sospetto sono diven-
tati radicalisti del sospetto, integralisti del sospetto. 

Il  soggetto  stesso  non  sarebbe  altro  che  un’etichetta  che 
abbiamo messo di fronte a una serie di processi tra loro scoordinati.
Ecco, questo è neuroetica nella prospettiva europea. Dubbi radicali
- vedremo più avanti - perché sono dubbi sulla stessa imputabilità
del soggetto, o sulla stessa capacità del soggetto di compiere atti 
liberi e responsabili. 

Di contro però c’è tutta la prospettiva nord-americana. 
La chiamo nord-americana perché in realtà prende anche
parte  del  Canada  e  parte  anche  del  Messico,  quindi  è  anche 
trans-linguistica da questo punto di vista. Ecco, la prospettiva nord-
americana in realtà è da declinarsi come etica delle neurotecnologie,
dove tutto con la nostra capacità di saper fare, di saper intervenire,
con  una  granulosità  più  piccola  sull’umano  rispetto  a  quelli 
che erano i processi che fino a oggi prendevamo in esame, ci dona 
nuove possibilità, ci fa sorgere nuovi interrogativi, fa nascere nuovi
case studies che chiedono di essere anche regolamentati e gestiti 
dal diritto. 

Quindi  due  campi  complementari,  due  campi  che  non 
possono essere riassunti l’uno nell’altro, due campi che, a causa di
una presenza globale del mercato e di una tradizione europea che
oggi quanto mai vediamo essere importante per la regolamentazione
di alcuni processi, chiedono di essere posti all’attenzione, chiedono
di essere messi al centro. Come? 

Nella prospettiva che un eticista delle tecnologie come il 

sottoscritto può portare. Qual è questa prospettiva? 

Ecco, provo a riassumervela con un articolo pubblicato da
uno dei miei maestri, che si chiama Langdon Winner, che nell’80,
in tempi quindi non sospetti per la tecnologia delle informazioni e
per le neuroscienze, parlava di che cosa vuol dire porre o proporre
un approccio etico alle tecnologie. E lo faceva presentando due
esempi: il primo esempio riguardava le autostrade, le “parkway”, 
che da New York portano a Long Island. Lui dice: quando noi 

I n t e r v e n t o   d i   P a o l o   B e n a n t i

23

percorriamo  queste  “parkway”,  noi  vediamo  tanti  ponti  in 
calcestruzzo come quelli che abitano per esempio la Milano-Napoli,
l’Autostrada del Sole. Ma in realtà, se noi guardassimo con l’occhio
dell’etica e delle tecnologie, dovremmo farci una serie di domande
differenti.  E  lui  racconta  in  questo  articolo  pubblicato  sulla 
rivista del MIT, del Massachusetts Institute of Technology, intito-
lato provocatoriamente “Do artifacts have politics?” (“Gli artefatti
tecnologici  hanno  una  politica?”),  che  se  noi  leggessimo  quella 
che è la storia del progettista capo delle infrastrutture dello Stato di
New York, Richard Moses, ci accorgeremmo che lui volutamente
ha chiesto quei ponti in calcestruzzo sotto misura. Per cui, quei
ponti consentono agilmente alle macchine di passare, non consen-
tono agli autobus di raggiungere la spiaggia di Long Island. Perché? 
Perché Moses era famoso per le sue idee politiche e questo
permetteva semplicemente alla “white middle class” americana di
raggiungere la spiaggia, e non lo permetteva alle altre minoranze et-
niche che non possedevano una macchina e si muovevano in auto-
bus. 

Conclude  Winner  che  ogni  artefatto  tecnologico  è  una 
disposizione di potere. Allora già in quest’ottica, il servizio che 
può fare l’etica delle tecnologie a un contesto come il seguente 
è far emergere alcune disposizioni di potere, far vedere come alcune
costruzioni tecnologiche consentono l’accesso, consentono l’esecu-
zione  di  alcuni  diritti,  inverano  o  negano  l’esistenza  dei  diritti 
che riconosciamo magari su carte costituzionali o su altri dispositivi
di legge. 

Il secondo esempio che faceva Winner riguardava una mac-
china appena sviluppata nel 1977, in California, dall’Università
della California. Era una raccoglitrice meccanica dei pomodori.
Ecco,  quello  che  ha  prodotto  questa  raccoglitrice  meccanica  di 
pomodori,  che  costava  100.000  dollari  per  essere  acquistata, 
è  un  passaggio  da  quasi  3.000  piccoli  coltivatori  di  pomodori 
a pochissimi soggetti, che in qualche misura se la potevano permet-
tere  come  investimento  risparmiando  nel  lungo  tempo  rispetto 

24

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

alla manodopera, tante volte frutto di immigrazione illegale dal
Messico verso la California. La seconda questione - commentava
ironicamente Winner - è che chiaramente si è dovuto selezionare
un  pomodoro  che  resistesse  alla  compressione  meccanica  della 
macchina, e questo è il motivo per cui il pomodoro nord-americano
ha  meno  sapore  di  altri  pomodori  coltivati  in  altre  zone  del 
pianeta. 

Ecco quindi, quando il mercato entra in un ambito con una
tecnologia, di fatto si produce da una parte un accentramento del
mercato stesso, dall’altro un cambio della qualità. Chiaro, sentire
le riflessioni di Winner anni prima che si diffondesse un problema
come quello che ha di fatto affrontato questo ufficio di fronte alle
platform, che concentrano il mercato e cambiano la qualità della
notizia, è un qualcosa di estremamente profetico. 

Ecco,  tutta  questa  premessa  per  dirvi  che  tutto  questo 
è confluito nel mio dottorato, che è stato discusso e difeso nel 2011,
e in un corso che insegno a partire dal 2013 presso la Pontificia
Università  Gregoriana.  Allora,  con  questa  prospettiva  vorrei 
con voi farmi qualche domanda, è questo il compito dell’eticista -
Socrate  è  stato  messo  a  morte  per  le  sue  domande,  per  il  suo 
flusso di “ti estì?” che cos’è?, in un’Atene che resisteva ad alcune 
domande  scomode  -  con  questo  vorrei  chiedermi,  e  chiederci, 
che  cosa  e  come  dobbiamo  capire  le  neurotecnologie  e  che 
cosa e come dobbiamo capire le neuroscienze dell’etica di fronte 
ai problemi che si affacciano sul nostro gestire la società? 

Bene, per quanto riguarda le neurotecnologie, partirei da
questo primo ambito che sono le più pervasive perché già disponi-
bili in parte sul mercato; dobbiamo riconoscere che le possibili
forme di tecnologie sono duplici: da una parte c’è una neurotecno-
logia che sfrutta la chimica, il farmaco; dall’altra c’è una neurotec-
nologia che invece sfrutta l’elettronica, l’impianto. 

Ecco, dal mio punto di vista secondo me è più urgente la
neurotecnologia farmacologica, perché passa di più tra le maglie
di quella che è la società attuale. 

I n t e r v e n t o   d i   P a o l o   B e n a n t i

25

Chiaro, un impianto cerebrale ha bisogno di una struttura
sanitaria, ha bisogno di un follow up, non che sia meno pericoloso
ma di fatto forse ancora più controllabile per tutto il processo che
richiede per essere messo in atto. Un uso off-label di un farmaco
qualsiasi già in commercio diventa più problematico. Allora, che
cosa conosciamo con queste neurotecnologie? 

Farò un piccolo esempio di case studies semplicemente per

dire là dove fioriscono i problemi già da una decina d’anni. 

Uno dei primi case studies che mi sembra opportuno mettere
davanti a voi è quello che io ho sentito nell’undicesima conferenza
di neurofarmacologia, nel 2013, tenuta a New Orleans, dove di
fatto un report in una delle plenarie della conferenza stessa diceva,
con una certa ironia da parte di chi lo presentava, che nei college
di fascia alta degli Stati Uniti d’America la sostanza illegale più spac-
ciata non era una droga, ma era il Ritalin, o altri farmaci che, uti-
lizzati off-label, consentivano agli studenti di aumentare la loro
capacità di concentrazione. 

Quindi è chiaro che se io investo in un ambiente, in cui
l’educazione è di fatto un prodotto di marketing, così tanti soldi
sulla mia formazione, capite che poter avere una vita sociale nor-
male per un ragazzo dell’università, e poi grazie all’aiuto di qualche
farmaco poter memorizzare appieno un libro, è un investimento a
lungo termine. Ecco, qualcuno in quella sede ha detto a voce alta
“Rendiamolo legale, creiamo un uso on-label di questo farmaco per-
ché ci si possa in qualche misura dopare cognitivamente e ottenere
meglio i risultati che vogliamo ottenere”. 

È chiaro che questo cambia tutta una serie di asset anche 
all’interno  dei  diritti.  Se  nello  sport  è  vietato  il  doping,  cosa 
diventerà l’equivalenza di un titolo con valore legale se possiamo
ottenerlo con una sorta di dopaggio cerebrale? Ma vedremo dopo
nei paradigmi di valutazione etica qual è, diciamo così, la soglia 
rispetto alla quale si può o non si può interrogarsi su questo tema.
Inoltre, una delle frequentazioni che ho avuto mentre studiavo 
in  America  era  con  l’Università  del  Maryland,  dove  uno  dei 

26

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

professori  di  neuroscienze  di  fatto  ha  introdotto  un  termine
che secondo me è molto interessante. 

Ha  introdotto  il  termine  “neurocosmesi”.  Lui  diceva: 
“All’interno di una società così prestazionale, che ci chiede così
tanto, che ci chiede un impegno cognitivo ed emotivo così alto 
per poter raggiungere il successo, alcune cose così decantate nella
letteratura dell’Ottocento, come la ‘melancolia’, non hanno più 
spazio”.  Se  io  ho  solo  il  sabato  sera  per  quello  che  chiamo  il 
divertimento, nessuno vuole essere triste il sabato sera. E allora ecco
che questa frontiera della cosmesi diventa una cosmesi emotiva, 
diventa  la  frontiera  in  cui  io  posso  vendere  degli  stati  d’animo 
con  modalità  che  non  producano  dipendenza,  con  modalità 
che sono poi gestite dall’organismo e vengono in qualche misura a
essere rese compatibili con la società. 

L’ambito  della  neurocosmesi  è  un  ambito  che  ci  deve 
interrogare, perché dietro la neurocosmesi c’è una ridefinizione
dell’umano - cosa vuol dire l’emozione, cosa vuol dire il vissuto - 
e c’è anche una nuova ridefinizione di quello che è anche il processo
creativo. Con la dottoressa Carfagna ci siamo più volte interrogati
su questo, anche da un punto di vista mediatico, perché si stanno
diffondendo sempre di più l’uso di micro-dosi di LSD in ambito
controllato,  dove  -  e  qui  gioco  un  attimo  la  parte  del  religioso 
in questione - l’accesso allo spirituale non è più tramite il religioso,
ma lo diviene tramite delle sostanze che aprirebbero a nuovi feno-
meni percettivi. 

È un fenomeno di massa. Per esempio, è stato studiato con
un paper molto interessante dalla rivista Aeon, questa rivista inglese
che si occupa di filosofia. Allora, l’idea che anche una delle caratte-
ristiche più antiche della nostra società, che è il vivere spirituale,
possa essere neurotecnologicamente mediato, è un altro di questi
indici  di  trasformazione  di  quanto  questo  tema  non  solo  sia 
importante, ma anche urgente, nelle gestioni della nostra società.
Senza parlare di quelli che sono i “neuroenhancement”, cioè in una
società che ha conosciuto tra Ottocento e Novecento alcune delle

I n t e r v e n t o   d i   P a o l o   B e n a n t i

27

sue più sanguinose guerre per dire che siamo tutti uguali - ricorreva
ieri  la  Giornata  della  memoria  -  ecco,  noi  di  fatto,  grazie  alle 
neurotecnologie, possiamo creare nuove stagioni di diversi, nuove
stagioni di migliori che inevitabilmente farebbero affacciare sulla
scena pubblica dei peggiori, dei non migliori. 

Ecco, qui non voglio facilmente far ricorso a quella che può
essere la fantascienza, ma è chiaro che gli scenari possibili pensati
da alcuni autori contemporanei iniziano ad apparire sempre più
reali. Ma non sarei del tutto completo e sincero se non declinassi
questo uso delle neurotecnologie in almeno due ambiti, che mo-
strano la complessità del tema di cui parliamo. 

Uno è l’ambito sanitario, dove di fatto l’uso di queste neu-
rotecnologie potrebbe migliorare di molto la vita di alcuni pazienti.
Si pensi a tutti quei pazienti che, per esempio, sono soggetti a ma-
lattie neurodegenerative. Farmaci per l’”enhancement” della memo-
ria potrebbero garantirgli, o garantire loro, di fatto una qualità di
vita prima impensabile. O pensiamo a tutti coloro che sono affetti
da qualche deficit, che poi diventa di fatto nel vivere sociale una
forma di handicap, laddove l’handicap è la non capacità - la pro-
spettiva che vi offro io - della società di integrare differenze di deficit
nelle persone. Io posso avere un deficit motorio: questo diventa un
handicap se la società non ha vie accessibili per qualsiasi portatore
di deficit motorio. Allora è chiaro che le neurotecnologie da questo
punto di vista possono promettere una società più giusta e più ac-
cessibile per tutti. 

Di contro, io ho pubblicato sull’American Journal of Bioe-
thics, nella sezione “Neuroscience”, un commento abbastanza cri-
tico nei confronti dell’amministrazione Bush - anche se i documenti
erano stati resi pubblici dall’amministrazione Obama - che aveva
usato dei neurofarmaci per gli interrogatori dei sospetti terroristi
all’interno della base soprattutto di Guantanamo. Siccome il far-
maco è metabolizzabile e non lascia segni sulla persona, sebbene
produca uno stato di prostrazione e sofferenza che nessuna tortura
fisica può indurre, c’era qualcuno che dubitava che quella fosse tor-

28

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

tura, c’era qualcuno che dubitava che quella fosse una procedura
non giustificabile in nome della sicurezza nazionale. 

Allora è chiaro che l’utilizzo di queste neurotecnologie in
ambiti come quello militare e quello della sicurezza nazionale sono
un altro grandissimo ambito che ci interroga e mostra la complessità
del sistema. 

Per  quanto  riguarda  le  interfacce  elettroniche  -  non  mi 
soffermo  su  Neuralink,  non  mi  soffermo  su  tutto  questo  -  mi 
soffermo però invece sulla capacità che hanno alcuni algoritmi di
machine  learning di  clusterizzare  -  come  diceva  il  Garante  -  le 
persone, rendendo di fatto comprensibile e gestibile quello che è il
loro comportamento. Perché? Perché qui c’è un ulteriore, secondo
me, case studies che può aiutare a interrogarci su come regolare e 
normare  queste  tecnologie.  Di  fatto,  una  famosa  azienda  stava 
sviluppando un kit per aiutare i giovani a riconoscere di essere 
vittime di cyberbullismo. 

Sostanzialmente un’intelligenza artificiale, dialogando con 
i  ragazzi  che  si  sentivano  non  a  loro  agio  in  un  contesto, 
riusciva a fargli dare il nome di cyberbullismo a quello che avevano
vissuto.  Mi  hanno  interrogato  per  chiedere  l’eticità  della  cosa, 
perché  questo  kit  voleva  essere  regalato  a  una  nazione  in 
particolare  della  Comunità  europea.  Ecco,  l’obiezione  che  io 
gli ho fatto è stata di questo tipo: “L’iniziativa mi sembra ottima,
vorrei veder scritto da qualche parte però che la capacità cognitiva
che la macchina assume in quest’opera a fin di bene, per esempio
domani non venga ritrovata venduta all’interno di un sistema che
interagisce  con  i  ragazzi  e  che  ha  come  scopo  vendergli  più 
prodotti possibili”. 

Ecco, l’interoperabilità che ha la macchina con finalità di-
verse, per cui si possono acquisire mediante l’operazione sui dati
capacità cognitive nel bene che poi vengano riutilizzati da altre parti
nel male, ci si chiede se dobbiamo pensare anche istituti giuridici
che prevedano la cancellazione non solo dei dati, ma anche degli
algoritmi addestrati su quei dati. 

I n t e r v e n t o   d i   P a o l o   B e n a n t i

29

Ecco, è un caso della settimana scorsa - lo riportavo sul mio
blog - che l’FTC, la Federal Trade Commission degli Stati Uniti,
ha imposto a una grande società di cloud non solo una grande 
ammenda perché ha usato illegalmente le foto degli utenti, ma
anche la cancellazione di tutti quei servizi cognitivi di riconosci-
mento facciale addestrati illegittimamente sulle foto degli utenti.
Ecco che qui l’ambito di protezione si sposta dai dati alle facoltà
cognitive che alcuni strumenti possono acquisire in una relazione
illecita o non trasparente sui dati stessi. E le neurotecnologie ci 
dicono  che  appunto  l’”inner  worth”  del  mondo  che  può  essere 
acquisito diventa enorme, diventa spaziosissimo. 

Il tempo è tiranno e mi sposto a quelle che sono le neuro-
scienze dell’etica, dove i tre temi sono sostanzialmente cosa resta
della libertà, della consapevolezza e della responsabilità umana. Su
questo non entro molto in dettaglio come nel caso delle neurotec-
nologie, perché sono dibattiti che vedono più coinvolta la filosofia
e che vedono anche più coinvolta quella che è la prassi giuridica. 
Mi limito a segnalare che ormai da, penso, cinque o sei anni
noi vediamo anche in Italia sentenze di assoluzione o di mitigazione
della pena perché gli avvocati di parte portano espressioni genetiche
del soggetto connesse a una maggiore o minore capacità di control-
lare la rabbia, che sono questioni di neuroscienze. 

Ecco, allora cosa rimane della persona? Come quell’ideale
tutelato dal diritto, come quell’ideale adombrato tra i primi numeri
della Costituzione, mai citato ma di fatto, tutelato da quella serie
di  diritti  e  doveri  fondamentali  della  Costituzione,  questa  è 
una  questione.  E  questa  è  una  questione  interdisciplinare,  che 
ci deve veder lavorare insieme per poter dare a quei diritti, sorti
dopo una pagina così triste della nostra storia come la violenza 
nazifascista che ha segnato il nostro territorio, un nuovo vigore, 
una nuova estensione in un’epoca in cui quello che conosciamo
della persona lo guardiamo a una risoluzione diversa con prospettive
diverse. 

Cosa significa essere liberi? Quale libertà non è situata? 

30

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Ecco, il situato neuroscientifico oggi della libertà nega l’esi-
stenza della libertà? O è una verifica di quell’antico adagio che dice
che ciò che è l’uomo è spirito incarnato? Dove questa è la dimen-
sione dell’incarnato e nulla più. Ma non toglie dignità a quell’essere
qualcosa che va oltre. Si capisca spirito nella declinazione di un
orientamento religioso o filosofico quale può essere quello di Egger.
Ecco,  c’è  un  qualcosa  dell’umano  che  trascende.  Cosa 

rimane della consapevolezza? 

Ecco, il neuromarketing ci insegna che noi possiamo indurre
una sorta di comportamenti agendo su una serie di trigger che sono
più bassi rispetto a quella che è la consapevolezza dell’individuo
stesso. Ecco, dalla tutela del consumatore fino alla tutela dei giovani
- tutto questo chiaramente nell’età giovanile e nell’età dello sviluppo
diventa un qualcosa di estremamente delicato, ma parlo a voi che
già  vi  siete  occupati  di  questo  con  un  social  network molto 
particolare - ecco, tutto questo ci interroga e ci fa chiedere: qual è
il livello di consapevolezza minimo richiesto nell’interazione con
dispositivi neurotecnologici? 

Cosa deve essere garantito? 
Dobbiamo forse pensare a una sorta di “fact-sheet”, una sorta
di etichetta tipo quelle che si mettono sugli alimenti, che invece di
comunicare le calorie comunica il livello di consapevolezza o di in-
terazione con meccanismi di questo tipo? E tutti i dati che vengono
raccolti - perché di fatto ogni oggetto di consumo è anche un og-
getto che trasmette dei dati - come devono essere tutelati? 

Come possono essere lavorati? Come l’aggregato fornisce
un’altra serie di controlli che devono in qualche misura essere di-
chiarati, controllati e sottoposti al bene comune? E infine la respon-
sabilità: mai come nella storia recente abbiamo visto appellarsi a un
concetto di responsabilità che è sempre più labile. 

Ecco, un dialogo tra filosofia, teologia anche - Cicero pro
domo sua - diritto e neuroscienze è urgente per poter tracciare nuove
soglie di responsabilità. Dove a me sembra che le neuroscienze con-
tribuiscano in maniera molto forte nel dire che magari non è pre-

I n t e r v e n t o   d i   P a o l o   B e n a n t i

31

sumibile la capacità libera del soggetto nel momento finale di com-
piere un’azione. 

Ho in mente in questo momento mentre vi parlo una storia
molto triste di un abuso su un minore dove di fatto un perito di
parte dice che non c’era la libertà nel momento dell’atto finale. 
È chiaro che però se quel soggetto ha messo in atto un lungo pro-
cesso per garantirsi la fiducia del minore, può non esserci la libertà
nel momento finale, ma in tutto quel processo di “grooming”, di ac-
quisizione di fiducia nei confronti del minore, tutto questo va an-
cora imputato come un’azione del disegno criminale. Allora questi
ragionamenti hanno bisogno di essere condivisi e di diventare anche
qualcosa che può orientare l’esercizio della giustizia nei confronti
della magistratura. 

E  arrivo  così  alla  conclusione  di  questa  mia  piccola 
provocazione. Quali paradigmi etici troviamo in questo momento
operanti nel contesto accademico internazionale? Ecco io, invece 
di  fare  un  elenco,  ve  li  raggruppo  in  tre  grandi  famiglie;  sono 
paradigmi  etici  soprattutto  improntati  a  uno  stile  anglosassone
analitico.  Il  primo  lo  possiamo  dichiarare  o  catalogare  sotto 
l’espressione “fear of uncertain”. Siccome comunque l’intervento 
tecnologico,  per  quanto  possa  essere  ingegnerizzato,  mantiene 
una  certa  dose  di  rischio,  c’è  tutta  una  grande  famiglia  di 
interventi che di fatto si basa sul criterio di incertezza. 

Un vecchio slogan ingegneristico sintetizzava il tutto dicendo
“think  twice,  cut  once”  (“una  volta  che  hai  tagliato  hai  tagliato, 
misura  due  volte  perché  il  principio  di  precauzione  vale”). 
Dove, attenzione, questa “fear of uncertain” va in due direzioni: 
va nella direzione della tutela del soggetto, quindi attenzione agli
esiti non voluti sul soggetto; va nella direzione della sopravvivenza
della specie. In un contesto di pandemia questo si capisce molto
bene,  c’è  un’incertezza  nell’applicare  alcuni  nuovi  trattamenti 
medici sul soggetto. Ma quando l’incertezza è minore del rischio
che  si  ha  nel  non  applicarli,  ci  si  orienta  in  questa  direzione. 
Quindi “fear of uncertain” è una delle prime famiglie di riflessione

32

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

etica che accompagnano tutto questo e si tiene in una tensione, 
ma è risolvibile, l’incertezza rispetto alla tutela del singolo e rispetto
alla collettività. 

Dal mio punto di vista, se questo ci ricorda che nessuna 
tecnologia è certa, di contro rappresenta un limite, perché il motore
dell’etica dovrebbe essere la ricerca del bene, non la paura di quello
che può succedere. Vi è poi una seconda grande famiglia, vi dicevo,
ambito chiaramente analitico nord-americano, e io la riassumerei
all’interno di queste due espressioni, che sono tipiche della dichia-
razione d’indipendenza degli Stati Uniti d’America: “equality” e
“pursuit of happiness”. Ecco, ci sono tutta una serie di discussioni
per  cui  se  io  voglio  migliorare  me  stesso  per  conoscere  di  più, 
e questa è la mia felicità, la modernità ci ha detto che uno stato 
di diritto è tale se consente la mia ricerca personale della felicità, 
io vorrei poter fare questo su me stesso. E tutto questo si scontra
con quell’altro principio, che è il principio di uguaglianza, che dice
che dovremmo essere tutti uguali. 

Ora le neurotecnologie per la prima volta ci possono rendere
disuguali e disuguali in una maniera significativa. Cito qui Fu-
kuyama, che parlava del transumanesimo come la più pericolosa
delle nostre idee, perché di fatto dopo le battaglie per l’uguaglianza
dalla rivoluzione francese il “post umano” postula dei disuguali per
diritto. Arriviamo in fondo alla terza famiglia di discussioni, dove
di fatto si parla di policy, dove si parla di regolamenti in cui non di-
scutiamo così tanto sul fondamento del diritto, ma che ci danno
una prima approssimazione e poi si correggeranno nel tempo. 

Arriva una mia personale proposta che penso possa essere più
compatibile con quella che è una sensibilità europea, e propongo
di passare da una visione del government di tutto questo a una vi-
sione della governance, cioè dove le diverse componenti della società
civile si ritrovano per aiutare a dare una direzione a tutto questo. 
Ma questo significa sottrarre questo tema al tema dell’inno-
vazione e trasformarlo nel tema dello sviluppo, cioè significa met-
tere al centro la persona e la sua dignità e significa chiedersi quali

I n t e r v e n t o   d i   P a o l o   B e n a n t i

33

forme di innovazione, cioè la capacità tecnologica di fare meglio 
in maniera più efficiente una cosa, corrispondono a una migliore
autorealizzazione dell’umano. 

Ecco, come deve essere questo sviluppo? 
Deve essere globale, cioè di tutte le donne e di tutti gli uo-
mini; deve essere integrale, cioè di tutta la donna e di tutto l’uomo,
non di una sua parte; deve essere plurale, attento ai diversi contesti
nel quale l’uomo vive - è chiaro che uno sviluppo per una grande
città europea sarà molto diverso da una periferia di un altro paese -
deve essere uno sviluppo fecondo, cioè attento alle nuove genera-
zioni. Vorrei riassumere dicendo che dovrebbe essere uno sviluppo
gentile, cioè attento a una serie di contesti che sono l’uomo e la casa
che ci ospita, che è l’ambiente. 

Ecco, capisco di aver aperto più questioni che non aver of-
ferto risposte, ma ho vissuto questo privilegio di questa posizione e
vi ringrazio e vi auguro buon proseguimento dei lavori.

34

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Neurodiritti: storia di 
un concetto e scenari futuri
Intervento di Marcello Ienca

Vorrei  innanzitutto  ringraziare  il  Presidente  dell’Autorità
garante, il professor Stanzione, per l’invito e per aver posto al centro
della  giornata  europea  della  protezione  dei  dati  la  tematica  della
privacy mentale e dei neurodiritti. 

Volevo fare anzitutto una piccola ricostruzione storica, perché
all’inizio  della  decade  appena  conclusa,  quando  ho  cominciato  a
lavorare  al  tema  delle  interfacce  cervello-computer  e  delle  loro
implicazioni  etico-giuridiche,  il  tema  della  privacy  dell’informazione
mentale  era  un  tema  molto  più  legato  alla  fantascienza  e  alla
futurologia che non a una rigorosa analisi scientifica ed etico-giuridica. 
Non  a  caso,  la  più  frequente  istanza  del  termine  “mental
privacy” era nel terzo libro di Star Trek dell’inizio degli anni ’80,
dove  si  prefigurava  questo  scenario  ipotetico  di  questa  navicella
spaziale che viaggiava nella galassia e il comandante della navicella
di Star Trek voleva acquisire informazioni riguardo agli abitanti di
un determinato pianeta e voleva, per far ciò, leggere nel pensiero
telepaticamente di questi abitanti e gli viene imposto dall’ordine
vigente  su  quel  pianeta  che  questo  non  può  avvenire,  perché  lì
vige il diritto alla privacy mentale che è un diritto inviolabile a
livello planetario, addirittura universale.

Parliamo appunto di istanze, di riferimenti letterari di tipo
fantascientifico, e invece oggi, a poco meno di una decade da allora,
il  tema  della  privacy  dell’informazione  mentale  è  al  centro  di  un
dibattito  pubblico  internazionale  che  coinvolge  la  comunità
scientifica, che coinvolge la Silicon Valley, l’industria del digitale, e
che  coinvolge  anche  e  soprattutto  i  legislatori  di  numerosi  stati
nazionali e organizzazioni supragovernative e intergovernative quali
il Parlamento europeo e il Consiglio d’Europa, l’OCSE e l’Unesco.

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

35

Quindi  che  cosa  è  avvenuto  in  meno  di  una  decade  per
portare  una  tematica  dall’ambito  della  fantascienza  all’ambito
della  ricerca  applicata  più  avanzata  e  soprattutto  da  richiedere
questa esigenza di intervento normativo di cui parliamo oggi? 

La  risposta  più  plausibile  è  che  c’è  stata  una  rivoluzione
tecnologica, quella che molti chiamano la rivoluzione neurotecnologica,
una rivoluzione a tutti gli effetti che crea dei nuovi contorni e che è in parte
elusiva ai nostri attuali strumenti etico-giuridici, e soprattutto strumenti di
concettualizzazione dei presupposti etico-giuridici di queste tecnologie. 

Questo è in parte vero. Io ho sostenuto in altra sede che quella
davanti  a  cui  ci  troviamo  è  una  transizione  storica  senza 
precedenti, perché se prendiamo quello che Christy Clark chiamava la
prospettiva ad ampio spettro, vediamo come per la prima volta nella
storia non solo della specie umana, ma addirittura dell’intero pianeta
Terra, un sistema biologico intelligente, quindi un sistema cognitivo
di  natura  biologica,  stia  progressivamente  acquisendo  la  capacità  di
analizzare se stesso scientificamente tramite le neuroscienze, di creare
ricorsivamente  un  sistema  cognitivo  di  tipo  artificiale,  che  è
l’intelligenza artificiale, e non da ultimo di connettersi a esso tramite
i progressi della neuroingegneria e delle nuove tecnologie. 

Tuttavia, è importante notare che molte delle tecnologie che
compongono  il  dominio  neurotecnologico  non  sono  tecnologie
emergenti, ma sono tecnologie che esistono già da svariate decadi.

36

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Ad  esempio,  la  più  comune  delle  neurotecnologie,  ovvero
l’elettroencefalografia, che è la più comune tecnica di registrazione
dell’attività elettrica del cervello, fu registrata per la prima volta nel
1924 da Hans Berger; anche la risonanza magnetica funzionale, di
cui parlava il presidente Stanzione, che è la più comune tecnica di
monitoraggio  in  tempo  reale  dell’attività  funzionale  del  cervello
umano, è una tecnica che ha già circa trent’anni; e le tecniche di
neuromodulazione - che sono quelle che vedete in basso - ovvero
tecnologie  che  non  solo  si  prospettano  l’obiettivo  di  leggere
l’attività  neurale,  ma  addirittura  di  riscriverla  attraverso  una
stimolazione,  sia  essa  elettrica  o  magnetica  dell’attività  cerebrale,
allo scopo di ottenere determinate risposte a livello neurocognitivo,
sono anch’esse tecnologie che esistono da un po’ di tempo. 

Allora che tipo di rivoluzione è la rivoluzione neurotecnologica

se queste tecnologie esistono già da qualche tempo? 

È anzitutto una rivoluzione sociotecnologica. 
Quello  che  sta  cambiando  alla  velocità  della  luce  è 
il  contesto  sociale,  economico  e  politico  che  circonda  queste 
tecnologie.  E  inoltre  sta  cambiando  il  contesto  dell’ecosistema 
digitale  e  degli  algoritmi  che  vengono  utilizzati  per  analizzare 
i dati generati da queste tecnologie. 

Quindi ci sono tre fondamentali fattori codeterminanti di

questa rivoluzione tecnologica. 

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

37

Uno  anzitutto  è  il  potenziamento  e  la  maggiore  adattabilità
dell’hardware tecnologico, che ci consente oggi di utilizzare le neuro-
tecnologie  per  fini  clinici  in  modo  da  creare  un  canale  di
comunicazione  diretta  tra 
il  cervello  umano  e  dispositivi
computerizzati esterni, quali braccia robotiche - come vedete in alto -
sedie a rotelle elettroniche, per comunicare verbalmente attraverso il
pensiero e anche per monitorare l’attività neurale in modo automatico. 
Quelle  che  vedete  qui  sono  tutte  istanze  della  cosiddetta
interfaccia  cervello-macchina  -  o  interfaccia  cervello-computer,
appunto  un  canale  di  comunicazione  diretta  tra  cervello  e
computer - e in questo canale un ruolo fondamentale viene giocato
dall’intelligenza artificiale, perché è tramite l’intelligenza artificiale
che  il  segnale  neurale  che  viene  acquisito  neurotecnologicamente
può  essere  elaborato  e  trasformato  in  un  output  che  poi  viene
generato dal dispositivo computerizzato esterno. 

Ad  esempio,  quella  che  vedete  qui  è  una  paziente
quadriplegica  che  in  questo  modo,  attraverso  l’impianto  neurale
invasivo,  quindi  impiantato  all’interno  del  cranio,  riesce  a
controllare un braccio robotico e, tramite il controllo cerebrale del
braccio robotico, riesce a nutrirsi in piena autonomia. Stessa cosa,
stesso principio per la sedia a rotelle elettronica: chi la utilizza può 
pensare  di  svoltare  a  destra  o  svoltare  a  sinistra  e  l’intelligenza 
artificiale  traduce  questo  input in  un  output,  che  poi  consentirà 
al paziente di agire in autonomia. Quindi questo è il primo punto. 
Il  secondo  punto  -  l’abbiamo  nominata  -  è  la  rivoluzione
dell’intelligenza  artificiale.  Se  noi  già  da  qualche  decade  siamo 
in  grado  di  acquisire  il  dato  neurale,  è  da  poco  tempo  che 
siamo  in  grado  di  elaborare  il  dato  neurale  con  scopi 
inferenziali  e  predittivi.  Questo  perché  il  “machine  learning”
e  altri  approcci  all’intelligenza  artificiale,  in  particolare  il 
“deep  learning”,  hanno  aperto  delle  frontiere  completamente
inesplorate per quanto riguarda l’analisi dei dati neurali. 

E grazie a questi algoritmi siamo adesso in grado di analizzare i
dati  in  modo  molto  più  efficiente  e  soprattutto,  attraverso  il 

38

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

cosiddetto processo di inferenza inversa, siamo in grado di compiere i
primi  passi  verso  quel  processo  di  decodifica  del  segnale  neurale  per
estrarne  il  contenuto  semantico  degli  stati  mentali  di  cui  parlava  il
Presidente nel suo intervento iniziale. Siamo appunto negli stadi iniziali
di sviluppo di queste tecnologie, però il progresso ha una velocità che,
comparata ad altri ambiti di sviluppo tecnologico, è senza precedenti. 
Il terzo aspetto di questa rivoluzione sociotecnologica è la

proliferazione extra-clinica delle neurotecnologie.

Se  fino  a  un  decennio  fa,  a  due  decenni  fa, 

le
neurotecnologie erano quasi esclusivamente confinate nell’ambito
della ricerca biomedica, da un po’ di tempo a questa parte c’è stata
una vera e propria proliferazione al di fuori dell’ambito clinico e
dell’ambito biomedico. 

Anzitutto,  nell’ambito  di  ricerca  militare:  numerose 
agenzie  governative  e  militari  di  numerose  nazioni  nel  mondo  -
quello  che  vedete  qui  è  il  programma  della  DARPA,  della 
Defense  Advanced  Research  Projects  Agency  degli  Stati  Uniti  -
stanno  sviluppando  delle  neurotecnologie  non  soltanto  per 
fini  terapeutici,  ad  esempio  per  assistere  i  soldati  che  tornano 
dal  fronte  con  disturbi  da  stress  post  traumatico,  ma  anche 
per  scopi  di  “enhancement”,  quindi  potenziare  le  capacità 
cognitive  dei  soldati,  ad  esempio  per  renderli  più  capaci 
di operare in assenza di sonno o in condizioni di fatica. 

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

39

Ma  ciò  che  ci  interessa  di  più  dal  punto  di  vista  della 
tutela  dei  dati  e  dei  diritti  della  persona  è  la  proliferazione 
extraclinica  delle  neurotecnologie  nel  cosiddetto  mercato  di 
consumo, le cosiddette “consumer neuro-technologies”. 

Quello a cui abbiamo assistito negli ultimi anni è uno sviluppo
enorme  di  un  intero  ecosistema  industriale  incentrato  sulle  neuro-
tecnologie, che negli ultimi cinque anni soltanto si è decuplicato in
termini  di  volume  di  investimento,  in  termini  di  numero  di
compagnie e di numero di dispositivi sviluppati in questo ambito. 

E non stiamo parlando soltanto di piccole startup e progetti
di  piccola  scala,  ma  i  più  grandi  giganti  del  digitale  sono  tutti
impegnati  nello  sviluppo  di  interfacce  cervello-computer  o  altri
tipi di altri dispositivi neurotecnologici. 

Questo  è  l’annuncio  fatto  da  Facebook  nel  2017  di 
un  programma  di  BCI,  di  “brain  computer  interface”,  finalizzato 
a  creare  un  dispositivo  in  grado  di  introdurre  informazioni 
sulla  news  feed direttamente  tramite  l’attività  del  pensiero, 
e  più  volte  è  stato  nominato  Elon  Musk  e  il  suo  Neuralink, 
il  cui  scopo,  la  cui  “finding  mission” è  proprio  quella  di 
creare  un  canale  di  comunicazione  diretta  tra  l’intelligenza 
artificiale e il cervello umano e, da un punto di vista funzionale,
Elon  Musk,  a  differenza  di  Facebook,  vuole  perseguire 
il canale della neurotecnologia invasiva, quindi tramite impianto

40

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

neurale; cosa che finora è stata testata esclusivamente su modelli 
animali,  però  Elon  Musk  ha  annunciato  di  voler  cominciare 
dei trial clinici su pazienti neurologici già a partire da questo anno,
dal  2021.  Quindi  queste  sono  le  tecnologie  in  fase  di  sviluppo.
Quali sono le tecnologie già sviluppate? 

Sono  le  cosiddette  neurotecnologie  non  invasive,  cioè 
neuro-tecnologie  che  sfruttano  le  tecnologie  di  “whereabouts”, 
quindi  al  pari  dei  nostri  smartwatch,  che  registrano  l’attività 
fisiologica  dell’organismo  ma, 
in  questo  caso,  registrano 
l’attività 
tramite
elettroencefalografia;  alcune  di  queste  sfruttano  anche  il  canale
della neuromodulazione, quindi rilasciano delle scariche elettriche
a  determinate  aree  del  cervello  con  lo  scopo  di,  ad  esempio,
migliorare i processi di concentrazione o ridurre i livelli di stress. 

cervello,  principalmente 

elettrica  del 

Tutte  le  tecnologie  che  vedete  qui  sono  tecnologie  già 
disponibili  nel  mercato  commerciale,  sono  acquistabili  da
chiunque  online  perché,  essendo  tecnologie  di  cosiddetto 
“wellness”,  non  sono  soggette  alla  medical  device  regulation, 
sia  a  livello  europeo  che  a  livello  degli  Stati  Uniti  d’America 
in base alle regolamentazioni della FDA. Quindi sono tecnologie,
come  si  dice,  “direct  to  consumer”,  cioè  direttamente  fruibili 
al consumatore. 

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

41

Quindi, alla luce di questi sviluppi così rapidi, cosa c’è da
prospettarsi? Forse la tesi un po’ provocatoria che vorrei avanzare è
che probabilmente nella decade appena cominciata ci troviamo in
una  situazione  analoga  a  quella  che 
l’inizio  degli  anni 
è stata per i personal computer. 

Gli anni ‘80 sono stati la decade in cui il personal computer è
passato dall’essere una tecnologia estremamente costosa, di utilizzo
principalmente  di  ricerca,  che  era  installata  in  grandi  stanze  di
laboratori  di  ricerca,  è  passato  a  essere  una  tecnologia  appunto  di
consumo che è sulla scrivania di ogni famiglia. Quello chepotremmo
vedere negli anni a venire è che le neurotecnologie diventino delle
“personal neurotechnologies”, cioè delle tecnologie a uso personale. 

42

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Ora  è  importante,  prima  di  analizzare  i  rischi  e  le
implicazioni  potenzialmente  negative  di  questa  proliferazione
extra clinica alle neuro-tecnologie, è importante notare però anche
che questo trend socio-tecnologico è per noi un’opportunità.

È  un’opportunità  perché?  Perché  i  disturbi  neurologici  e
neuropsichiatrici  rappresentano  una  porzione  enorme  del  “global
burden of disease”, quindi dell’impatto delle malattie a livello globale.
Soprattutto  disturbi  quali  il  morbo  di  Alzheimer,  il  Parkinson,  le
emicranie, l’ictus e così via, sono delle malattie che invalidano una
fetta enorme della popolazione mondiale. E con l’invecchiamento
della popolazione, il trend è destinato ad aumentare. 

Queste  tecnologie,  le  neurotecnologie  possono  aiutarci,

perché non possiamo curare quello che non possiamo misurare. 

Questa  è  una  legge  epistemologica  della  medicina  molto 
elementare,  e  le  neurotecnologie  anche  d’uso  extra  clinico  ci 
consentono  di  avere  la  base  dati  necessaria  per  elaborare  queste 
informazioni  per  scopi  epidemiologici  o  di  medicina  a  livello
individuale, soprattutto medicina personalizzata.

Tuttavia,  è  importante  analizzare  la  validità  scientifica 
di questi dispositivi e soprattutto le loro implicazioni da un punto di
vista della privacy e della sicurezza dei dati. 

Questi che vedete sono i risultati di un’analisi comparativa di
tutti  i  dispositivi  commercialmente  disponibili  all’anno  2018,  alla

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

43

quale ho lavorato con un neuroscienziato cognitivo, Pim Haselager, 
e con Ezekiel Emanuel, un eticista medico, e abbiamo osservato che
tutti questi dispositivi analizzati sfruttano canali di condivisione dei
dati non protetti, che elaborano informazioni contestualmente ricche
e tramite big data sono in grado di trarre conclusioni sensibili alla
privacy anche da dati non sensibili. 

Ad  esempio,  quando 

il  dato  elettroencefalografico 
è  anonimizzato,  comunque  possono  sorgere  delle  implicazioni, 
perché  il  dato  può  essere  reidentificato  o  anche  perché  può
generare delle implicazioni per la privacy a livello della cosiddetta
“group  privacy”,  quindi  rivelare  delle  informazioni  riguardo  a
determinati  gruppi  di  utenti  che  magari  hanno  una  risposta  più
lenta  a  determinati  task cognitivi,  o  presentano  dei  biomarker
di  maggiore  rischio  di  sviluppo  di  patologie  neurologiche  quali 
il  declino  cognitivo  o  il  morbo  di  Alzheimer.  E  questo  avviene 
in  assenza  di  supervisione  istituzionale  e,  con  molta  limitata 
tracciabilità  e  verificabilità  delle  inferenze  basate  sui  dati  neurali
anche  e  soprattutto  per  via  della  cosiddetta  opacità  del  machine 
learning che viene adottato da questi sistemi. 

Quindi  quello  a  cui  stiamo  assistendo  è  un  processo
attraverso cui, mediante le tecnologie che ho presentato prima, il
dato  neurale,  che  è  un  dato  che  finora  non  eravamo  in  grado 
di  registrare  al  di  fuori  dell’ambito  clinico  e  della  ricerca

44

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

biomedica,  viene  immesso  per  la  prima  volta  nel mare  magnum
dell’ecosistema  digitale,  di  quella  che  Luciano  Floridi  chiama
l’infosfera.  E  nel  momento  in  cui  il  dato  neurale  viene  immesso
all’interno  del mare  magnum dei  dati  digitali  dell’ecosistema
digitale, esso diviene esposto a tutti i rischi e vulnerabilità dei dati
personali acquisibili digitalmente e disponibili online, tra cui il data
mining, le analisi di big data, problemi di cybersecurity e così via. 

Questo processo, che è stato definito di nudità del cervello,
perché  -  come  menzionava  il  Presidente  -  per  la  prima  volta  il
cervello è fruibile all’osservazione esterna, per la prima volta il foro
interno  è  fruibile  all’analisi  e  all’elaborazione  esterna,  ha  delle
implicazioni  importanti  sulla  base  della  natura  del  dato  neurale,
perché  il  dato  neurale  è  un  dato  differente  da  altri  tipi  di  dati
registrabili per via fisiologica, per cinque principali ragioni. 

La  prima  è  per  la  sua  importanza  ontologica,  ovvero  il 
cervello non è un organo come qualsiasi altro, esso è bensì la sede
fondamentale  dei  processi  vitali  dell’organismo  e  soprattutto 
è il correlato fisiologico più diretto delle facoltà mentali, quali la
coscienza, la memoria, il pensiero e l’esperienza percettiva. 

Secondo punto, è l’importanza antropologica del dato neurale.
I fatti correlati neurali svolgono un ruolo primario nell’autopercezione
e nell’identità personale. Si è menzionato prima il cogito ergo sum di
Cartesio, e questo ha a che fare anche con l’esperienza soggettiva della
persona, dunque le implicazioni fenomenologiche del dato neurale. A
differenza di altri tipi di dati, che sono dati oggettivanti, il dato neurale
è  in  grado  di  acquisire  informazioni  riguardo  la  sfera  qualitativa  e
soggettiva  della  persona.  E  infine  c’è  un’importanza  epistemologica
che è dovuta al fatto che il dato neurale ha carattere predittivo, al pari
del  dato  genetico,  in  quanto  ci  può  dare  informazioni  predittive
riguardo allo stato di salute, al comportamento e agli stati percettivi
della persona, non solo nel presente ma anchein tempi futuri. Ci sono
interessanti studi che mostrano come algoritmi di machine learning
possano predire lo sviluppo della demenza ben due anni prima della
comparsa dei primi sintomi. 

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

45

Chiaramente,  capite  bene  che  questi  sono  tipi  di
informazioni che, nel momento in cui arrivano nelle mani sbagliate
- poniamo nel datore di lavoro o dell’assicuratore - possono creare
dei  problemi  di  grande  rilevanza.  E  infine  c’è  un’importanza
metodologica su cui vorrei porre l’accento. 

si  può  bilanciare 

A differenza di altri tipi di dati, i dati neurali non sono di
sola  lettura,  ma  sono  dati  riscrivibili;  questo  perché  al  “brain
reading”
la
neurostimolazione  e  la  neuromodulazione.  Quindi  noi,  nel
momento  in  cui  leggiamo  il  dato  neurale,  possiamo  anche
utilizzare  quell’informazione  per  modificare  l’attività  neurale
tramite le cosiddette interfaccia cervello-computer ibride. 

il  “brain  writing”,

cioè 

Quindi  sulla  base  di  queste  implicazioni  fondamentali,
assieme al giurista Roberto Andorno, abbiamo avanzato un’ipotesi;
abbiamo prima condotto un’analisi comparativa del panorama dei
diritti  che  possono  avere  rilevanza  e  possono  dare  una  guida
normativa nello sviluppo responsabile alle neuro tecnologie e, sulla
base di questa analisi, abbiamo proposto quella che per certi versi
- sicuramente il collega Pollicino ne discuterà più nel dettaglio -
può essere presentata come un’interpretazione evolutiva di diritti
esistenti, e ci siamo focalizzati su questi quattro diritti, ovvero: la
privacy  mentale,  la  libertà  cognitiva,  l’integrità  ambientale  e  la
continuità psicologica.

46

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

La privacy mentale è appunto l’applicazione, diciamo, l’istanza
del  diritto  alla  privacy  relativa  all’informazione  mentale.  Qui  è
importante  tracciare  una  distinzione  tra  privacy  mentale  e
neuroprivacy, perché la neuroprivacy è la privacy del dato neurale; non
tutti i dati neurali vengono utilizzati per fare inferenze riguardo gli stati
mentali  della  persona,  ad  esempio,  l’esempio  che  facevo  prima:  un
biomarker neurocognitivo che dimostra una predisposizione al declino
cognitivo, alla malattia d’Alzheimer, non ci dice nulla sul contenuto
semantico dello stato mentale, ma ci dà un’informazione sullo stato di
salute della persona, che è di grande importanza da un punto di vista
della privacy. 

La  privacy  mentale,  invece,  è  inerente  alla  predizione
inferenziale  degli  stati  mentali  della  persona.  Ora  è  evidente  che  la
privacy  mentale  può  essere  posta  sotto  scacco  non  soltanto  dalle
neurotecnologie,  ma  anche  dalle  tecnologie  comportamentali,  dalle
tecnologie online, i social network notoriamente; il famoso studio di
contagio emozionale di Facebook è una perfetta istanza di ciò. 

Ma  le  neurotecnologie  offrono  degli  strumenti  di  magnitudine
estremamente  più  forte  rispetto  a  tutte  le  altre  tecnologie,  perché  essi
possono  avere  accesso  ai  correlati  neurali  più  diretti  delle  informazioni
mentali. Ora, al netto delle varie teorie di filosofia della mente che pongono
l’accento sul ruolo dei fattori extra-cerebrali, è indiscutibile che il cervello
giochi un ruolo fondamentale nella determinazione degli stati mentali. 

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

47

Io avevo degli esempi che volevo farvi vedere di istanze in cui il

potenziale diritto alla privacy mentale potrebbe essere violato. 

L’esempio che volevo porre alla vostra attenzione è l’utilizzo
di  tecnologie  di  “neuromonitoring”,  quindi  di  monitoraggio
dell’attività neurale, in una scuola elementare cinese dovesono state
utilizzate  le  tecnologie  di  “neuromonitoring”  per  monitorare  i
processi di concentrazione e di apprendimento degli studenti. 

Queste tecnologie erano molto elementari: avevano una luce qui
nella  fascia  della  corteccia  prefrontale  che  si  accendeva  per  quegli
studenti che avevano, a detta del dispositivo, dei deficit di attenzione, e
lo scopo era quello di migliorare i processi di apprendimento sulla base
di queste informazioni. Chiaramente stiamo parlando di un contesto in
cui  la  confidenzialità  è  impossibile,  perché  all’interno  della  classe
l’insegnante conosce tutti i propri studenti. 

Sempre  per  quanto  riguarda  la  Cina,  sappiamo  che 
in  numerose  centrali  nucleari  e  nei  treni  ad  alta  velocità  della 
Cina  vengono  utilizzati  dei  dispositivi  di  “neuromonitoring” 
in modo obbligato, cioè il datore di lavoro impone al lavoratore 
l’utilizzo  di  questi  neuro-dispositivi  per  monitorare  l’attività
cerebrale e calibrare i flussi di produzione in modo correlato. 

Quindi in questo caso c’è un uso coercitivo, o di cosiddetta
coercizione  indiretta  del  dispositivo  neurotecnologico,  che  crea 
uno svantaggio nei confronti dell’utente.

48

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

libere  e  competenti 

La  libertà  cognitiva,  si  è  spesso  detto,  è  al  contempo 
una  libertà  positiva  e  negativa.  Positiva  nel  senso  che  essa 
pone le basi concettuali per la libertà di ciascun individuo di fare
scelte 
inerenti  al  proprio  dominio
neurocognitivo.  Ma  al  tempo  stesso  è  una  libertà  negativa  -  nel
senso sempre di Berlin - perché comporta la libertà di essere liberi 
dall’influsso esterno non autorizzato nel dominio neurocognitivo
della persona. 

Il  terzo  principio  concettuale  di  cui  volevo  parlare 
è  l’integrità  mentale  -  che  notoriamente  è  menzionata  già
nell’articolo 3 della Carta europea dei diritti fondamentali - dove 
è definito principalmente come un principio che è complementare

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

49

all’integrità  fisica,  ma  l’integrità  mentale  è  fondamentale 
per  prevenire  la  manipolazione  non  consenziente  e  dannosa 
dell’attività  neurale  della  persona  attraverso  il  cosiddetto  “brain 
hacking” o altri usi - o misusing - delle neurotecnologie. 
Anche qui non parliamo di scenari fantascientifici. 
Il  “brain  hacking”,  cioè  la  possibilità  di  hackerare 
un’interfaccia cervello-computer con fini malevoli e con potenziale
danno  per  l’utente,  è  un  fenomeno  che  è  stato  già  ampiamente 
studiato e riscontrato negli esperti di cybersecurity. 

Infine,  la  continuità  psicologica,  che  sulla  base  di  una 
tradizione di filosofia nella mente e nelle neuroscienze cognitive, 
che  risale  a  Derek  Parfit  ma  poi  continua,  comporta  un  diritto 
a  preservare  la  propria  identità  personale  e  la  continuità 
degli stati mentali da alterazioni esterne non autorizzate. 

Questo  è  un  esempio  relativamente  buffo  di  una 
persona  che  ha  cambiato  completamente  preferenze  musicali  a
seguito  di  neurostimolazione  ricevuta  per  fini  clinici,  però, 
come  potete  immaginare,  nel  momento  in  cui  una  persona 
può  modificare  dei  tratti  così  essenziali  del  gusto  e  della 
personalità,  non  è  inimmaginabile  che  degli  effetti  off  target 
di  tipo  analogo  possano  andare  a  coinvolgere  altri  aspetti 
della personalità, quali ad esempio il credo politico. 

50

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

E questo è importante da analizzare alla luce dell’intimo legame
tra cognizione e identità personale. Ora, in questi ultimissimi minuti
volevo  porre  l’accento  e  fare  alcuni  cenni  inerenti  ad  alcuni  recenti
sviluppi  nell’ambito  della  governance  e  dell’intervento  normativo
relativo alle neurotecnologie, perché questo approccio ai neurodiritti è
stato  al  centro,  negli  ultimi  anni,  di  un  crescente  dibattito,  di  una
crescente attenzione all’interno della comunità scientifica. 

Anzitutto,  ha  ricevuto 

l’endorsement  del  cosiddetto
Morningside  Group,  che  è  un  gruppo  di  venticinque  ricercatori,
coordinato dal professore Rafael Yuste, della Columbia University degli
Stati Uniti, e che ha al suo interno anche Jack Gallant, che è il neuro-
scienziato  che  sta  lavorando  alle  più  avanzate  tecnologie  di  “brain

I n t e r v e n t o   d i   M a r c e l l o   I e n c a

51

reading”, i quali hanno raccomandato l’inclusione dei neurodiritti nei
trattati internazionali.
Ad  esempio, 

loro  suggeriscono  come  clausola  alla

Dichiarazione universale dei diritti umani. 

Questo approccio incentrato e focalizzato su neurodiritti è stato
adottato  anche  dal  Comitato  sulle  neurotecnologie  dell’OCSE,  con  il
quale ho avuto la fortuna di collaborare all’interno del cui programma sulle
neurotecnologie;  abbiamo  sviluppato  il  primo  documento  di  standard
internazionale sull’innovazione responsabile nelle neurotecnologie, che è
stato adottato dal Consiglio dell’OCSE nel dicembre 2019 e, tra i vari
principi  di  innovazione  responsabile  che  propone,  come  vedete  c’è  un
focus sui neurodiritti della privacy e della libertà cognitiva. 

52

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Contemporaneamente,  il  Comitato  internazionale  di
bioetica  dell’Unesco  sta  ponendo  crescente  attenzione  al  tema
dei  neurodiritti  e  sta  valutando  la  possibilità  di  sviluppare 
una  nuova  Dichiarazione  internazionale  sul  cervello  umano  e 
sui dati cerebrali che sostanzialmente ricalca una forma analoga
a  quella  della  Dichiarazione  internazionale  sui  dati  genomici
umani. Si tratta di un programma quinquennale che ha appena
avuto inizio. 

Contemporaneamente,  anche  il  Consiglio  d’Europa  sta 
ponendo  crescente  attenzione  al  tema  dei  neurodiritti  e  ha
appena  lanciato  un  programma  di  azione  quinquennale  che  si
concluderà  nel  2025,  il  cui  scopo  principale  è  quello  di 
valutare  la  rilevanza  e  la  sufficienza  dei  framework  relative  ai
diritti  umani  attuali  per  valutare  le  implicazioni  generate  dalle
neurotecnologie. 

Quindi questo è lo scenario normativo attuale. 
Nel  frattempo  si  sono  mossi  anche  alcuni  legislatori
nazionali quali la Repubblica del Cile - e qui il collega Yuste è
stato  attivo  nello  sviluppo  di  quello  che  è  un  “proyecto  de  ley
para  la  neuroprotección”,  quindi  la  protezione  neurale,  che  è
stato  adottato  dal  Senato  del  Cile  lo  scorso  dicembre;  e  anche 
la Digital Rights Build della Spagna fa menzione dei neurodiritti
e delle neurotecnologie. 

Quindi,  concludendo,  quello  a  cui  stiamo  assistendo 
è  un  rapido  sviluppo  tecnologico.  Fortunatamente  c’è  anche 
un  rapido  sviluppo  di  strumenti  concettuali  ed  etico-giuridici 
a riguardo, però ci tengo a porre l’attenzione sul fatto che questo
è  un  processo  che  è  appena  cominciato,  ma  la  strada  davanti 
a  noi  è  estremamente  lunga  e  contorta,  per  via  della
complessitàdella  materia,  per  via  della  difficoltà  normativa, 
per  via  dell’esigenza  di  un  delicato  atto  di  bilanciamento  tra 
il  diritto  alle  neuroscienze  e  allo  sviluppo  delle  scienze  e 
delle tecnologie per lo studio del cervello, bilanciato alla tutela
dei  diritti  fondamentali  della  persona,  che  -  come  ho  cercato 

I n t e r v e n t o   d i   M e r c e l l o   I e n c a

53

di esprimere - si tratta di implicazioni che per molti versi sono
elusive  agli  strumenti  concettuali  che  abbiamo  a  disposizione
finora. 

E con questo ci tengo a ringraziarvi per la vostra attenzione 

e augurare un buon continuamento dei lavori.

54

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Quale futuro per il 
Post-umano? L’Umano*
Intervento di Giacomo Marramao

Desidero  innanzitutto  rivolgere  un  sentito  ringraziamento
per  questo  invito  al  Presidente  Stanzione  e  alla  dott.ssa  Resta. 
Non  solo  per  avere  pensato  a  me,  ma  per  avere  coinvolto  un 
filosofo  a  trattare  questioni  cruciali  che  ci  proiettano  verso  un
futuro già da tempo iniziato, entrato nelle nostre vite senza che ce 
ne accorgessimo: come una rivoluzione silenziosa. 

Ognuno  di  noi  che,  pur  non  essendo  un  nativo  digitale, 
è venuto familiarizzandosi con il mondo dei computer - dopo diversi
libri  scritti  a  macchina  e  alcuni  articoli  con  un  computer  Olivetti 
da scrivania, ho composto il mio primo libro su un laptop nel 1988,
uno Zenith comprato a New York che pesava cinque chili ma allora
mi  sembrava  leggerissimo  -  avrà  notato  che  negli  ultimi  tempi 
le traduzioni effettuate con Google Translate sono molto migliorate. 

Per quale ragione? 
Perché  prima  c’era  un  programma  che  traduceva  parola 
per parola, con effetti disorientanti o addirittura comici, mentre ora
c’è un algoritmo potente che simultaneamente trova i diversi loci, le
diverse  ricorrenze  di  un  termine  associato  ad  altri  termini 
o  contesti  sintagmatici  analoghi,  e  di  conseguenza  riesce  -  non 
sempre,  ma  molte  volte  -  a  realizzare  delle  traduzioni  di  buona 
qualità.  Tutto  ciò  non  potrebbe  accadere 
senza  una
“superintelligenza”,  direbbe  Nick  Bostrom,  capace  di  gestire  un
inimmaginabile  deposito  di  dati  confrontando  miliardi  di  frasi
analoghe per selezionare non solo i singoli termini ma le espressioni
più appropriate. 

* Il testo riproduce, con alcune rielaborazioni formali e integrazioni, la trascrizione 
dell’intervento orale.

I n t e r v e n t o   d i   G i a c o m o   M a r r a m a o

55

Anche con questo esempio a portata di mano, ci troviamo 
dunque al cospetto di un’avvisaglia del potere dell’AI, dell’Artificial
Intelligence.

Da  qui  la  prima  considerazione:  il  futuro  non  è  qualcosa 
che prevedevamo o progettavamo, ma un evento che ci sorprende.
È,  diceva  un  certo  Saulo  di Tarso  alias  San  Paolo,  il  kairós che 
ci coglie come un ladro nella notte. Per questo ho trovato quanto
mai  appropriato  e  coraggioso  il  titolo  del  nostro  incontro:
Privacy  e  neurodiritti.  Un’endiadi  davvero  espressiva  dello
Zeitgeist,  dello  spirito  del  tempo.  Poche  settimane  fa  ho
partecipato  a  un  gigantesco  webinar  internazionale,  organizzato
dalla New York University con una rete di sedi universitarie di vari
continenti,  sulle  questioni  aperte  dalle  prospettive  del
“transhuman”  e  del  “posthuman”. Due  neologismi  spesso
erroneamente assunti come sinonimi, ma che in realtà rimandano
a fattispecie molto diverse. 

Il  transumano  è  stato  definito  dal  già  ricordato  Nick
Bostrom,  filosofo  svedese  tra  i  massimi  esperti  in  Intelligenza 
il Future  of  Humanity  Institute
Artificiale,  che  dirige 
dell’Università  di  Oxford  e  presiede  la World  Transhumanist
Association (WTA), come “un movimento culturale, intellettuale
e  scientifico,  che  afferma  il  dovere  morale  di  migliorare  le
capacità fisiche e cognitive della specie umana e di applicare le
nuove tecnologie all’uomo, affinché si possano eliminare aspetti
non desiderati e non necessari della condizione umana come la
sofferenza,  la  malattia,  l’invecchiamento,  e  persino,  l’essere
mortali” (Cfr. N. Bostrom, Intensive Seminar on Transhumanism,
Yale University, 26 June 2003). Il transumanesimo si presenta,
pertanto,  come  un  nuovo  paradigma  sul  futuro  dell’umanità,
nato dal concorso di scienziati e filosofi della mente provenienti
da diverse aree (dall’Intelligenza Artificiale alla neurologia, dalla 
nanotecnologia  alla  biotecnologia  applicata),  con  l’obiettivo 
di  potenziare  la  natura  umana  e  prolungarne  le  aspettative 
di vita. 

56

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Il  movimento  transumanista  ha  raccolto  i  principi 
fondamentali  della  teoria  nella  seguente  dichiarazione: 
“L’umanità  sarà  radicalmente  trasformata  dalla  tecnologia 
del  futuro.  Prevediamo  la  possibilità  di  riprogettare  la
condizione umana in modo da evitare l’inevitabilità del processo
di  invecchiamento,  le  limitazioni  dell’intelletto  umano  (e
artificiale),  un  profilo  psicologico  dettato  dalle  circostanze
piuttosto  che  dalla  volontà  individuale,  la  nostra  prigionia  sul
pianeta terra e la sofferenza in generale”.

il  duplice 

individuo  con  capacità  fisiche, 

Dove  sta,  allora,  la  differenza  tra  il  transhuman e  il
posthuman?  Elena  Postigo  Solana,  docente  dell’Università  CEU
San Pablo di Madrid, che ha trattato le implicazioni bioetiche del
transumanesimo, ha richiamato il modo in cui lo stesso Bostrom
ha  puntualizzato 
regime  di  distinzione  e
interconnessione tra i due termini. Il “transumano” rimanda a un
essere  umano  in  fase  di  transizione  verso  il  postumano,  inteso
come  un 
intellettuali  e
psicologiche  “migliori”  rispetto  ad  un  “umano  normale”.  Il
“postumano” sarebbe pertanto una nuova entità, in parte naturale
in parte artificiale, dotata delle seguenti caratteristiche: aspettative
di  vita  superiori  ai  500  anni,  capacità  cognitive  due  volte  al  di
sopra  del  massimo  possibile  per  un  individuo  umano  attuale,
controllo degli input sensoriali, assenza di sofferenza psicologica.
Si  tratterebbe,  cioè,  di  un’entità  le  cui  capacità  oltrepassano  in
modo  eccezionale  l’essere  umano  attuale,  al  punto  tale  di
eliminare  ogni  possibile  ambiguità  tra  l’umano  e  il  postumano:
qualcuno, in definitiva, completamente diverso. Sarebbe un ente
“più  perfetto”,  più  compiuto  sia  dell’essere  umano  sia  del
transumano.

Un postumano, a detta di Bostrom, potrebbe godere di un 
ampliamento  della  vita  senza  deteriorarsi,  di  maggiori  capacità 
intellettuali, avrebbe un corpo in concordanza coi suoi desideri,
potrebbe  fare  copie  di  sé  stesso,  disporrebbe  di  un  controllo 
emozionale totale. 

I n t e r v e n t o   d i   G i a c o m o   M a r r a m a o

57

In  breve.  “Trans-human”  significa  la  possibilità  di  avere 
dei  supporti  tecnologici  che  potenziano  le  nostre  capacità 
umane.  “Post-human” invece  è  quella  stranissima  cosa  -  che 
però  è  una  “cosa”  anche  questa  ormai  molto  reale  -  che  era 
stata  prevista  dal  genio  di  Philip  Dick  già  tantissimi  anni  fa, 
ma  all’interno  di  una  prospettiva  che  non  era  ancora  quella  del
digitale  contemporaneo,  quanto  piuttosto  la  prospettiva  della
cibernetica  di  Norbert  Wiener:  sia  pure  -  ma  adesso  non  c’è 
tempo  per  approfondire  questo  aspetto  -  specularmente
rovesciata.  Vi  ritornerò  al  termine  del  mio  intervento  con  una
provocazione finale. 

Questa  soglia,  questa  linea  di  confine  che  -  come
nell’etimologia  del  lemma  con-fine,  che  rimanda  a  un  limite
condiviso  -  insieme  delimita  e  congiunge  postumano  e
transumano,  viene  ora  ad  imbattersi  nella  compagine  dei  “riti” 
e  della  “sapienza”  del  diritto:  di  quella  scienza  giuridica  che  ha 
in  Italia,  soprattutto  in  Italia  aggiungo  senza  alcuna  retorica
patriottica,  un  modello  di  prima  grandezza  su  scala  mondiale.
Ebbene, la nostra scienza giuridica, come tutta la scienza giuridica
occidentale,  ha  un  presupposto  agostiniano  soggiacente:  quello
del foro interiore. Dagli studiosi di roboetica questo presupposto
viene  ricondotto  in  modo  surrettizio  a  Cartesio,  al  Cogito
cartesiano:  come  se  la  nostra  identità  coincidesse  con  la  mente. 
A ben guardare, però, la mente non è la nostra identità. 

Questa era la posizione di Descartes, ma non di Agostino.
Agostino  arriva  al redi  in  te  ipsum a  un  certo  punto  della  sua
biografia,  così  come  riportata  nelle  Confessioni.  Il  foro  interiore
non è pura mente, ma un pensiero-corpo, un pensiero-esperienza
modellato  dal  linguaggio.  Non  dimentichiamo  che  il  berbero
Agostino,  originario  di  una  delle  regioni  culturalmente  più
avanzate  del  declinante  Impero  romano,  era  un  sofisticatissimo
retore: un intellettuale, dunque, avvezzo a lavorare sul linguaggio.
Il pensiero era per lui sempre codificato dalla parola: dalla parola
come phoné,  come  discorso  orale,  e  dalla  parola  come  graphé, 

58

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

lettura 

lectio,  nella 

silenziosa  di  un 

dalla parola scritta. Ma a quel tempo la lettura della parola scritta,
anche per intellettuali raffinati come lui, veniva declamata ad alta
voce.  Si  comprende  allora  lo  stupore  di  Agostino,  non  ancora
convertito al cristianesimo, nel vedere Ambrogio immerso in una
tacita 
codice. 
Uno  stupore  che  egli  percepì  -  l’aveva  compreso  bene  Umberto
Eco  -  come  un’autentica  rivoluzione  culturale:  la  scoperta
dell’interiorità  come  passaggio  dalla  lettura  ad  alta  voce  alla
lettura  silenziosa.  Troviamo  questa  straordinaria  testimonianza
nel  Libro  VI  delle  Confessioni.  Tenete  conto  che  siamo  ancora
nella  fase  iniziale  del  processo  di  conversione:  occorrono  altri
cinque  libri  prima  che  si  arrivi  a  quello  straordinario  Libro  XI 
che  introduce  una  riflessione  sul  tempo  che  anticipa  per  molti
aspetti  la  filosofia  e  la  scienza  contemporanea  con  la  celebre
domanda:  Quid  est  ergo  tempus?  Si  nemo  ex  me  quærat,  scio; 
si  quærenti  explicare  velim,  nescio (“Che  cos’è  dunque  il  tempo? 
Se  nessuno  me  lo  chiede,  lo  so;  se  voglio  spiegarlo  a  chi  me  lo
chiede,  non  lo  so  più”).  Frase  stupenda  e  vertiginosa:  il  tempo 
è  insieme  naturale  ed  enigmatico,  un  intreccio  inestricabile 
di ovvietà e inesplicabilità. 

Ma  torniamo  al  VI  libro  e  al  primo  incontro  con
Ambrogio.  In  realtà,  non  era  stato  un  vero  incontro,  dal
momento che Agostino, che si era recato per conoscere un uomo
su cui aveva sentito racconti straordinari, non ebbe il coraggio di
presentarsi  e  andò  via  per  non  disturbare  l’intimità  di  quella
lettura silenziosa che lo aveva profondamente colpito, pensando
che uomo eccezionale dovesse essere quello che vedeva intento a
leggere  senza  neppure  muovere  le  labbra.  Provo  a  ripercorrere 
a  memoria  quello  straordinario  passo:  Sed  cum  legebat,  oculi
ducebantur per paginas - “Ma mentre leggeva gli occhi scorrevano
le  pagine”  -  et  cor  intellectum  rimabatur - “e  il  cuore  [l’intimità
dell’animo] era intento a penetrare il significato” - vox autem et
lingua quiescebant -“mentre la voce e la lingua stavano in riposo”. 
Intimo nesso, dunque, tra parola, scrittura e foro interiore.

I n t e r v e n t o   d i   G i a c o m o   M a r r a m a o

59

A differenza di Cartesio, Agostino non diceva che noi siamo solo
mente,  puro  Cogito.  Noi  siamo  mente-cuore,  ragione-passione.
Noi  scopriamo  la  nostra  interiorità  perché  plasmati  dal
linguaggio.  E,  per  il  tramite  della tacita  lectio,  dalla  scrittura.
Sarebbe  davvero  il  caso  di  riprendere  a  studiare  alcune  delle
straordinarie storie e filosofie della scrittura di cui disponiamo. La
lingua  è  la  prima  tecnologia.  E  le  prime  istituzioni  sono  quelle
linguistiche:  e  proprio  qui  si  apre  la  possibilità  di  ripensare  il
rapporto  tra  codificazione  tecnologica  e  codificazione  giuridica.
L’essere umano è naturalmente artificiale, naturalmente tecnico.
Tecnica è, pertanto, la forma di vita umana. La prima tecnologia
è la parola. Ma la parola è anche la prima forma di potere, perché
la prima forma di potere coincide con il potere di nominazione.
Le donne lo sanno fin troppo bene, dal momento che la lingua
degli  “universali”  -  a  partire  dall’universale  “Uomo”  e  dai  suoi
diritti - è, quasi in tutte le civiltà, spiccatamente androcentrica.

Ma  torniamo  al  foro  interiore  per  affrontare  un  tema
cruciale  del  diritto:  il  tema  della  coscienza  e  del  rapporto  tra
intenzionalità e non-intenzionalità. Il problema che qui si pone è
davvero  dirimente:  quei  concetti  non  possono  restare  indenni
dopo  la  scoperta  dell’inconscio.  È  un  problema  di  decisiva
importanza, che è per me da tempo materia di discussione con il
collega Jürgen Habermas. 

Per  Habermas  si  danno  due  forme  di  comunicazione,
corrispondenti a due diversi usi del linguaggio: la comunicazione
strategico-strumentale  e  la  comunicazione  franca,  trasparente  e
pertanto herrschaftsfrei, “libera-dal-dominio”. Ma Habermas può
intanto  sostenere  una  tale  posizione  in  quanto  si  limita  a
distinguere tra un agire linguistico finalizzato a obiettivi strategici
di  potere  o  di  interesse  e  un  agire  linguistico  improntato  alla
schiettezza,  alla parrhesía,  alla  libertà  di  dire  ciò  che  si  pensa,
trascurando così completamente che si può essere sinceri con “noi
stessi”,  in  pace  con  la  nostra  coscienza,  e  tuttavia  soggetti
all’autoinganno.  La  rimessa  in  discussione  del  Cogito  da  parte

60

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

della psicoanalisi freudiana ci ha insegnato che la prima forma di
intrasparenza è l’intrasparenza con noi stessi. Capita a volte che,
nel mentre siamo convinti di dire qualcosa in maniera sincera, ci
stiamo auto-ingannando. 

L’autoinganno rappresenta oggi uno dei nodi cruciali della
teoria  e  della  socialpsicologia  della  comunicazione,  come
dimostra il moltiplicarsi degli studi sulla self-deception. Ma questo
chiama  in  causa  per  l’appunto  un  aspetto  cruciale  delle
neuroscienze, e cioè il tema che è stato più volte evocato anche
dalla neuroetica. La neuroetica - quanto diceva prima Benanti mi
pare del tutto condivisibile - è al crocevia dei dilemmi del nostro
tempo.  È  innanzitutto  il  dilemma  tra  necessità  e  libertà:  libertà
intesa  come  spazio  della  decisione.  Ora  -  senza  la  pretesa  di
indossare le vesti dell’epistemologo, come certi zelanti filosofi che
si atteggiano a ‘cronisti sportivi’ della scienza - non posso tuttavia
astenermi  dall’osservare  che  nell’ambito  della  neuroetica  alcuni
hanno parlato della preesistenza di un vocabolario morale innato:
una  sorta  di  grammatica  generativa  dell’etica  simile  a  quella
prospettata da Chomsky per la lingua. E, da filosofo, non posso
ignorare che, prima della psicoanalisi freudiana, gli studi di fine
Ottocento di un antropologo e fisico come Pierre Broca e di uno
psichiatra e neurologo come Carl Wernicke avevano messo in luce
il  nesso  tra  attività  neurale,  pensiero  e  comportamento,
anticipando per alcuni aspetti l’attuale impatto delle neuroscienze
su  vari  ambiti:  dalla  politica  all’economia,  dall’estetica  all’etica.
Non mi sfugge, pertanto, il significato della biforcazione che si è
prodotta  all’interno  della  neuroetica  tra  neuroetica  filosofica  e
neuroetica  applicata:  per  cui  la  prima  sarebbe  un’etica  delle
neuroscienze e la seconda uno studio delle basi neurologiche della
morale. 

Tuttavia,  dietro  l’apparente  accordo  sui  rispettivi  ambiti,
mi  pare  di  scorgere  un  conflitto  tra  paradigmi  opposti,  o
comunque difficilmente conciliabili: il paradigma fisicalistico e il
paradigma agenziale. 

I n t e r v e n t o   d i   G i a c o m o   M a r r a m a o

61

Per  il  paradigma  fisicalistico  non  solo  ogni  nostro
comportamento ma le stesse scelte sarebbero predeterminate dal
punto  di  vista  fisico  e  biologico.  Mentre  il  paradigma  agenziale
dice:  può  darsi  che  buona  parte  dei  nostri  comportamenti  sia
determinata  su  base  neurologica,  ma  le  decisioni  finali  sono  il
prodotto di una sorta di salto. Come se, a partire dalla medesima
situazione  che  si  determina  sotto  il  profilo  neurale,  a  un  certo
punto  ci  trovassimo  davanti  alla  scelta  tra  un  ventaglio  di
alternative: una scelta finale il cui esito è dovuto a fattori che non
possono essere predeterminati dal punto di vista neurale. Sliding
doors: vi  ricordate  quel  bellissimo  film?  A  volte  un  fattore
impercettibile,  una  scelta  aleatoria  dell’ultimo  istante  -  come
prendere o non prendere l’ascensore, oppure decidere di passare il
weekend in un luogo anziché un altro - può cambiare la vita.

Detto ciò, lo stesso paradigma della agency - almeno stando
a  Daniel  Dennett,  uno  degli  studiosi  più  acuti  dei  fenomeni
mentali  -  non  può  essere  declinato  in  termini  di  Coscienza,
poiché  la  Coscienza  -  e  lo  vedeva  meglio  Agostino  nelle
Confessioni che  non  Cartesio  -  è  un  artefatto  costruito  dal
linguaggio,  dalla  scrittura.  Si  è  parlato  prima  della  Bibbia:  del
Libro dei libri. 

Usi, costumi, abitudini, parole che danno significato a cose
ed eventi hanno determinato il cosmo linguistico-culturale della
coscienza. Il fenomeno della coscienza rappresenta, dunque, senza
ombra di dubbio un risultato evolutivo importante e, soprattutto
dal  punto  di  vista  etico  e  giuridico,  imprescindibile.  Ma  non
dobbiamo  mai  dimenticare  che  si  tratta  di  un  artefatto
linguistico-culturale  costruito  sull’erronea  idea  dell’infallibilità
dell’introspezione.  Come  il  cervello,  con  buona  pace  del
fisicalismo,  non  spiega  le  sfumature  e  i  salti  imprevedibili  della
psiche umana, così non esiste una “morale prima della morale”,
come  pretende  l’odierna  retorica  psicologica  e  filosofica
dell’empatia.  Occorre  dunque  guardarsi  -  come  ha  ammonito
Wray  Herbert  presentando  un  libro  di  David  DiSalvo  -  “dalla

62

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

moltitudine  di  pubblicazioni  di  pessima  qualità  che  circolano
sull’argomento”. Provate a leggere gli psicologi e gli psicobiologi
oggi alla moda: gli uni per l’empatia, gli altri per il “gene egoista”.
In  realtà,  né  l’una  cosa  né  l’altra,  o  le  due  cose  insieme.  Perché
cos’è  che  caratterizza  la  natura  umana,  quella  strana  figura  o,
come  lo  chiamava  Foucault  -  prima  citato  dal  Presidente,  ma
Foucault ha detto cose alquanto contraddittorie nella sua opera-,
quell’“allotropo empirico-trascendentale” che chiamiamo uomo?
Ebbene l’umano, quell’animale che si è venuto attrezzando contro
i rischi e le contingenze dell’ambiente dando luogo a una “forma
di  vita  tecnica”,  come  diceva  Canguilhem,  uno  dei  maestri  di
Foucault, è determinato dal possibile. 

Lo  avevano  colto  alla  perfezione  i  grandi  autori  del
Rinascimento italiano: entro l’amplissimo ventaglio dei possibili
che  ne  caratterizzano  la  natura,  l’individuo  umano  può  essere
l’animale più abbietto del creato o prossimo a un angelo. E si dà
talora  il  caso  che  le  due  nature  coabitino  nella  stessa  persona.
Questa estrema varietà e contingenza dell’umano è la sfida che il
diritto  si  trova  oggi  a  fronteggiare  davanti  alla  soglia  dei
cambiamenti indotti dall’antropotecnica. 

Riprenderei  a  questo  punto  il  filo  del  discorso  sulla 
neuroetica.  Si  deve,  com’è  noto,  alla  neuroscienziata  e  filosofa
Adina  Roskies  la  proposta  di  una  partizione  tra etica  delle 
neuroscienze e  neuroscienze  dell’etica.  L’etica  delle  neuroscienze 
è  la  condotta  da  tenere  nell’elaborazione  e  applicazione  delle 
ricerche  neuroscientifiche,  tenendo  conto  dell’impatto  che  i 
risultati di tali ricerche possono determinare sulle strutture etiche,
sociali  e  giuridiche.  Le  neuroscienze  dell’etica  ci  parlano  invece
della  ricaduta  delle  indagini  sul  funzionamento  del  cervello  su 
nozioni-chiave  quali  decisione,  intenzione,  libero  arbitrio,
identità  del  sé.  Ma  qui  sorge  la  domanda:  noi  siamo  il  nostro
cervello?  No,  noi  non  siamo  soltanto  il  nostro  cervello.  Diversi
neurologi sono giunti alla conclusione che la ragione, il pensiero,
non  sono  concentrati  nel  cervello,  e  vari  ambiti  della  ricerca

I n t e r v e n t o   d i   G i a c o m o   M a r r a m a o

63

scientifica  hanno  messo  in  evidenza  il  nesso  che  intercorre  tra
pensiero,  emozioni,  e  sensazioni,  con  tutti  i  loro  correlati
neurofisiologici.  È  proprio  la  scienza,  quella  più  avvertita,  ad
ammettere  di  non  poter  spiegare  come  da  questa  complessità  si
formi un “Io”, una struttura identitaria. Risiede qui uno dei nodi
problematici  cruciali  del  rapporto  tra  la ratio  juris e  le  nuove
frontiere della scienza. Nel 1991 - i giuristi qui presenti lo sanno
benissimo  -  la  Corte  Costituzionale  ha  sancito  il  valore
costituzionale inalienabile della tutela della coscienza intesa come
-  e  qui  cito  -  “nucleo  essenziale  di  uno  o  più  diritti  inviolabili
dell’uomo”,  “principio  creativo  che  rende  possibile  la  realtà 
delle libertà fondamentali” e “regno delle virtualità di espressione
dei diritti inviolabili del singolo nella vita di relazione” (sentenza
n.  467,  1991).  Una  formulazione  molto  complessa,  come  avete
sentito, che si colloca lungo una nobile linea di confine tra diritto,
morale  e  filosofia.  Le  scienze  contemporanee  -  sulla  scia  della
critica delle nozioni di sostanza, causa e personal identity operata
da  David  Hume  -  hanno  contribuito  a  dissolvere  la  concezione
essenzialistica  dell’identità  nell’idea  di  un  multiple  Self.  Ogni
individuo  (a  dispetto  dell’etimologia  del  termine)  è  un  Sé
multiplo, modellato dalla molteplicità dei volti, degli incontri e
degli eventi che hanno segnato il percorso della sua vita. Proprio
perché  l’umano,  come  dicevo  prima,  è  contrassegnato  dal
possibile, la sua identità non è mai precostituita biologicamente
ma aperta alla contingenza e al cambiamento. La nostra identità
non sta, dunque, nella nostra biologia, ma trova espressione nella
nostra biografia. 

Che  l’identità  della  persona  non  sia  data  una  volta  per
tutte,  è  un  dato  da  tempo  acquisito  alla  teoria  come  alla  prassi
giuridica. Tant’è  vero  che  il  diritto  penale  non  solo  prevede  ma
auspica  la  metànoia,  la  redenzione,  il  recupero  del  carcerato:
anche un criminale, anche un assassino, può cambiare, diventare,
come  dice  il  diritto  stesso,  “un’altra  persona”.  Si  tratta  di
un’acquisizione  decisiva,  da  tener  ferma  contro  il  “rischio

64

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

tecnologico”  del  diritto:  con  l’eterno  ritorno  della  tentazione
neolombrosiana  di  ricercare  l’origine  di  un  comportamento
criminale  in  lesioni  cerebrali  e  di  fondare  su  basi  neurologiche
una  previsione  di  pericolosità  sociale  avvalendosi  di  tecniche
come il memory detector per riscontrare nella mente di un soggetto
tracce  di  memoria  autobiografica  legate  a  un  delitto  di  cui  è
sospettato.  L’adozione  di  siffatte  tecniche  computerizzate  di
memory  detection sarebbe  comunque  in  contrasto  con  l’art.  188
del nostro Codice di procedura penale, secondo cui “non possono
essere  utilizzate,  neppure  con  il  consenso  della  persona
interessata,  metodi  o  macchine  idonei  a  influire  sulla  libertà  di
determinazione  o  ad  alterare  la  capacità  di  ricordare  e 
di valutare i fatti”. E tuttavia….

E tuttavia i nuovi scenari aperti dall’intreccio tra robotica
digitale,  genetica  e  Intelligenza  Artificiale  tendono  a  volte  ad 
assumere  le  sembianze  di  un  transfert  perverso  dell’idea  di 
trasparenza  dalla  tradizionale  dimensione  della  “coscienza 
interiore”  al  piano  dei  circuiti  cerebrali.  Si  profila  così  un
paradigma  di  onnitrasparenza  che  suona  come  una  revoca  in
questione  delle  categorie  giuridiche  fondate  sulla  libertà  del
volere: rectius, sulla categoria di volontarietà intesa come variabile
dipendente  di  una  scelta  consapevole.  Le  nuove  tecnologie  di
interazione e comunicazione digitale sono di fatto condizionanti
non  solo  per  l’invasione  della  privacy,  ma  per  la  colonizzazione
del  pensiero,  profilandosi  come  una  minaccia  a  quella  che  il
Presidente Stanzione chiamava l’”Habeas mentem”. 

La strategia di “personalizzazione” adottata dai colossi del
digitale  e  dagli  stessi  social  media  ci  espropria  non  solo  della
nostra sfera personale ma della nostra stessa mente, che viene così
colonizzata da immagini, parole e notizie che la rimodellano. Per
altro  verso,  le  prospettive  di  interazione  tra  cervello  umano  e
dispositivi artificiali, fino alla possibilità di trasferire gli “archivi
di  memoria”  della  mente  umana  su  supporti  extracorporei,
sembrano  alimentarsi  della  chimera  trans-umanistica  di  una

I n t e r v e n t o   d i   G i a c o m o   M a r r a m a o

65

sopravvivenza della coscienza oltre il decadimento del corpo e la
stessa morte.

Un’autentica  “chimera”,  per  la  semplice  ma  decisiva 
ragione  che  noi  non  siamo  solo  mente,  ma  complesso  mente-
corpo.  L’ha  spiegato  con  luminoso  rigore  il  neurologo  Antonio 
Damasio  quando,  nel  suo  ormai  famoso  libro  del  1994 L’errore 
di  Cartesio,  ha  invitato  a  liberarsi  del  dualismo  mente/corpo, 
per poi adottare in un’opera successiva una splendida espressione
di Baruch Spinoza: “La mente è l’idea del corpo”. Ma se la mente
è  un’idea  del  corpo,  il  cervello  un feeling  brain,  è  un  sentire  il
corpo emozionalmente.

Ma vi è di più. Occorre ora rispondere a un’altra domanda,
una  domanda  che  va  molto  oltre  le  neuroscienze:  in  che  modo 
l’intreccio  mente-corpo  costitutivo  delle  individualità  umane 
si colloca nella nuova visione cosmologica fondata, con la teoria
della  relatività  e  la  meccanica  quantistica,  sull’equazione  di
materia ed energia? 

È la questione posta diversi anni fa dal matematico e fisico
Roger Penrose, i cui modelli matematici sono stati fondamentali
per la ricerca di Stephen Hawking sui buchi neri. Avevo trattato
approfonditamente  l’argomento  di  Penrose  nel  lontano  1992, 
nella  prima  edizione  del  mio  libro  Kairós.  Apologia  del  tempo
debito, che la Bollati Boringhieri ha di recente riproposto in una
nuova edizione ampliata. Ricordo che allora alcuni amici, fisici e
filosofi  di  rilievo,  mi  criticarono  per  aver  dato  eccessiva
importanza a un bizzarro matematico come Penrose anziché allo
stesso Hawking. La mia risposta fu molto secca: soffermarmi sul
già  celebratissimo  costruttore  della  “Teoria  del  Tutto”  sarebbe
stato  troppo  ovvio  e  banale,  mentre  ritenevo  assai  più  utile
mettere in luce l’originalità di quello che loro consideravano un
collaboratore che viveva di luce riflessa. A quanto pare, non avevo
poi tutti i torti, visto che lo scorso anno Penrose è stato insignito
del premio Nobel per la fisica. 

Ma veniamo alla sua tesi. Anche Penrose si proietta oltre 

66

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

il dualismo, ma con un argomento diverso da quello di Damasio.
Nel  giudicare  Cartesio,  osserva  Penrose,  non  possiamo
dimenticare che l’immagine del mondo della sua epoca era quella
della  rivoluzione  scientifica  galileiana.  Anzi,  la  rilevanza  di
Cartesio  sta  nell’aver  costruito  il  primo  sistema  metafisico
moderno, modellato sull’universo-macchina di Galileo. Rispetto
a  quel  modello  il  dualismo  cartesiano  non  era  un  “errore”. 
Un  universo  meccanico,  costruito  come  una  catena  di  cause
efficienti,  non  è  in  grado  di  includere  in  sé  il  fenomeno  della
mente.  Per  questo  Cartesio  si  era  visto  costretto  a  trovare  per 
il  pensiero,  per  la res  cogitans,  un  fondamento  ontologico
autonomo  rispetto  a  quello  della  materia,  della res extensa.  Solo
un universo quantistico è in grado di includere in sé il fenomeno
della  mente:  proprio  perché  solo  l’immagine  della  materia  non
più  come  una  catena  di  causazioni  ma  come  un’energia
discontinua, scandita da scarti e salti quantici, ammette la libertà
dell’evento.  Per  questa  ragione,  conclude  Penrose,  la  mente
scaturita  dall’energia  quantica  della  materia  non  è  un  semplice
fenomeno psicologico ma un evento cosmologico. Ed è in virtù 
di  questa  libertà  dell’evento  che  con  il brain  imaging possiamo
conoscere  la  topografia  (il  dove)  e  talora  la  dinamica  cerebrale 
(il quando), ma non il come e il perché da quei processi scaturisca
il ‘salto’ della scelta. 

Poche  parole,  dunque,  per  concludere.  Su  questa  soglia
nella  quale  ci  troviamo  è  possibile  declinare  il  postumano  -  ma
non so fino a che punto il termine sia ancora appropriato - come
una rottura del paradigma antropocentrico e una rinegoziazione
del nostro posto nel pianeta sul duplice versante della tecnica e
delle  forme  di  vita  animali  e  vegetali.  Una  tale  prospettiva
aprirebbe  delle  possibilità  straordinarie  di  utilizzare  le  nuove
tecnologie  e  la  stessa  Intelligenza  Artificiale  non  in  funzione  di
potere, di controllo e di addomesticamento del “gregge umano”,
come  vorrebbe  il  delirio  dei  potenti,  ma  per  stabilire  un  nuovo
rapporto  con  l’ecosistema  fondato  su  uno  sviluppo  non  più

I n t e r v e n t o   d i   G i a c o m o   M a r r a m a o

67

quantitativo, ma qualitativo. Non una decrescita, ma una crescita
della qualità, a partire dal presupposto per cui ognuna e ognuno
di noi è una combinazione unica e irripetibile di mente e corpo,
pensieri ed emozioni, desideri e immagini, cognizione del dolore
e intelletto d’amore. Ognuna e ognuno di noi è al contempo un
esperimento unico e un experimentum mundi.

Dobbiamo allora affrontare i nuovi orizzonti della tecnica
e  dell’Intelligenza  Artificiale  con  etica  della  responsabilità  ma
senza  timori:  nella  consapevolezza  che  anche  il  più  supersonico
dei robot digitali non potrà mai avere la memoria attiva, creativa,
del più umile degli esseri umani. 

A meno che - per parafrasare una provocatoria battuta del
grande Philip Dick - un giorno non ci si imbatta in un androide
antropomorfo che, davanti a una domanda del tipo “Che tempo
fa oggi?”, risponda: “Prima Lettera ai Corinzi”. 

Allora ci troveremmo al cospetto di uno scenario inedito,
magari  suggestivo,  ma  certo  assai  più  inquietante  di  quello
descritto da Player Piano di Kurt Vonnegut. 

68

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

Costituzionalismo, privacy
e neurodiritti
Intervento di Oreste Pollicino

1. Introduzione
Innanzitutto  un  sentito  ringraziamento  al  Presidente  ed 
ai  Componenti  del  Collegio  per  questo  invito  che  mi  onora. 
Ci tengo anche a ringraziare la dott.ssa Federica Resta per uno scam-
bio di riflessioni per me prezioso.

emancipazione 

Il  tema  che  qui  si  affronta  oggi  è  di  fondamentale 
importanza nell’era dei big data.1 Queste tecniche di trattamento
dei dati (anche personali) tendono, per definizione, a emanciparsi
dalla questione legata alle singole identità. Come anche osservato
da Shoshana Zuboff nel suo libro “Il capitalismo della sorveglianza”,
tale 
concetto 
di identità personale.2 Di conseguenza, la tutela dei dati personali,
come  poi  tradotta  nel  Regolamento  679/2016,  anche  noto 
come  GDPR,  viene  posta  all’angolo  perdendo  in  parte  quella 
capacità di assicurare forme di tutela che derivano dalla matrice per-
sonalistica  del  costituzionalismo  europeo.  Una  matrice  che 
è croce e delizia.

fuori  del 

avviene 

al  di 

La  domanda  per  il  giurista  è  quale  sentinella  notturna 
può  opporsi  a  quell’intrusione  del  “ladro  nella  notte”  prima 
evocato  dal  prof.  Marramao.  E  la  risposta  non  può  che  essere 
biunivoca, perché il dilemma che si deve affrontare è quello relativo
alla elaborazione di nuovi diritti per nuove istanze di tutela o, in-
vece, alla possibilità che i cataloghi dei diritti preesistenti siano in
grado invece di fornire una tutela effettiva a queste nuove istanze.
Non si tratta di una questione formale né nominalistica, 

1 G. De Gregorio, R. Torino, Privacy, tutela dei dati personali e Big Data, in E. Tosi (a
cura di), Privacy Digitale, Giuffrè 2019, 447; G. Della Morte, Big data e protezione
internazionale dei diritti umani. Regole e conflitti, Editorial Scientifica 2018. 

2 S. Zuboff, Il capitalismo della sorveglianza, Luiss University Press, 2019.

I n t e r v e n t o   d i   O r e s t e   P o l l i c i n o

69

ma  di  una  portata  sostanziale  che  è  relativa  al  tema  cruciale 
dell’effettività  della  tutela  dei  diritti  in  gioco  nell’era  digitale. 
In particolare, il rischio è quello della possibile inflazione dei diritti,
perché  non  è  neutrale  aggiungere  un  nuovo  o  nuovi  diritti  al 
catalogo. Tale inflazione, amplificando la conflittualità potenziale
tra i diversi diritti in gioco, potrebbe portare non ad un avanza-
mento della tutela, ma addirittura a una diminuzione della stessa. 
Da questo punto di vista, un’altra questione interessante pro-
viene  dalle  riflessioni  precedenti  di  Marcello  Ienca  che  osserva 
come diverse sfide assai istruttive ai nostri fini si erano già poste 
per la prima volta all’indomani della diffusione della dimensione
digitale. Rispetto a quelle lezioni, le questioni legate al rapporto tra
costituzionalismo, privacy e neurodiritti va valutata con le sensibi-
lità e con le caratteristiche tipiche dei due modelli costituzionali a 
confronto  in  prospettiva  transatlantica,  cioè  quello  europeo  e 
quello statunitense. 

2. La rule of law come terreno comune
Prima  di  focalizzarsi  su  queste  due  sponde,  sembra 
opportuno sottolineare un primo terreno comune, in particolare,
quello  legato  alla  ‘rule  of  law’, allo  stato  di  diritto.3 Sul  punto 
è possibile citare un passaggio di un articolo del Presidente della
Corte europea dei diritti dell’uomo, Robert Spano, recentemente
pubblicato sull’European Law Journal: “Io direi che alla base della
‘rule of law’ vi è il rispetto dell’autonomia personale e l’esclusione
dell’arbitrio  da  parte  dei  governi  e  dei  poteri,  sia  pubblici  che 
privati”.4 Da  questo  emerge  che  il  concetto  dell’autonomia 
personale è il terreno di incontro tra le due sponde.

In un contesto sempre più digitale, il principio di rule of law

3 M. Krygier, The Rule of Law: Legality, Teleology, Sociology, in G. Palomblla and N.
Walker (ed.), Relocating the Rule of Law, Hart, 2009; J. Waldron, The Concept and
the Rule of Law, in Georgia Law Review 43, 1, 2008, 1.

4 R. Spano, The rule of law as the lodestar of the European Convention on Human Rights:
The Strasbourg Court and the independence of the judiciary, in European Law Journal
2021.

70

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

è sotto pressione.5 Lo sviluppo di nuovi metodi di trattamento 
dei dati personali che si traduce nella creazione di profili predittivi
è solo un esempio di come valori e principi costituzionali vengono
percepiti, interpretati e modellati nella c.d. società dell’informa-
zione.6 Lo  stato  di  diritto  non  è  stato  risparmiato  in  questo 
processo  di  inquadratura  delle  categorie  tradizionali  alla  luce 
delle  dinamiche  tecnologiche.  La  tecnologia  costituisce  infatti 
anche un’opportunità per promuovere il principio della rule of law
poiché può fornire migliori sistemi di applicazione delle politiche
pubbliche nonché un chiaro e un quadro affidabile che compensi
le inefficienze che di fatto minano la certezza del diritto.

In  questo  quadro  tra  innovazione  e  rischio,  la  domanda 
da porsi è se le tecnologie digitali incoraggino l’esercizio di poteri
arbitrari  che  possano  comprimere  quell’autonomia  personale 
alla base dello stato di diritto. Il rispetto di tale principio è una 
precondizione per garantire la parità di trattamento davanti alla
legge, tutelando i diritti fondamentali, prevenire l’abuso di potere
da  parte  delle  autorità  pubbliche  e  ritenere  responsabili  gli 
organi  decisionali.  Pertanto,  il  principio  di  rule  of  law è  un 
baluardo costituzionale che limita l’esercizio delle autorità al di fuori
di  qualsiasi  limite  costituzionale  e  garantisce  che  questi  limiti 
rispondano a uno schema costituzionale comune.

Nella  società  dell’informazione,  questo  principio  è  una 
garanzia  primaria  per  garantire  che,  quando  gli  attori  pubblici 
utilizzano tecnologie digitali, ad esempio, per fornire servizi più 
efficienti o migliorare lo svolgimento di compiti pubblici, l’esercizio
di queste attività non sia discrezionale ma basato su regole chiare 
e  proporzionate.  Allo  stesso  tempo,  la  mancanza  di  esperienza 
delle  autorità  pubbliche  e  il  consolidamento  dei  gatekeeper

5 O. Pollicino, G. De Gregorio, Constitutional Democracy in the Age of Algorithms:
The Implications of Digital Private Powers on the Rule of Law in Times of Pande-
mics, IACL Democracy Roundtable, 2020.

6 A. Simoncini, L’algoritmo incostituzionale. intelligenza artificiale e il futuro delle li-

bertà, in BioLaw Journal, 1, 2019, 63.

I n t e r v e n t o   d i   O r e s t e   P o l l i c i n o

71

online hanno  spinto  il  settore  pubblico  a  fare  sempre  più 
affidamento  su  attori  privati    per  garantire  l’applicazione  delle 
politiche pubbliche online.7 La pandemia non solo ha amplificato
le sfide tecnologiche come nel caso del tracciamento dei contatti,
ma  ha  anche  mostrato  il  ruolo  degli  attori  privati    nell’agire 
come digital utilities. Facebook, Amazon e Zoom sono solo tre
esempi di attori che hanno permesso lo svolgimento di attività 
quotidiane durante la pandemia.

Tuttavia, in mancanza di regolamentazione o applicazione
orizzontale dei valori costituzionali, il principio dello stato di diritto
non limita la libertà di cui godono gli enti privati   nello svolgimento
delle loro attività, compreso il diritto alla libertà di espressione o
alla libertà economica. In un ambiente digitale globale, le minacce
per  il  principio  dello  stato  di  diritto  non  provengono  solo 
dall’attuazione di tecnologie digitali da parte di attori pubblici, 
ma  anche,  e  principalmente,  dalla  capacità  degli  attori  privati 
  transnazionali  di  sviluppare  e  applicare  standard  privati    in 
concorrenza con valori pubblici. 

Detto questo, è evidente che la questione si pone in maniera
diversa  negli  Stati  Uniti  e  in  Europa,  perché  la  dimensione 
sacrale  del  Primo  Emendamento  della  Costituzione  americana 
chiaramente caratterizza dal punto di vista assiologico il dibattito
transatlantico.  Secondo  la  visione  statunitense,  la  libertà  di 
espressione è interpretata come cognitive freedom e protetta (quasi)
a livello assoluto. Questo approccio nasconde un grande rischio 
di  partire  dal  presupposto  sbagliato  per  cui  il  pensiero  sarebbe 
“invincibile” fin quanto resta tale e soltanto quando questo viene
estrinsecato allora meriterebbe di essere anche tutelato. Si tratta 
di un presupposto sbagliato, per l’appunto. 

L’anticipazione  della  tutela  è  quindi  fondamentale  in 

7 J. R. Reidenberg, States and Internet Enforcement, in U. Ottawa L. & Tech. J. 1, 213,
2003; M. D. Birnhack, N. Elkin-Koren, The Invisible Handshake: The Reemergence
of the State in the Digital Environment, in Virginia Journal of Law & Technology,
8, 2003, 1.

72

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

questo  contesto.  Come  affermato  dal  Presidente  dell’Autorità 
Garante,  il  professore  Pasquale  Stanzione,  presto  la  tutela  delle 
nostre libertà fondamentali potrebbe richiedere non solo un habeas
corpus (il  fondamento  dello  stato  di  diritto)  e  un  habeas  data 
(fondamento della nozione moderna di privacy) ma anche un habeas
mentem a fondamento delle libertà individuali e dei diritti della per-
sona in un mondo in cui sfumano i confini tra uomini e macchine. 
La  buona  notizia  è  che  le  fondamenta  giuridiche  dei 
neurodiritti potrebbero essere già presenti (quasi profeticamente)
nelle  Carte  esistenti.  Certo,  una  prima  lettura  di  tali  Carte, 
accompagnata  da  un’interpretazione  letterale,  potrebbe  farci 
pensare al contrario.

Il riferimento alla tutela è quasi sempre collegato al momento
dell’espressione  del  pensiero.  Il  che  potrebbe  fare  presumere, 
e sarebbe una presunzione errata, che il pensiero in sé, inespresso,
avrebbe uno scudo di invincibilità, e quindi non necessiterebbe di
tutela  costituzionale.  Si  tratterebbe  di  una  lettura  errata  che 
decontestualizza il testo (costituzionale) dal contesto sia storico 
che tecnologico. Risulta evidente infatti che i framers delle Carte di
prima,  seconda  e  terza  generazione  non  potessero  prevedere 
espressamente  ciò  che  era  tecnologicamente  imprevedibile. 
Vale  a  dire,  come  si  è  cercato  di  fare  emergere  prima,  anche 
il pensiero non espresso né sussurrato può rappresentare uno spazio
potenzialmente  a  repentaglio  e  quindi  bisognoso  di  una 
protezione di carattere costituzionale.

Il  fatto,  tuttavia,  di  non  avere  previsto  espressamente 
detta protezione non vuol dire che sia esclusa. Al contrario, una 
interpretazione  evolutiva  e  tecnologicamente  orientata  del 
giudice, non solo costituzionale, sembra in grado, sin da subito, 
di garantire una tutela effettiva all’habeas mentem. Anche perché,
come già sottolineato, nuove Carte, e nuovi diritti, non portano
per  forza  di  cose  ad  un  innalzamento  della  tutela  dei  valori  al 
gioco. Al contrario, l’inflazione dei diritti non può che portare 
al conflitto e quindi all’effetto esattamente contrario.

I n t e r v e n t o   d i   O r e s t e   P o l l i c i n o

73

3. La tutela della privacy attraverso l’Atlantico
Già a proposito di tecnologie non di carattere neurale ci sono 
stati degli insegnamenti e delle lezioni da trarre. Brandeis e Warren
facevano  riferimento  a  quella  “peace  of  mind” ossia  quella 
dimensione emotiva che è esattamente la prima pietra angolare 
della  privacy,8 prima  che  quarant’anni  fa  -  come  ricordava  il 
Presidente Stanzione - si passasse da quella dimensione statica del
diritto  a  essere  lasciato  solo  a  quella  dimensione  dinamica  del 
controllo  dei  dati.  È  lì  che  atterra  in  Europa  la  data  protection 
nel 1981. 

Ma già prima, a cominciare dal 1950 e dall’articolo 8 della 
Convenzione  europea  dei  diritti  dell’uomo,  è  quel  diritto  a 
essere  lasciato  solo  che  include  una  dimensione  emotiva  e  non 
solo  fisica.  Questo  emerge  anche  quando  si  guarda  al  contesto 
statunitense  nel  caso  Olmstead,9 in  una  delle  più  importanti 
opinioni dissenzienti del giudice Brandeis quando precisava che,
seppur  la  conversazione  telefonica  nel  caso  in  questione  era 
stata  intercettata  con  strumenti  tecnologici  che  sono  posti 
all’esterno dell’abitazione, il quarto emendamento tutela l’individuo
dalle  interferenze  del  potere  pubblico.  Qui  si  può  leggere  il 
riferimento ad Hart, più precisamente al dilemma tra punto di 
vista  esterno  e  interno,  perché  evidentemente  la  maggioranza 
della Corte suprema aveva un punto di vista esterno alla tecnologia
e  quindi  evidentemente  non  poteva  considerare  che  quel  tipo 
di interferenza riguardasse il diritto alla privacy. 

Invece  Brandeis  propone  un  punto  di  vista  interno  alla 
tecnologia, per cui quelle conversazioni “that are only whispered”
meritano  comunque  di  essere  tutelate.  Ebbene  quel  sussurro 
oggi è anticipato rispetto al semplice silenzio, attraverso la lettura 
di possibili proiezioni mentali.

Se  è  vero  che  la  pietra  miliare  per  la  ricostruzione  della 

8 S. D. Warren, L. D. Brandeis, The right to privacy, in Harvard Law Review, 4, 1890,

193.

9 Olmstead v. United States, 277 U.S. 438 (1928).

74

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

nascita ed evoluzione della tutela della privacy e dei dati personali
è la teorizzazione americana di Warren e Brandeis, è anche vero che,
rispetto  all’ordinamento  giuridico  statunitense,  in  Europa, 
la  protezione  dei  dati  personali  e  la  privacy  digitale  hanno 
acquisito lo status di diritti fondamentali. In realtà, questi diritti
assumono  una  natura  super  fondamentale,  che  sembra  non 
trovare  alcun  limite  nella  dimensione  territoriale  dell’UE  e 
nel processo di bilanciamento tra diritti fondamentali.

Quando invece si sposta l’attenzione sull’Europa e la sua 
sensibilità, come è stato detto sottolineato dal Presidente Stanzione,
il  primo  emendamento  del  costituzionalismo  europeo  è,  prima 
ancora che la privacy,10 la dignità dell’uomo che evidentemente
trova  il  suo  fondamento  in  quella  prima  sentenza  della  Corte 
costituzionale tedesca del 1983,11 nella quale si identifica la tutela
dell’autodeterminazione informativa in due articoli della Costitu-
zione  tedesca:  l’articolo  1,  dignità,  e  l’articolo  2,  i  diritti  della 
personalità. 

Il diritto al libero sviluppo della propria personalità come ri-
flesso del primo emendamento europeo, cioè dignità, e privacy, 
caratterizza tutto il sistema europeo. L’attenzione merita di essere
posta non solo sull’articolo 3 della Carta dei diritti dell’Unione, 
o sugli articoli 7 e 8, ma su un articolo che è al di là di qualsiasi 
sospetto tecnologico, cioè l’articolo 8 della Convenzione europea
dei diritti dell’uomo, che parla di rispetto della vita privata, e che,
come già sottolineato, non poteva prevedere l’evoluzione positiva
del diritto alla privacy quando ancora i primi database non erano
stati sviluppati in Europa. 

Questa evoluzione è iniziata nella seconda metà del XX se-
colo nel sistema della Convenzione europea dei diritti dell’uomo
quando il diritto alla privacy è stato codificato considerandolo come

10 Bilyana Petkova, Privacy as Europe’s first Amendment, in European Law Journal, 25,

11 German Federal Constitutional Court’s Judgment of 15 December 1983, 1 BvR 209,

2019, 140.

269, 362, 420, 440, 484/83.

I n t e r v e n t o   d i   O r e s t e   P o l l i c i n o

75

il 

europeo 

costituzionale 

riconoscimento 

una  sorta  di  habeas  corpus riguardante  le  proiezioni  spaziali  e
relazionali  di  una  persona.  Come  negli  Stati  Uniti  anche  nel 
quadro 
la 
codificazione  del  diritto  alla  privacy  sono  stati  originariamente 
pensati lungola linea “negativa”, cioè il riconoscimento del diritto
al rispetto della propria vita privata, tuttavia nei decenni successivi 
questo  proprio  ha  subito  una  profonda  trasformazione.  Anzi, 
soprattutto  a  causa  di  un’accelerazione  della  tecnologia,  una 
dimensione “positiva” del diritto alla protezione dei dati personali
ha  arricchito  la  dimensione  “negativa”,  tipica  del  diritto  alla 
privacy. 

e 

Questo  allargamento  alla  protezione  dei  dati  personali 
ha  segnato  un’espansione  di  un  diritto  inizialmente  limitato  al 
concetto  “tradizionale”  di  privacy.  In  questo  scenario,  è  stato 
importante  il  ruolo  svolto  dalla  Corte  europea  dei  diritti 
dell’uomo  che  ha  affrontato  alcuni  cambiamenti  tecnologici 
e le sfide del trattamento dei dati online.

In  questo  contesto,  le  istituzioni  dell’allora  Comunità 
europea furono più lente nel codificare un diritto alla protezione
dei dati o alla privacy digitale, a causa della loro originale ispirazione
economica.  Per  molto  tempo,  nell’ordinamento  dell’Unione 
europea, i diritti individuali sono stati riconosciuti quasi esclusiva-
mente  al  fine  di  garantire  le  libertà  economiche  fondamentali: 
di conseguenza, in questo contesto, era difficile fare della protezione
dei dati personali una questione che potesse catturare l’attenzione
delle istituzioni europee per il suo impatto diretto su alcuni diritti
fondamentali.

Il punto di rottura è stata la Direttiva 95/46/CE, anche se 
a ispirarla è stata una dimensione economica. La Direttiva è stato 
il  primo  strumento  giuridico  nel  sistema  giuridico  dell’UE 
che ha promosso l’armonizzazione a livello dell’UE delle norme
sulla privacy e sulla protezione dei dati e ha stabilito sia alcuni 
principi generali sia alcune regole speciali basate su trattamenti 
particolari. In questo scenario, il diritto fondamentale embrionale

76

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

alla protezione dei dati personali e alla privacy digitale ha iniziato
ad acquisire una declinazione concreta. 

In realtà, il riconoscimento e la “costituzionalizzazione” di
questo diritto erano strettamente connessi all’evoluzione dell’iden-
tità dell’Unione. E, forse, questo è stato un motivo in più per la 
creazione e il consolidamento di questo diritto super fondamentale.
Il diritto alla protezione dei dati personali e della privacy digitale 
è stato finalmente codificato nella Carta dei diritti fondamentali
dell’Unione  europea  e  sancito  dall’articolo  16  del  Trattato  sul 
funzionamento dell’Unione europea che fornisce la base giuridica
per l’adozione di un nuovo quadro normativo per il trattamento
dei  dati  personali,  rientrante  nell’ambito  di  applicazione  del 
diritto europeo. Nello specifico, la Carta dei diritti fondamentali 
dedica due disposizioni in materia, rispettivamente l’articolo 7, 
relativo  al  rispetto  della  vita  privata  e  familiare,  e  l’articolo  8, 
relativo alla protezione dei dati personali.

Risulta quindi chiaro che il diritto alla privacy progettato da
Warren e Brandeis come il diritto di essere lasciati soli ha vissuto
un processo di migrazione dagli Stati Uniti all’Europa, acquisendo
progressivamente una dimensione che non protegge esclusivamente
l’aspettativa di privacy dell’individuo ma che vede nella definizione
di un sistema di principi e regole per la protezione dei dati un ul-
teriore momento essenziale per tutelare la personalità. Tuttavia, que-
sta  migrazione  è  stata  preceduta  da  una  giurisprudenza  molto
pervasiva della Corte di giustizia europea orientata ad applicare la
visione europea del diritto alla privacy digitale.12

Guardando al punto di vista della Corte europea dei diritti 
dell’uomo, è possibile osservare il passaggio dalla privacy all’auto-
nomia  personale.  Senza  passare  in  rassegna  la  giurisprudenza 
della Corte europea dei diritti dell’uomo, è possibile fare almeno 

12 O. Pollicino, M. Bassini, Bridge is Down, Data Truck Can’t Get Through . A Critical
View of the Schrems Judgment in The Context of European Constitutionalism, in
The Global Community - Yearbook of International Law and Jurisprudence, 2017.

I n t e r v e n t o   d i   O r e s t e   P o l l i c i n o

77

un riferimento alla sentenza Tysiac v. Poland del 2007.13 In questo
caso, la Corte sottolinea che il concetto di vita privata va interpre-
tato in maniera estensiva e abbraccia anche aspetti dell’identità 
sociale, fisica e mentale del soggetto, e quindi l’autonomia personale
e  l’integrità  psicologica.  In  questo  caso  emerge  un  parametro 
costituzionale  di  riferimento  di  natura  evolutiva. Tuttavia,  tale 
approccio trova il suo limite nella concettualizzazione giurispruden-
ziale del fenomeno ossia quel case-by-case che dal punto di vista 
della certezza del diritto necessita di essere compensato attraverso 
il processo politico, innanzitutto, e rinforzato dai decisori tecnici.
Di conseguenza la domanda che qui emerge è se l’articolo 8 
della  Convenzione  europea  è  un  approdo  sicuro,  o  se  bisogna 
riflettere su nuovi diritti, andando quindi verso una codificazione
neurotecnologica,  che  poi  segue  la  stessa  impostazione  della 
codificazione della Dichiarazione dei diritti e dei doveri su Internet.
Questa esigenza di nuova codificazione sembra far emergere la paura
di confrontarsi invece con un dato giuridico che in Europa è già
sufficiente per poter cercare di far fronte alle esigenze di tutela. 

4. Una visione di carattere costituzionale
Sembra quindi opportuno concentrarsi sulla necessità di una
rigenerazione semantica delle carte esistenti, a cominciare dalla
Convenzione europea che di fatto trova applicazione proprio in
questo contesto, per non menzionare poi l’esempio della Corte 
di giustizia che applica gli articoli 7 e 8 della Carta a nuovi diritti,
come per esempio il diritto a essere dimenticato. Quel “right to be
forgotten”, in realtà, non è che una declinazione dei diritti esistenti. 
Si può quindi fare affidamento su alcune lezioni per quanto 
riguarda la dimensione digitale che possono essere fatte proprio 
in questo contesto. 

A questo punto, occorre sottolineare alcuni punti. 
Il primo attiene al livello dell’intervento. Da un punto di

13 Tysi c v. Poland, Application no. 5410/03, 2007.

78

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

vista  costituzionale  non  sembra  necessario  intervenire  con 
nuove carte, ma intercettare assiologicamente quell’anticipazione
della tutela già menzionata, che è già insita nei parametri costitu-
zionali  esistenti.  Dal  punto  di  vista  invece  della  legislazione 
secondaria, evitando l’inflazione di carte e di corti, bisognerebbe
intervenire  su  una  regolamentazione  più  specifica,  ad  esempio, 
l’articolo 22 del GDPR per quanto riguarda la decisione algorit-
mica. Ebbene, quel tipo di normativa svolge un ruolo importante
perché  fornisce  un  tipo  di  base  giuridica  specifica  in  grado  di 
affrontare le sfide del presente ma anche quelle che si porranno 
per via dello sviluppo tecnologico. 

Il secondo punto fondamentale è legato ad un altro possibile
terreno comune. La domanda è se, oltre l’autonomia individuale,
ci sia un secondo possibile ponte di interconnessione tra le due 
visioni in contrasto, prima evocate, tra i due “Primi Emendamenti”
del costituzionalismo transatlantico, la libertà di espressione da una
parte e la privacy (e dignità) dall’altra. La risposta sembra essere 
positiva Si tratta del terreno procedimentale che viene chiamato
digital  due  process, e  che  qui  potrebbe  essere  interpretato  come 
neuro  due  process, ossia  quella  serie  di  regole  che  fanno  sì  che 
l’interazione tra utente e algoritmo sia rafforzata. Questa tutela è
già  esistente  quando  si  guarda  all’articolo  6  della  Convenzione 
europea non verticalmente, ma orizzontalmente, visto lo sposta-
mento nella geometria del potere, non più potere esclusivamente
verticale,  ma  un  potere  che  ha  dimensione  orizzontale.  Quindi 
l’applicazione orizzontale dei diritti rileva non soltanto per i diritti
sostanziali ma anche per i diritti di matrice procedimentale e il 
Digital Services Act è proprio un esempio di questo terreno comune
da un punto di vista procedimentale può accorciare le distanze delle
due sponde dell’Atlantico. 

Una terza riflessione attiene invece alla dimensione consu-
meristica di queste nuove tecnologie. Come precisava Rodotà: “
L’indisponibilità dei diritti in questione - qui parliamo di diritti in-
violabili  -  deve  essere  riferita  allo  scambio  mercantile,  non  alle 

I n t e r v e n t o   d i   O r e s t e   P o l l i c i n o

79

attività  e  alle  scelte  che  attengono  al  legame  sociale”.  A  questo 
punto  occorre  domandarsi  qual  è  il discrimen ossia  qual  è  la 
sottile  linea  rossa  in  questo  contesto  tra  dimensione  sociale  e 
dimensione  consumeristica.  Sul  punto  un’altra  lezione  che  si 
può  provare  a  far  propria  rispetto  agli  errori  che  si  sono  fatti 
nella dimensione digitale è legata all’evitare qualsiasi tipo di tenta-
zione relativa alla monetizzazione del neurodato. La monetizzazione
del  dato  nella digital  privacy è  in  qualche  modo  stata  forzata 
dal fatto che quel tipo di illusione che c’è stata in Europa nel ’95,
cioè l’assoluto controllo dell’utente sui propri dati, si è reputata 
appunto  un’illusione,  una  promessa  non  mantenuta.  Se  non  si 
può avere un controllo assoluto, allora la contropartita è stata la
monetizzazione dei dati in una dimensione pragmatica che possa
in qualche modo far emergere una gratificazione. Questo tipo di
discorso costituisce un punto di non ritorno rispetto al quale biso-
gna mantenere salde invece le radici del costituzionalismo europeo
dei diritti indisponibili contro qualsiasi tentazione consumeristica. 
Il terzo punto fondamentale è legato al concetto di autode-
terminazione che si declina dal punto di vista del controllo dei dati. 
Di nuovo è molto importante evitare quello che potrebbe 
essere invece un tentativo di operare un compromesso tra l’idea 
di controllo e l’idea invece di consenso come ponte tra le scelte 
personali e l’ambiente circostante. Come sottolineato da Giorgio
Resta, “Attenzione alla delicatezza del consenso perché il ponte 
tra le scelte personali e l’ambiente circostanti è però infido, perché
il problema cruciale sta nel fatto che tale comunicazione non è 
mai unidirezionale, ma bidirezionale; nel momento in cui opera
come dispositivo di regolazione in uscita, il consenso contestual-
mente apre la sfera soggettiva a tutte le sollecitazioni provenienti
dal contesto e segnatamente a quelle del mercato”. Questo tipo di
doppia proiezione, in entrata e in uscita, è uno dei pericoli in questo
momento più rilevanti che vanno affrontati. 

A questo punto, occorre concentrarsi sul quarto punto e, 
in  particolare,  sull’inflazione  di  diritti,  il  conflitto  tra  diritti, 

80

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

il bilanciamento e le nuove carte. L’ultima lezione che può essere
colta dall’esperienza del digitale attiene al ruolo che le corti hanno
avuto nell’enforcement della digital privacy in Europa, da Google
Spain a Schrems. Quel tipo di attivismo ha fatto sì che si siano ri-
scritte alcune regole, che poi sono state codificate dal GDPR. Que-
sto tipo di meccanismo va assolutamente evitato in questo campo.
Predieri nel ’97, riferendosi alle Autorità indipendenti, metteva in
luce il passo indietro della politica e dell’avanzamento della tecnica.
Quando  parlava  di  fare  un  passo  indietro  della  politica, 
il riferimento era diretto anche alla politica giudiziaria. In altre 
parole, bisogna fare attenzione all’enforcement, o dal punto di vista
del processo politico o dal punto di vista del processo giudiziario, 
perché la dimensione giudiziaria europea ha prodotto non solo una
frammentazione ma anche un nocumento alla certezza del diritto
mettendo  da  parte  quello  che  la  stessa  Corte  di  giustizia  in 
Schrems fa emergere chiaramente, cioè l’importanza delle Autorità
garanti  come  decisori  decentrati  di  diritto  dell’Unione  europea 
che  riscoprano  la  questione  tecnica  e  la  facciano  emergere  in 
maniera che possa avere da una parte certezza del diritto e dall’altra
parte  un’interlocuzione  anche  alternativa  rispetto  al  singolo 
giudice del singolo foro. 

Occorre quindi prendere atto che la stagione del liberismo
tecnologico degli ultimi vent’anni è in qualche modo fallita e in-
sieme a questa la delega in bianco alle piattaforme della possibilità
di farsi arbitri dei conflitti tra diritti. Questa è chiaramente un’epoca
tramontata. Occorre quindi chiedersi quale sta per iniziare, ossia
quella del neurocapitalismo digitale. Sul punto, il potere pubblico
e dei decisori tecnici svolge un ruolo importante di guida dell’en-
forcement anche con il fine di riprendersi quel ruolo paracostituzio-
nale che non può essere più minimamente delegato alle piattaforme
e ai poteri digitali. 

È stato fatto questo errore nella stagione del digitale, sarebbe

da evitare in quella delle neuroscienze.

I n t e r v e n t o   d i   O r e s t e   P o l l i c i n o

81

Privacy e neurodiritti
La persona al tempo delle neuroscienze

CONCLUSIONI

Pietro Perlingieri

CONCLUSIONI

Note sul “potenziamento 
cognitivo”
Intervento di Pietro Perlingieri 

Esposizioni su un tema così complesso non si prestano a 
conclusioni: esse possono tutt’al più sollecitare indicazioni che, 
di là dalle poche certezze e dalle manifestate condivisioni, tentino 
di riassumere la problematicità che la neuroscienza prospetta al 
giurista contemporaneo.

Per  accedere  al  tema  occorre  sia  allontanare  il  convinci-
mento che i computer «fanno solo quello che sono programmati a
fare», avendo ormai anche la capacità di acquisire abilità senza una
specifica istruzione, sia accettare che essi, per velocità, precisione
e memoria, già allo stato - in una gamma piuttosto ampia di com-
piti intellettuali - sono superiori agli esseri umani, quali strumenti
di incredibile utilità. 

Il machine learning, nel procedere in modo esponenziale,
per la disponibilità dei dati che è in continua espansione, può con-
figurarsi come una «singolarità tecnologica», come una intelligenza
relativamente autonoma che, progettata per prolungare la propria
esistenza, potrebbe sviluppare strategie impreviste e imprevedibili;
possibili errori tecnici o di programmazione potrebbero farne per-
dere il controllo e produrre disastri sociali.

In una società caratterizzata sempre più da una commistione
di esperienze fisiche e virtuali, dove l’online e l’offline contribui-
scono a comporre la “complessiva realtà” e dove ormai le informa-
zioni anche sensibili circolano in rete - o perché volontariamente
cedute o perché acquisite surrettiziamente dalla negoziazione nei
social -, la stessa privacy, come tradizionalmente concepita, è irri-
mediabilmente compromessa: la piena trasparenza, da garantire 

I n t e r v e n t o   d i   P i e t r o   P e r l i n g i e r i

85

nell’acquisizione e nell’utilizzazione dei dati - pur da più parti 
invocata -, si configura di fatto come una imperdonabile ingenuità.
Il plurale e diffuso accesso ai dati consente di conoscere le
nostre vite, i nostri desideri, i nostri bisogni, le nostre debolezze. 
L’intermediazione algoritmica prevale nell’attribuire signi-
ficati e nel determinare inesorabilmente il “reale” con un approccio
dataista  fortemente  fideistico,  fondato  indistintamente  su  dati
tanto razionali quanto istintivi ed arbitrari, tutti elevati a indici di
conoscenze e di decisioni, a fonti indistinte e intrinseche dell’al-
goritmo. L’uomo si macchinizza e rischia di disumanizzarsi, di non
conoscere se stesso, di allontanarsi dalla fisicità della natura e di
affidarsi alla verità dell’algoritmo. L’IA domina l’immenso flusso
di dati i quali, senza aver bisogno di essere compresi, sono regi-
strati, caricati, condivisi; destinati semplicemente a piacere o non
piacere e a risultare dominanti se statisticamente prevalenti. 

La  probabilità  del  loro  accadere  assume  una  centralità 
esclusiva,  trasformando  la  società dell’informazione  in  società 
eretta sull’informazione. Dell’algoritmo è l’Autorità di indicare 
scientificamente le decisioni da assumere: il server - ironia del suo
nome - diventa il nostro padrone.

La verità scaturisce non dal singolo dato ma dal loro in-
sieme,  dalla  loro  connessione,  matematicamente  manipolata; 
il bene e il male, cosi raggiunti, rischiano di ridurre la realtà umana
e sociale a un sistema statistico-computazionale. Al fine di evitare
tale  rischio,  nella  consapevolezza  che  la  priorità  è  degli  esseri 
viventi, si invoca, da più parti, che gli algoritmi siano accessibili
alla  cognizione  umana,  controllabili  all’interno  dello  stesso 
complesso  e  articolato  loro  sistema  secondo  una  precostituita 
gerarchia selettiva ispirata almeno alla non compromissione del-
l’autonomia  degli  esseri  viventi,  sì  che  l’IA  possa  consentire 
«agli  uomini  di  rimanere  uguali  fra  loro»,  favorendone  uno 
sviluppo differenziato e assecondandone le attitudini materiali e
personali.

È pur vero che l’IA - tecnologia ispirata a comportamenti

86

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

biologici, allo studio della mente umana e ai suoi modelli elettro-
nici e meccanici -, pur non sapendo quali potenzialità possa rag-
giungere,  comporta,  come  qualsiasi  tecnologia,  benefici  e
potenziali problemi. Come narra la storia dell’uomo sapiens, l’evo-
luzione  culturale  e  tecnologica  incide  sulla  stessa  evoluzione 
genetica,  realizzando  una  vera  e  propria  evoluzione  cognitiva, 
sì che l’uomo, con un proprio tipo di linguaggio e con una condi-
zione di conoscenze e di strumenti tecnici, ha proceduto a civiliz-
zarsi,  a  cambiare  lo  stile  di  vita,  ma  rimanendo  pur  sempre  al
centro dello sviluppo civile. Vi è da chiedersi, tuttavia, se potrà
continuare ad essere così, là dove la rivoluzione digitale, nel tra-
sformare  tutto  in  dati  numerici,  nel  correlare  quantità  sempre 
maggiori di dati, non si preoccupasse di approfondire eticamente
le ragioni delle loro correlazioni.

Il fenomeno del «potenziamento cognitivo» è particolar-
mente significativo, destinato com’è a superare la tradizionale no-
zione  di  istruzione  e  di  formazione  professionale  sino  a
compromettere non soltanto il principio della eguaglianza tra gli
uomini - con il conseguente ripensamento del principio merito-
cratico e del suo rapporto con la democrazia - ma anche e soprat-
tutto la stessa identità umana, stravolgendone persino la struttura
genetica. 

II potenziamento cognitivo può essere, infatti, tanto mi-
nimo e prevalentemente integrativo quale supporto alla mente
umana, quanto assumere un ruolo sostitutivo. ln tale ipotesi la di-
versità qualitativa può incidere sulla determinazione soggettiva del
pensiero e della volontà, con un completo controllo sul funziona-
mento della mente umana e con conseguenze sui temi classici della
negoziazione e soprattutto dell’imputabilità e della responsabilità.
Di fronte a questi problemi la tutela della privacy, che pur
in sé configura un valore apprezzato dagli ordinamenti giuridici
più evoluti, non sembra possa rappresentare un presupposto essen-
ziale e rassicurante dei diritti umani. Per evitare esiti aberranti, che
si ripercuotono negativamente sul processo cognitivo e decisionale,

I n t e r v e n t o   d i   P i e t r o   P e r l i n g i e r i

87

non basta che i dati siano esatti; gli esiti aberranti possono comun-
que prodursi con il trattamento di dati raccolti con determinate 
finalità ma manipolati a fini diversi. Manipolazioni che, nel trava-
licare interessi di natura privatistica e individuale, spesso incidono
sullo stesso pacifico ordine sociale.

Le alterazioni e i condizionamenti del processo cognitivo,
non tutti imputabili a innesti neuronali, sono di diverso tipo e
hanno rilevanze diverse. Tale varietà non può sfuggire ad una ade-
guata tutela giuridica, pur avendo comunque neuroscienza e neu-
romarketing profili comuni. 

Si impone allora un limite ragionevole al potenziamento co-

gnitivo, stabilendo un suo estremo confine.

La risposta non può che essere istituzionale, di governo della
conoscenza e dell’informazione, con un approccio che rappresenti,
nonostante la problematicità insita nel tema, una realistica conver-
genza, nella consapevolezza che le IA, «prima di essere un problema
tecnologico, rappresentano un problema epistemologico e filoso-
fico» e che soltanto una innovazione garante dell’uomo e della na-
tura  può  riservare  un 
il
fondamentalismo macchinico.

futuro  armonioso  ed  evitare 

Necessario, a tal fine, è un cambiamento culturale a tutti i
livelli e più diffuso possibile che, nell’innescare un processo edu-
cativo e formativo, ad un tempo umanistico e tecnologico, asse-
condi una crescita sostenibile che contrasti la disumanizzazione del
mondo e l’inciviltà.

II contributo dell’IA nella conoscenza della complessità, 
particolarmente del lavoro e della produzione economica e scien-
tifica, va costantemente monitorato nella convinzione che l’intero
universo non è riducibile a un flusso di dati. È tempo, quindi, 
di pensare filosoficamente il software, al fine di comprendere che
tipo di conoscenza l’algoritmo sta generando rispetto al dualismo
dati-concetti. La relazione IA-persona umana - nonché più ampia-
mente  la  relazione  IA-esseri  viventi  (in  quanto  esseri  che 
respirano) - ha bisogno di essere regolata e soprattutto di essere go-

88

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

vernata in forme istituzionali che sappiano riservare, come la nostra
Costituzione declina, alle persone, diritti inviolabili e doveri inde-
rogabili e alle macchine, sia pure intelligenti, un’adeguata tutela in
quanto «cose», anche là dove l’ordinamento le considerasse centri
di imputazione di poteri e di responsabilità, non essendoci una
correlazione dogmatica tra responsabilità e soggettività giuridica.
Le IA sono un laboratorio aperto e denso di problematicità.
Nella neuroscienza permangono inquietanti interrogativi
persino su cosa debba intendersi per intelligenza e se sussista una
sua specificità. La mera velocità di calcolo è indice di una intelli-
genza superiore? V’è differenza qualitativa tra intelligenza artificiale
e umana? Può l’IA esaurirsi nella mera capacità computazionale e 
ridursi ad un insieme di informazioni? Come valutare il livello di
una intelligenza e definirla più intelligente di un’altra? E ancora, 
c’è da chiedersi se avremo mai tecnologie che rendano impossibile
distinguere i propri pensieri da quelli delle persone alle quali si sarà
connessi; se l’esperienza artificiale sarà più vasta e significativa 
di quella umana e se l’una sarà separabile dall’altra; se sarà, infine, 
possibile trasferire la propria mente in una macchina sì da rendere
irrilevante la distinzione tra IA e intelligenza umana.

Interrogativi che si traducono in problemi propriamente co-
gnitivi e che si prospettano in forme inquietanti: i computer pos-
sono davvero pensare, provare emozioni o si limitano a simulare il
pensiero; possono avere una mente ed essere davvero intelligenti o
possono semplicemente essere capaci di agire come se fossero in-
telligenti;  possono  avere  coscienza  di  sé,  la  consapevolezza  di 
esistere?

Sono state pronunciate, in questa sede, parole profonde e
importanti  da  parte  del  filosofo  su  cosa  siano  la  mente,  la  co-
scienza, l’identità che non si esauriscono nella ragione. 

Ma v’è differenza, se differenza esiste, tra le idee che passano
per la mente e i byte che sfrecciano in un computer? Le macchine
arriveranno  a  comportarsi  coscientemente,  a  sentire  dolore 
o benessere soltanto perché programmate dall’uomo con tale pre-

I n t e r v e n t o   d i   P i e t r o   P e r l i n g i e r i

89

visione? Possono esse effettuare scelte significative che prescindano
dall’esterno, dal contesto? E soprattutto è divenuta reale la pro-
spettiva di integrare il cervello umano, quale massa di neuroni in-
terconnessi che si scambiano segnali elettronici o chimici con il
mondo dell’elettronica sì da comunicare e controllare macchine e
robot con la sola mente?

Problemi inquietanti si prospettano così al giurista per la
prima volta nella storia dell’umanità e che concernono la stessa
identità umana. Se il potenziamento cognitivo giungerà a creare
esseri umani migliori di altri, il diritto al pieno e libero sviluppo
della persona potrà continuare ad essere garantito? Non soltanto.
In un contesto di scarsità di risorse, è conforme ai principi costi-
tuzionali investire sul potenziamento cognitivo di pochi anziché
curare le malattie di molti e quindi prediligere la qualità della 
vita di tutti? E parimenti lo è affidare alla macchina la decisione
della  vita  e  della  morte  degli  esseri  viventi,  la  selezione  di  chi 
è degno di nascere e chi no, il ripristino o no della pena di morte?
Senza una adeguata politica del diritto, serio è il pericolo di
un  predominio  dell’IA  e  della  conseguente  disumanizzazione 
della societas. È indubbio che le scelte spetteranno alla politica, ma
delicato si prospetta il ruolo del giurista, chiamato a collaborare
alla interdisciplinarietà necessaria per la stessa elaborazione algo-
ritmica.

Di fronte a questi scenari, così impegnativi, le risposte del
diritto si devono concentrare sulla sottrazione di monopoli privati
e consumeristici della detenzione e dell’utilizzazione dei dati con
risposte di valenza sovranazionale e sull’uso di una tecnica legislativa
che si avvalga di principi - più che di regole dettagliate e puntuali
- che consentano interpretazioni adeguate ai casi concreti e ai con-
testi storici, con una vera e propria rivoluzione nella teoria delle
fonti giuridicamente rilevanti. Un ruolo decisivo spetta alle Autho-
rity nazionali  e  ancor  più  a  quelle  sovranazionali.  Tuttavia  la 
stessa  concentrazione  in  mano  pubblica,  senza  un  congruo 
controllo democratico, è foriera di inconvenienti assai gravi che

90

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

mettono in forse l’apprezzamento delle modalità di raccolta dei
dati, gli scopi della loro utilizzazione.

La  crisi  affonda  le  sue  radici  nel  liberismo  economico 
e investe non soltanto il tema specifico della neuroscienza, ma la
complessiva problematica dell’intelligenza artificiale e quindi tutte
le possibili utilizzazioni che l’intelligenza artificiale fa dei dati. 

L’informazione rappresenta la ricchezza del secolo: la sua
utilizzazione - e quindi tutte le sue possibili applicazioni nei settori
più diversi -, non può essere gestita liberamente da poteri privati;
esige necessariamente un controllo che ne garantisca il corretto
svolgimento.

È stato messo ben in evidenza che l’uso della neuroscienza 
e delle tecnologie legate alla neuroscienza, come la storia insegna,
può essere tanto positivo quanto pericoloso e distorto; nel caso 
delle  intelligenze  artificiali  può  porsi  addirittura  in  contrasto 
con  l’uomo  e  con  la  realtà  fisica.  Questa  preoccupazione  è 
fortissima,  ma  non  deve  comportare  rinunzia  all’elaborazione 
della neuroscienza, che ha già molteplici e significative applicazioni
positive specialmente in materia sanitaria e terapeutica.

Il problema, tuttavia, non si può limitare al diritto alla sa-
lute, ma investe la persona nella sua unitarietà psico-fisica, con la
messa in evidenza della frammentarietà e della fragilità di una ri-
costruzione con sempre nuovi diritti della personalità. A questa
frantumazione sono stato sempre fortemente contrario. Personali-
smo significa tutela della persona nella sua unitarietà assecondan-
done la promozione e la realizzazione.

Come  è  possibile  oggi,  di  fronte  a  situazioni  complesse 
come quelle prodotte dalla tecnologia e dalle intelligenze artificiali,
realizzare  questa  tutela?  Il  problema  è  innanzitutto  culturale. 
Si contrappongono la cultura nordamericana e quella europea. 

Le sentenze Schrems, prima e seconda, lo mettono ben in
evidenza.  In  quella  nordamericana,  prevalgono  il  liberismo 
economico, la libertà assoluta, la mancanza di controllo da parte
dello Stato sulle tecnologie e sulla finanza; in Europa, il costitu-

I n t e r v e n t o   d i   P i e t r o   P e r l i n g i e r i

91

zionalismo - scritto nelle carte ma presente anche nelle sentenze
delle  Corti  costituzionali  e  della  Corte  Europea  dei  Diritti 
dell’Uomo  -  si  ispira  invece  ad  una  filosofia  della  vita, 
ad un’assiologia dove al centro del sistema non è il mercato - come
pure in un primo momento il Trattato di Roma del 1957 sembrava
indicasse - ma la persona umana, i suoi diritti e i suoi doveri.

Questo comporta che il tema esige di essere affrontato in 
maniera interdisciplinare, con un approccio fondato sulla cono-
scenza  non  soltanto  della  tecnologia,  e  quindi  della  scienza, 
ma anche del diritto, dell’etica e della filosofia. Il tema, tuttavia -
per  la  natura  stessa  transazionale  del  dato,  dell’informazione, 
dell’algoritmo e dell’intelligenza artificiale -, non potrà mai essere
risolto con soluzioni legislative statali, anche se proposte da un in-
tero continente.

Nella  suindicata  contrapposizione  nordamericana  ed 
europea si aggiunge la specificità della realtà cinese e di quella 
asiatica. Emblematica è l’esperienza di un sistema di credito sociale
sviluppatosi  in  Cina,  il  quale,  in  un  gigantesco  Grande 
Fratello - a prescindere dall’esattezza o dall’inesattezza della veri-
dicità dei dati e dalla loro natura, sensibile o no - finisce con il 
legittimare un ingiustificato diseguale trattamento, sì da indurre
l’uomo-cittadino  a  percepire  la  necessità  e  la  convenienza 
dell’obbedienza,  dispensando  benefici  e  privilegi  sulla  base  di 
discutibili  criteri  valutativi  che  per  di  più  non  tengono  conto 
del contesto.

Allora,  non  basta  la  Convenzione  Europea  dei  Diritti 
dell’Uomo  -  che  pure  è  stata  sottoscritta  da  numerose  nazioni; 
occorre  una  Convenzione 
internazionale  per  principi  che 
coinvolga quante più nazioni possibili, escludendo dall’elaborazione
dei dati - che sono la benzina delle intelligenze artificiali - chi non
si adegua. 

Diversamente le soluzioni, che pur si indicano a livello giu-
risprudenziale o legislativo nazionale, non raggiungeranno mai un
risultato apprezzabile.

92

P r i v a c y   e   n e u r o d i r i t t i .   L a   p e r s o n a   a l   t e m p o   d e l l e   n e u r o s c i e n z e

II tema è sempre lo stesso: deve prevalere il mercato, la con-
cezione statalistica autoritaria o lo sviluppo delle persone umane e
quindi la loro tutela? Dal punto di vista del personalismo costitu-
zionale l’impiego dei dati non si può giustificare in una logica 
mercantile,  in  una  loro  compravendita,  sia  pure  mascherata 
da una surrettizia loro utilizzazione avente il ruolo di corrispettivo
di un servizio di là dall’apparente gratuità. La logica è: io presto 
il mio servizio soltanto perché mi concedi la libera utilizzazione 
dei dati.

Questo convegno, voluto dall’Authority, ha contribuito a
mettere  in  evidenza  una  problematica  di  struggente  attualità, 
dove la tutela della dignità della persona predomina. Il giurista 
ha il compito di contribuire a realizzarla - secondo le linee guida
del  sistema  ordinamentale  italiano  ed  europeo  -  proponendo 
soluzioni adeguate.

Gli interventi - sia quello del filosofo, sia quello del tecnico
e sia quello del costituzionalista, unitamente all’introduzione del
Presidente dell’Authority - hanno offerto un quadro realistico; forse
sarebbe stato utile avere come interlocutori anche un ingegnere,
un informatico. È necessario che l’ingegnere, l’informatico, il giu-
rista, il filosofo lavorino insieme allo scienziato per raggiungere so-
luzioni apprezzabili.

Vorrei, infine, ringraziare il Presidente Pasquale Stanzione
e l’Authority che hanno avuto la cortesia di invitarmi e di affidarmi
le conclusioni.

I n t e r v e n t o   d i   P i e t r o   P e r l i n g i e r i

93

CHIUSURA DEI LAVORI

Pasquale Stanzione

Grazie  a  tutti  i  relatori,  agli  intervenuti  e  a  coloro  che 

ci ascoltano.

Come avete avuto modo di sentire in queste ore di attenta 
riflessione, ci troviamo in presenza di un fenomeno nuovissimo, 
preoccupante, che ha bisogno della nostra attenzione, della regola-
mentazione,  del 
limite  che  è  stato  varie  volte  descritto. 
Il tutto in una prospettiva - l’abbiamo sentito dai vari relatori - di
una tutela integrale della persona umana nella sua unitarietà. 

Ora,  nel  rinnovato  ringraziamento,  l'Autorità  ha  creduto 
opportuno fissare in una targa il ricordo della Giornata e di questa
vorrei fare omaggio ai relatori. 

C h i u s u r a   d e i   l a v o r i .   P a s q u a l e   S t a n z i o n e

95

