PAR Process/2020/76 1
NATIONAL COMMISSION
DATA PROTECTION
OPINION/2020/116
I - Order
The Committee on Constitutional Affairs, Rights, Freedoms and Guarantees of the Assembly of the Republic asked the National Data Protection Commission (CNPD) to comment on Bill No. 473/XIV/1.a, initiated by the parliamentary group of the Socialist Party, which approves the Charter of Fundamental Rights in the Digital Age.
The request made and the present opinion fall within the attributions and powers of the CNPD as the national authority to control the processing of personal data, in accordance with the provisions of subparagraph c) of paragraph 1 of article 57 and paragraph 4 of article 36 of Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 (General Data Protection Regulation - RGPD), in conjunction with the provisions of article 3, n. 2 of article 4 and subparagraph a) of paragraph 1 of article 6, all of Law no. internal legal order.
The assessment of the CNPD is limited to the assessment of the rules that provide for or regulate the processing of personal data.
II - Appreciation
The bill in question aims to strengthen people's rights in the digital context, as explained in the explanatory memorandum, "without being limited to a mere compilation of norms that in the Portuguese legal system already enshrine digital rights, provided for in the Constitution itself or contained in diplomas that transposed European directives.” Thus, with the Project, it is sought to «enunciate a diversified and comprehensive set of rights, freedoms and guarantees that innovates, clarifies and goes ha also as the bases of a program of binding action of the organs of the
With special relevance to the guarantee of rights in the context of processing of personal data, the CNPD welcomes the concern revealed throughout the Project with the consequences for Internet users of technological Artificial Intelligence solutions, especially when they involve machine learning (machine learning). ), and automated decisions about each individual based on profiles and other information collected about them.
AV. D. CARLOS I. 134 - Io I 1200-651 LISBON [ WWW.CNPD.PT I TEU+351 213 928 400 ] FAX:+351 213 976 832
Process PAR/2020/76 1v.
B
Despite the invocation of an extensive set of legal instruments, most of them of an international or European nature, and of other initiatives of debate on the matter, in the draft of the Project it seems to forget that many of the rights, here enshrined as digital, are already recognized, and with a well-defined scope, in binding legal instruments for the Portuguese State. And, therefore, consecrated and delimited in such terms that they cannot now, at the national legislative level, be changed, even if in an expansive sense of the subjective positions of the data subjects.
It is from this point that the present analysis begins, without forgetting to highlight that many of the norms of this Project employ concepts whose definition is contained in legal diplomas of Union Law, therefore having a specific meaning, but which are not, not even by reference , explained in the text of the Project, which makes it difficult to interpret these rules, including their scope of application, impairing the predictability and legal certainty that rules enshrining rights, which correspond to the obligations of third parties, cannot fail to ensure.
It is also worth noting that a diploma with the nature of a Charter of Fundamental Rights in the Digital Era, as the Project is called, must have a perennial nature, therefore, that it is not valid only for situations of normality of legal relations. However, the exclusion of regulation of digital rights in various types of legal relationships, as well as "in several areas whose success has been one of the faces of the fight against the COVOD-19 pandemic" (as read in the explanatory memorandum), seems to undermine the legal force of this Charter of Fundamental Rights.
1. Nonconformity of the Project's rules with European Union Law
Throughout the Project, rights are already enshrined, not only in the Constitution of the Portuguese Republic, in the Charter of Fundamental Rights of the European Union and in the European Convention on Human Rights, but also in conventions of a more specific scope1 * and also in diplomas of the European Union. directly applicable in the Portuguese legal system, as with the GDPR.
1 Of particular note is Convention 108 for the protection of individuals with regard to the automated processing of
personal data, from the Council of Europe, which was amended in 2018, by a protocol already signed by the Portuguese State, but not yet ratified, whose modernized version is commonly known as Convention 108+, available
in
Process PAR/2020/76 2
/
NATIONAL COMMISSION
DATA PROTECTION
If it is admitted that the Bill does not intend to exclude, in the context of cyberspace, the current rules that enshrine and protect rights, freedoms and guarantees (as provided for in paragraph 2 of article 1 of the Bill), the truth is that several of its provisions appear to repeat the rights already provided for and regulated in Union law, in particular in the RGPD, with the aggravating factor that they are often written in terms that modify the meaning and scope of these rights.
In this regard, it is recalled that the Court of Justice of the European Union (CJEU) has already censured the practice of replicating the content of Union regulations in national law, subjecting them to national law and, to that extent, also affecting the jurisdiction of the European court. The CJEU underlined that this creates a misunderstanding with regard to the legal nature of the provisions to be applied, reiterating that any implementation modalities that may impede the direct effect of Community regulations and, thus, jeopardize their uniform application, are contrary to the Treaty. in the community space2.
And as for national rules that distort the meaning of Union law rules, the CJEU specified that the Member States have a duty not to obstruct the direct applicability inherent to the regulations, and strict compliance with this obligation is an indispensable condition for an application uniform and simultaneous implementation of the Regulations throughout the Community.
Now, the Bill under analysis, in an effort to bring together the rights recognized in the Portuguese legal system in the digital context, integrates a set of norms that are presented in disagreement with European Union Law, in terms that put in crisis the primacy of the European Union law and the hierarchy of norms recognized by paragraph 4 of the
https://rm.coe.int/CoERMPublicCommonSearchServices/DisplayDCTMContent?documentld=09000016808ac91
8
2Cf. Judgment Commission / v. Italy (proc. 39/72), point 17, in http://curia.europa.eu/juris/showPdf.isf;|sessionid=9ea7d2dc30ddbf94149c102f4a878610d7c0bd468c6f.e34Kaxi Lc3qMb40Rch0SaxyNbxz0&lst&doc=3x54&ldoc&lst=PTx54 &occ=first&part=1& cid=601673 3
3 Cf, the Smallpox judgment (proc. 34/73), point 10, in
http://curia.europa.eu/juris/showPdf. jsf?text=&docid=88457&pagelndex=0&doclang::::EN&mode=req&dir::=&occ=f irst&part=1 &cid=378305
AV. D. CARLOS I, 134 - Io | 1200-651 LISBON I WWW.CNPD.PT I TEL:+351 213 928 400 j FAX:+351 213 976 832
Process PAR/2020/76 2v.
Article 8 of the Constitution of the Portuguese Republic. The CNPD understands that, in accordance with the aforementioned jurisprudence, such rules should be eliminated from the Bill.
However, given that, within the scope of the legislative procedure concerning the implementation of the GDPR, the national legislator opted, in Law no. contravened rules of the RGPD, the CNPD will make recommendations here aimed at alleviating non-compliance with European Union law.
Let's see.
1.1. First of all, in Article 4(1) of the Project, the prohibition of intentional interruption of access to the Internet, in whole or in part, or the limitation of the information that can be disseminated on it is highlighted. Although the guarantee of universal access to this means of communication and access to information is understood, the truth is that the cases set out in the second part of this rule leave out other situations provided for by law, where, in order to guarantee fundamental rights, other administrative authorities are given the power to determine the blocking of access to the Internet or the limitation of the information to be disclosed: this is precisely the case of the powers of the authority to control the processing of personal data provided for in paragraph 2 f) of article 58 of the GDPR, which obviously apply to the processing of personal data carried out on the Internet, or the powers of the competent authorities for the purposes of applying Regulation (EU) 2017/2394 on consumer protection4. In both cases, Union regulations provide for mutual assistance actions between the authorities of the Member States, the implementation of which depends on the set of minimum powers, defined in Union law, that these authorities enjoy, and which cannot be restricted. by domestic law.
In order to avoid a contradiction with the provisions of this rule of European Union law, directly applicable in the Portuguese legal system, the CNPD recommends that, in the final part
4 Regulation (EU) 2017/2394 of the European Parliament and of the Council of 12 December 2017 on cooperation between national authorities responsible for enforcing consumer protection legislation and repealing Regulation (EC) 2006/2004. This regulation has been applicable since January 17, 2020. See, in particular, article 9, which regulates the minimum powers of competent authorities, and other articles regarding mutual assistance.
Process PAR/2020/76 3
NATIONAL COMMISSION
OF DATA PROTECTION
of paragraph 1 of article 4 of the Project, the exception covers the cases provided for in this law and in other legal instruments, in addition to cases in which there is a judicial decision to that effect.
At the same time, paragraph 2 of article 7 of the Bill must also provide for, in addition to the cases provided for in the criminal procedural law and with the authorization of a judge, other cases provided for by law. This is because, while it is not clear whether the sense of security and secrecy of communications concerns only the communicated content or also other data relating to such communications, it is important to note that there are several legally prescribed offenses that presuppose the power to identify, at least, the sender or recipient of such communications, which obliges the administrative authorities competent for the investigation of such illicit acts to know traffic data, or even the content of some messages to verify if they contain unsolicited marketing content (spam).
In fact, this provision, without further clarification, seems to undermine the power recognized by the Regulatory Entity for the Media (ERC), in paragraph 2 of article 5 of the Project, to deal with complaints regarding false or misleading online content. .
1.2. Also within the scope of article 7 of the Project, which enshrines the right to digital privacy, its paragraph 4 recognizes a right to protection against illegally profiling. If this provision alone does not raise reservations, as it implicitly refers to the diploma where the limits to the definition of profiles are defined, which substantially corresponds to the RGPD, the exemplification that follows raises the greatest reservations. There it is explained, as a situation corresponding to a definition of profiles carried out illegally, when the decision-making regarding the natural person or the analysis of their preferences, behavior or attitudes is at stake.
First of all, there seems to be a misunderstanding here: decision-making concerning a natural person is not in itself illegal, nor is the definition of profiles to serve as a basis for decision-making concerning a natural person always contravenes the law or deserves, per se, censorship. The definition of profiles (profiling) can be legitimately carried out, with the aim of serving the decision-making process regarding natural persons and to analyze their preferences or conduct (cf., for example, the provisions of paragraph 2 f) Article 13(2)(g) of Article 14 and Article 21(1) and (2) of the GDPR).
Av. D. CARLOS I, 134 - Io j 1200-651 LISBON I WWW.CNPD.PT l TEU+351 213 928 400 | FAX: +351 213 976 832
Process PAR/2020/76 3v.
What will eventually be intended here is the automated definition of profiles - based on information collected in the digital environment, which the standard in question does not make explicit - so it would be useful to refer to the GDPR regarding this concept. But even with regard to this definition (profiiing), what is considered illegal, in certain circumstances, is the automated decision process about a natural person from profiles thus created. However, those circumstances are regulated in Article 22 of the GDPR, and the national legislature, regardless of the goodness of the scope it intends to give to the right enshrined therein, cannot establish a regime different from the regime of Union law, claiming that any and all use of profiling when it comes to making decisions regarding a natural person or analyzing their preferences, behavior or attitudes.
In short, on the one hand, the very concept of profiling used in paragraph 4 of article 7 of the Project only makes sense, within the scope of this Project, if a reference is made to the concept enshrined in paragraph 4) of the Article 4 of the GDPR; on the other hand, the exemplification contained in the final part of that provision contradicts the regime of law enshrined in article 22 of the RGPD, by extending the terms in which the use of these profiles will be considered illegal.
The CNPD therefore recommends the elimination of paragraph 4 of article 7 of the Project, or, if this is not the case, the revision of its wording in terms that do not contradict the provisions of article 22 of the GDPR.
1.3. Also in Article 8 of the Project rights are enshrined, now regarding the use of Artificial Intelligence and robots, which are nothing more than the repetition of rights already enshrined and regulated in the GDPR and, more seriously, in terms different from this one. statute.
First of all, note Article 8(2): it states that any individual decision taken on the basis of algorithmic processing must inform the person concerned. Leaving aside the fact that the subject of the sentence is here the decision and that a duty to do is imputed to it, which seems to presuppose a perspective of imputability of legal duties and responsibilities to robots and technology, once again it seems be faced with a misunderstanding as to the concepts used.
In fact, it seems that the Project is confused, as if it were the same reality, the algorithmic treatment of information about natural persons with the treatment of this information through Artificial Intelligence technologies. Now, the algorithms are,
Process PAR/2020/76 4
/
NATIONAL COMMISSION
OF DATA PROTECTION
known to be relevant to Artificial Intelligence, but not all information analysis using algorithms corresponds to this new reality. To that extent, the CNPD recommends reviewing this provision.
In any case, what seems to be meant here is, in fact, what Article 13(2)(f) and Article 14(2)(g) of the GDPR already provide, therefore, in accordance with the jurisprudence of the CJEU already mentioned, the CNPD underlines the unnecessary need for this rule and the convenience of its elimination so that it does not prejudice the meaning and legal force of the provisions of those provisions of the GDPR.
The same goes for Article 8(3), which complements the information to be provided to the holders of personal data. If the national legislature intended with this provision to extend the scope of the right to information provided for in Article 13(2)(f) and Article 14(2)(g) of the GDPR, in order to enshrine a right to an explanation of the data processing carried out using machine learning techniques, the CNPD, welcoming the guarantee intention, draws attention to the difficulties of densifying such a right different from that contained in the RGPD.
1.4. In relation to article 11 of the Project, the CNPD begins by recalling that there are rules of European Union law that regulate electronic identification, highlighting Regulation (EU) 910/2014 of the European Parliament and of the Council, of 23 July, 2014, so the provisions of Article 11(2) cannot fail to be read in the light of such rules.
But it emphasizes above all the provisions of paragraph 4 of article 11. While it is well understood what is intended to be safeguarded here, the ban on the use of a two-dimensional code does not seem to be necessary, nor does it appear to be a sufficient guarantee of the rights of natural persons.
In fact, it is not sufficiently guaranteed because it does not consider the possibility of representing higher-dimensional codes that affect the rights of individuals in the same way, thus running the risk of quickly becoming obsolete. The two-dimensional code, such as the QR Code, can be followed by the use of three-dimensional or n-dimensional codes, which allow the processing of personal data with equal or, possibly, greater intensity and impact. It is therefore important to find a formula that not only avoids the use of two-dimensional codes, but also higher-dimensional codes.
AV. D. CARLOS I, 134 - Io I 1200-651 LISBON I WWW.CNPD.pt I TEU+351 213 928 400 I FAX:+351 213 976 832
Process PAR/2020/76 4v.
Although it is not unknown that the larger the size, the more information the code contains, it cannot be said, without further ado, that there is a direct relationship between the size of the code and the risk to the rights of holders. In fact, the introduction of two-dimensional codes, in addition to the possibility of representing more information, made it possible, through the use of easily accessible applications (e.g., using a smartphone), to read the representation of the code. However, it is from the readability of the representation of the codes and, therefore, from the susceptibility of generalized knowledge of the information contained therein, that a greater affectation of the rights of individuals can arise. It is this result that must be avoided.
It is in this perspective, and considering that dimensional codes can be very useful tools, that the CNPD considers the ban on two-dimensional codes, without further ado, as too radical and unnecessary a measure.
Thus, the CNPD recommends that, instead of an absolute ban on the use of this type of code, and in line with the security measures provided for in Article 32 of the GDPR, it is allowed, as an alternative to the ban, that representation be subject to to a method of secure encryption of information prior to code generation.
The CNPD dares to suggest the following wording for paragraph 4 of article 11 of the Project: Any form of use of a two-dimensional code, or of a higher dimension, to process information on health status or any other aspect related to the rights of natural persons, sa/vo if secure encryption is applied to the information prior to the generation of the code.
1.5. Still regarding the rights enshrined in the GDPR and which are reaffirmed in the Project in the digital context, it is now important to analyze the right provided for in Article 12 of the Project.
Firstly, it is pointed out that the designation of the right as the right to be forgotten is not the most appropriate (even if it is popularized), since the meaning of the right corresponds to a claim “to be forgotten” (cf. 17 of the GDPR), which does not contradict the right to memory. The CNPD therefore recommends changing the heading of Article 12 of the Project to Right to be forgotten.
Secondly, the CNPD reiterates its concern for the legislative option of seeking to reproduce the rules of the RGPD in the specific digital context with the risk of distortion
Process PAR/2020/76 | 5
NATIONAL COMMISSION
DATA PROTECTION
the scope of the law defined in that diploma, and that the reference to the “terms of the law” may not be enough to exclude it. Take, for example, the mention in paragraph 1 of article 12 of the Project, among a short list of reasons justifying this right, to “for another relevant reason”. Such reference seems to leave a discretionary space for the applicator of the legal norm, when in fact the grounds for the ownership and exercise of this right are exhaustively listed in paragraph 1 of article 17 of the GDPR and in more extensive terms than those listed here.
Once again, it is recommended that, if the reference to this right is persisted in the context of this Draft diploma, one should refer to the grounds or reasons provided for in article 17 of the RGPD.
With regard to paragraph 2 of the same article 12 of the Project, it is recommended to revise the wording of the same, as it includes an interpretation that would go beyond the scope of the right to disassociate the result of a search from the name of the data subject in the search engine, as recognized by the CJEU5 and enshrined in the aforementioned article 17 of the GDPR.
In fact, the current wording allows the interpretation that the search in the digital source which contains information about the data subject cannot be carried out based on the name of the data subject, when the rationale of the rule seems to be to recognize that the right elimination of search engine results based on the name of the holder does not affect a search in the search engine based on a term other than the name of the holder. It is important here to distinguish, due to the completely different impact it has on the rights of the holders, a search carried out in a search engine of national or international scope, or a search limited only to a website and, therefore, only aggregating the information contained in that website. website and not the entire Internet.
The CNPD therefore recommends a clarification of the wording of this paragraph 2 of article 12 of the Project.
Thirdly, the imposition, in Article 12(3), of the exercise of the right to erase personal data provided to social networks or information society services
5 Cf. Judgment Google Spain SL Google Inc v. Agencia Espano/a de Protección de Datos, of May 13, 2014, in case C-131/12.
AV. D. CARLOS I, 134-Io I 1200-651 LIS BOA I WWW.CNPD.PT I TEl:+351 213 928 400 I Fax-,+351 213 976 832
Process PAR/2020/76 5v.
by means of a simple digital form and its guarantee within a reasonable period of time, goes further than stipulates - in terms that are binding on the Member States - Article 12 of the GDPR. It imposes on the controller the obligation to facilitate the exercise of rights, and a maximum period of one month from the receipt of the request is established, which may be extended (cf. Article 12(2) and (3) of the GDPR ).
In addition, the grounds for deleting personal data are being limited to cases of obsolete or inaccurate data, which, it is reiterated, grossly contradicts the provisions of Article 17(1) of the GDPR.
Furthermore, the CNPD draws attention to the delimitation of the context in which this right is intended to be regulated, since the concept of information society services has a well-defined meaning in Directive (EU) 2015/1535, of the European Parliament and the Council, and no similar services are achieved. Reasons of predictability of legal norms justify, therefore, the rigor in the concepts used and the clarification of the same.
To that extent, the rule must be eliminated or revised, as it imposes the means of fulfilling the obligation when the GDPR has not done so and because it refers to a reasonable period that has already been implemented by the European legislator, in disregard of article 12. of the GDPR, and also for restricting the scope of the right to erasure of personal data provided for in article 17 of the GDPR.
Finally, the scope of paragraph 4 of article 12 of the Project is not understood. The provision that data concerning minors will be deleted without the limitation provided for in the previous number can refer to the requirement of a digital form for the exercise of the right and its guarantee within a reasonable period, as well as the grounds for exercising the right. of that right, which in paragraph 3 are limited to the inaccuracy or obsolete nature of the data. It is therefore important to clarify the meaning of the rule.
In any case, whatever its meaning, this provision is unnecessary, as the right to erase the personal data of minors collected in the context of offering information services referred to in Article 8(1) of the GDPR, is enshrined in subparagraph f) of paragraph 1 of article 17 of the same diploma.
Process PAR/2020/76 6
/
NATIONAL COMMISSION
DATA PROTECTION
1.6. Note also paragraph 1 of article 13 of the Project, when it refers to the right of users of digital platforms to obtain a copy of the data that concern them in an interoperable way and the erasure of such data on the platform.
Firstly, for reasons of normative predictability, it would be appropriate to define, for the purposes of this diploma, the concept of digital platforms. In any case, the right that seems to be at issue here is the right to data portability, enshrined in article 20 of the GDPR, which, here, because it refers to the change in contractual conditions, falls under point a) of Article 20(1) of the GDPR, but restricted to the processing of personal data carried out on the basis of a contract.
However, the right to portability does not necessarily imply the deletion of personal data by the controller. The right to erasure exists in the cases provided for in paragraph 1 of article 17 of the RGPD and, for what is relevant here, it can be affirmed when the basis of lawfulness of the treatment ceases or the data are no longer necessary ( for having terminated the contractual relationship). There are simply circumstances, in accordance with paragraph 3 of article 17, that may justify the retention of data (e.g. to defend rights in legal proceedings, to comply with legal obligations in tax matters and to combat money laundering of capital).
While it is true that the national legislator may create legal obligations to erase data, under the terms of subparagraph ejdo no. hence the reweighting of this provision.
1.7. With regard to the right to protection against abusive geolocation, enshrined in Article 15 of the Project, the CNPD begins by insisting, once again, on the need to clarify the concepts used, which actually correspond to defined concepts in diplomas of Union law.
This is the case with several terms used in this article (for example, the concept of call), which refer to the Electronic Communications Privacy Law (Law no. 46/2012, of 29 August), which transposed the e-Privacy Directive (Directive 2002/58/EC, of the European Parliament and of the Council, of 12 July, on the processing of personal data and the protection of privacy in the sector of
AV. D. CARLOS l, 134-1° j 1200-651 LISBON I WWW.CNPD.pt I TEU+351 213 928 400 j FAX:+351 213 976 832
Process PAR/2020/76 6v.
electronic communications, as amended by Directive 2009/136/EC, of the European Parliament and of the Council, of 25 November).
Since the CNPD does not have reservations about the general provisions of this article, it believes, however, that the wording of paragraph 2 needs clarification and revision.
It follows from this precept that personal georeferencing data, within the scope of mobile or fixed public networks, can only be used by the authorities[s] iely competent in the fields of civil protection, public health and criminal investigation.
It so happens that the regime for the processing of this data is regulated in the Electronic Communications Privacy Law, which transposed the e~Privacy Directive, where the processing of geolocation data by electronic communications operators is allowed in certain circumstances (cf. article 7 of the Electronic Communications Privacy Act). However, as it is worded, Article 15(2) of the Project seems to prohibit the processing of such data in the cases provided for in Article 7 of that national law, which would count the e-Privacy Directive.
On the other hand, authorization for the processing of these data by the legally competent authorities in the fields of civil protection, public health and criminal investigation broadens the universe of entities legitimized by Law No. 41/2004 (Article 7(2)) and by the e-Privacy Directive itself (Article 10(b) and Recital 36) to process geolocation data: in these diplomas only authorities competent by law to receive and respond to emergency calls are authorized to process such data and not all authorities responsible for civil protection and public health.
Although the e-Privacy Directive recognizes, in its article 15, the Member States have the power to, by law, restrict the rights to the inviolability and confidentiality of electronic communications, traffic data and geolocation data, that restriction must prove to be adequate, necessary and not excessive in relation to the purposes pursued, since it involves the restriction of the fundamental rights to respect for private life and the inviolability of communications, enshrined in Article 7 of the Charter of Fundamental Rights , and in articles 26 and 34 of the Portuguese Constitution. Especially in the open, non-detailed terms, in which such access is foreseen. Also taking into account that this rule derogates from paragraph b) of article 10 of the Directive and partially amends the provisions of paragraph 2 of article 7 of Law no. reasons does not expressly mention it, nor is the suitability and necessity of extending the
Process PAR/2020/76 7
NATIONAL COMMISSION
DATA PROTECTION
universe of administrative entities with the power to know location data in the context of electronic communications. The CNPD recommends, therefore, that the provisions of Article 15(2) be considered, stressing that it reflects the partial derogation of rules provided for in Law No. 41/2004 and in the e-Privacy Directive, and that, also because of the open terms in which access is provided, it seems to violate the principle of proportionality (cf. Article 18(2) of the CRP and Article 52(1) of the Charter).
2. Analysis of other legal provisions
Still from the perspective of the compatibility of the Project rules with the personal data protection and personal data security regime, the CNPD draws attention to the following aspects of the regime.
2.1. First, a short observation regarding the regime enshrined in Article 3 and Article 5 of the Bill.
The CNPD recognizes the sensitivity of the process of harmonizing fundamental rights to freedom of expression with other fundamental rights or constitutionally relevant interests and, specifically, the difficulty of this conciliation with the objective of public protection against certain opinionated content and disinformation.
In any case, taking into account that the exercise of the right to freedom of expression and opinion may involve the processing of personal data {e.g., the use of this data, especially in the context of profiling processes based on the personal information collected in social networks), recalls that, in another context (which is the political campaign), the European Union has provided for a sanctioning regime only when the disinformation process is based on, or takes advantage of, the violation of the rules for the protection of personal data-cf. Article 10a of Regulation (EU/Euratom) 1141/2014 of the European Parliament and of the Council of 22 October 2014, last amended by Regulation (EU/Euratom) 2019/493 of the European Parliament and of the Council, of March 25, 20196.
6 Available at https://eur-lex.europa.eu/legal-content/PT/TXT/PDF/?uri=CELEX:02014R1141-20190327&from=EN
Av. D. CARLOS 1, 134 - Io I 1200-651 LISBOA I WWW.CNPD.pt I TEL: +351 213 928 400 i fax-.+351 213 976 832
Process PAR/2020/76 7v.
2.2. Article 16 of the Project provides for the right to a digital will.
Although the epigraph helps to interpret the content of the rule, it is important to clarify that the suppression of personal profiles on social networks and the like here in view is that which occurs after the death of the holder of the profiles.
In addition, the rule needs further densification, namely by specifying the appropriate means for demonstrating that will by the data subject, as well as with whom such an expression of will can be formulated (eg together with the person responsible for the social network in cause). This recommendation is based on the difficulties that have been experienced by those responsible for processing personal data in verifying the assumptions for the application of paragraphs 2 and 3 of article 17 of Law no. August, concerning the exercise of rights relating to the processing of data of deceased persons. Therefore, it is insisted, under penalty of this Project norm also running the risk of unenforceability, in its densification.
2.3. Recognizing the importance of affirming the rights of citizens in the interaction with the Public Administration through electronic means, the CNPD here points out some reservations to the terms of its provision in article 17 of the Project.
First, it notes that the generic provision of a right not to repeat the provision of data already provided, needs to be further densified, first of all with regard to the recipient of that provision. Although the political-legislative tendency is to guarantee the interoperability of the information available in the Public Administration, there are constraints that have to be considered, also for reasons of security of the information systems, so the desirable simplification of the interaction between the citizens and the Public Administration knows, in fact, limits.
The same can be said of the right to adopt a digital administrative procedure. The transformation of the decision-making administrative activity of the Public Administration into an exclusively electronic model has been progressive, not only due to the immediate economic costs, which not all public entities are able to immediately bear, but also due to the guarantees of information security and information systems. that cannot be neglected. This norm should be affirmed more as a principle or programmatic norm than as an immediately enforceable right, because the security of the Public Administration's information systems (and with that the security
Process PAR/2020/76 8
NATIONAL COMMISSION
DATA PROTECTION
of the Portuguese State itself, as well as the privacy of citizens) is not compatible with the immediate guarantee of such a right.
The CNPD therefore recommends a densification of the rights provided for in paragraphs a) and d), in order to safeguard the security of information and the information systems of the Public Administration.
Thirdly, the right to benefit from “Open Data” schemes that provide access to data contained in public service computer applications and allow their reuse, enshrined in article 17(e) of the Project, is provided for with a degree of indeterminacy not compatible with the predictability, proportionality and legal certainty that a legal rule attributing rights must be endowed with, especially when, as is the case here, the affirmation of that right is liable to restrict other fundamental rights.
In fact, in the absence of an explanation of the concept of open data, it is essential to delimit the set of information existing in computer applications of public services, under penalty of enshrining a right of open access to personal data. This cannot certainly be the meaning of the consecration of this right of access, because it is, from the outset, delimited, among other diplomas, by the Code of Administrative Procedure and by Law No. 26/2016, of 22 August, and Directive (EU) 2019/1024 of the European Parliament and of the Council of 20 June 2019 on open data and the reuse of information in the public sector (recast).
For this reason, the CNPD recommends clarifying the wording of subparagraph e) of article 17 of the Project, suggesting that it be added, possibly at the end, under the terms provided for by law.
III - Conclusion
1. Although recognizing the value of a diploma that aims to bring together all rights in the digital context, the CNPD cannot fail to point out the rules that repeat rights regulated by rules of European Union law, in disagreement with the jurisprudence of the CJEU, some of the which, seeking to replicate rights already recognized in the RGPD, change the content of these rights, by innovating where the RGPD exhaustively defines their assumptions or by distorting their meaning or scope of application, in contradiction with Union Law. Notwithstanding that the CNPD understands that such norms should be eliminated from the Bill, it presents recommendations that aim to reduce the non-compliance with Union Law.
AV. D. CARLOS l, 134 - Io I 1200-651 LISBON I WWW.CNPD.pt I TED+351 213 928 400 | FAX: +351 213 976 832
Process PAR/2020/76 8v.
In addition, many of the norms provided for in the Bill of Law employ concepts whose definition is contained in legal acts of Union Law, therefore having a specific meaning, but which are not, even by reference, explained in the Articles of the Project, thus hindering their interpretation and affecting the predictability and legal certainty required of rules enshrining rights to which third-party obligations correspond.
Thus, the CNPD, in the light of these arguments and the specific reasons set out above, regarding the rules listed below, the CNPD recommends:
a) In article 4 of the Project, that the exception in paragraph 1 covers the cases provided for in this law and in other legal instruments, in addition to cases in which there is a judicial decision to that effect;
b) In article 7 of the Project, which the exception in paragraph 2 covers, in addition to the cases provided for in the criminal procedural law and with the authorization of a judge, other cases provided for in ier,
c) The elimination of paragraph 4 of article 7 of the Project, or, if not understood, its wording in terms that do not contradict the provisions of article 22 of the GDPR;
d) The elimination of paragraph 2 and paragraph 3 of article 8, or, if this is not understood, their wording in terms that do not differ from the provisions of paragraph 2 f) of article 13 and in point g) of paragraph 2 of article 14 of the GDPR;
e) Amendment to the wording of paragraph 4 of article 11, with the introduction of the terms marked in italics: Any form of use of a two-dimensional code, or of a higher dimension, to process information on the state of health or any other other aspects related to the rights of natural persons, unless secure encryption is applied to the information prior to the generation of the code.;
f) In article 12:
i. The revision of paragraph 1, referring to the grounds for the right to be forgotten provided for in article 17 of the GDPR;
ii. Clarification of the wording of paragraph 2;
iii. The elimination of paragraph 3, or, if this is not the case, its revision in terms that do not contradict the provisions of paragraphs 2 and 3 of article 12 of the GDPR, nor restrict the grounds for the right to erasure of personal data provided for in article 17 of the GDPR;
Process PAR/2020/76 9
NATIONAL COMMISSION
DATA PROTECTION
iv. The deletion of paragraph 4, as it adds nothing in relation to paragraph f) of paragraph 1 of article 17 of the GDPR;
g) In paragraph 1 of article 13, the reconsideration of the provision of a right to erasure of data within the scope of digital platforms, in the light of the exceptions provided for in paragraph 3 of article 17 of the GDPR;
h) In article 15, the reconsideration of the provisions of paragraph 2, emphasizing that it reflects the partial derogation of rules provided for in Law no. access is provided for, appears to violate the principle of proportionality (see Article 18(2) of the CRP and Article 52(1) of the Charter).
2. The CNPD, on the grounds set out in point II.2., also recommends:
a) The densification of article 16, either to specify that the deletion of personal profiles on social and similar networks regulated therein concerns a post-mortem moment to the respective holder, as well as the means and with whom such manifestation of will be formulated;
b) The densification of the rights provided for in paragraphs a) and d) of article 17 of the Project, to safeguard the security of information and the information systems of the Public Administration; and
c) Clarification of the wording of subparagraph e) of article 17 of the Project, suggesting that it be added, possibly at the end, under the terms provided for by law.
Approved at the meeting of September 28, 2020
Filipa Calvão (President)
AV. D. CARLOS I, 134 - 1st | 1200-651 LISBON | WWW.CNPD.PT | TEL:+351 213 928 400 | FAX: +351 213 976 832